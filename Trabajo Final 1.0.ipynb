{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6a716e",
   "metadata": {},
   "source": [
    "# PRIMERA FUENTE DE DATOS: World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fa858-7856-46d3-8310-6a52568fffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - requests: para obtener datos de Internet.\n",
    "# - pandas: para organizar los datos en tablas.\n",
    "# - json: para trabajar con información en formato JSON.\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API del Banco Mundial donde están los datos de anemia infantil.\n",
    "base_url = \"http://api.worldbank.org/v2/country/ALL/indicator/SH.ANM.CHLD.ZS\"\n",
    "\n",
    "# Indicamos a la API que queremos los datos en formato JSON.\n",
    "params = {\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía donde guardaremos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Enviamos la solicitud a la API.\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Verificamos si la solicitud fue exitosa (código 200 significa éxito).\n",
    "if response.status_code == 200:\n",
    "    # Convertimos la respuesta de la API en un formato que Python pueda entender (JSON).\n",
    "    data = response.json()\n",
    "    \n",
    "    # Revisamos si hay datos útiles en la respuesta.\n",
    "    if len(data) > 1:  # Los datos que necesitamos están en la segunda parte de la respuesta.\n",
    "        all_data = data[1]  # Guardamos esos datos en nuestra lista.\n",
    "    else:\n",
    "        print(\"No se encontraron datos en la respuesta.\")\n",
    "else:\n",
    "    # Si ocurre un error, mostramos el código de error.\n",
    "    print(\"Error al obtener los datos:\", response.status_code)\n",
    "\n",
    "# Ahora, organizamos los datos en una tabla usando pandas.\n",
    "df_worldbank = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV (una hoja de cálculo).\n",
    "output_file = \"world_bank_anemia.csv\"\n",
    "df_worldbank.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo sin incluir índices.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70b340",
   "metadata": {},
   "source": [
    "# SEGUNDA FUENTE: Global Health Observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API para datos de nutrición y anemia infantil.\n",
    "base_url = \"https://ghoapi.azureedge.net/api/NUTRITION_ANAEMIA_CHILDREN_NUM\"\n",
    "\n",
    "# Configuramos los parámetros para obtener los datos en partes (paginación):\n",
    "# - \"$top\": cuántos registros obtener por solicitud.\n",
    "# - \"$skip\": cuántos registros saltar para la siguiente solicitud.\n",
    "params = {\n",
    "    \"$top\": 1000,  # Pedimos 1000 registros por solicitud.\n",
    "    \"$skip\": 0     # Empezamos desde el inicio.\n",
    "}\n",
    "\n",
    "# Lista vacía para guardar todos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para seguir pidiendo datos hasta que no queden más.\n",
    "while True:\n",
    "    # Hacemos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Si la solicitud fue exitosa:\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en un formato JSON y agregamos los datos a nuestra lista.\n",
    "        data = response.json()\n",
    "        all_data.extend(data[\"value\"])  # Extendemos la lista con los nuevos datos.\n",
    "        \n",
    "        # Si la cantidad de datos obtenidos es menor que \"$top\", significa que no hay más datos.\n",
    "        if len(data[\"value\"]) < params[\"$top\"]:\n",
    "            break  # Terminamos el ciclo.\n",
    "        \n",
    "        # Si hay más datos, incrementamos \"$skip\" para pedir la siguiente página.\n",
    "        params[\"$skip\"] += params[\"$top\"]\n",
    "    else:\n",
    "        # Si ocurre un error, mostramos el código de error y terminamos el ciclo.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos en una tabla con pandas.\n",
    "df_anemia = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV.\n",
    "output_file = \"nutrition_anemia_children.csv\"\n",
    "df_anemia.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25d6c",
   "metadata": {},
   "source": [
    "# TERCERA FUENTE: DHS Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ffa11",
   "metadata": {},
   "source": [
    "### ENCUESTA 1: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER TIPO DE ANEMIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de nutrición (anemia en este caso).\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_ANY\"\n",
    "\n",
    "# Parámetros que se enviarán a la API:\n",
    "# - \"perpage\": número máximo de registros por solicitud (aquí pedimos 1000).\n",
    "# - \"page\": indica el número de la página que estamos solicitando (empezamos en la 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Máximo de registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la página 1.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para almacenar todos los datos obtenidos de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para descargar todos los datos disponibles en la API.\n",
    "while True:\n",
    "    # Realizamos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de respuesta 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta de la API a formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos dentro de la clave \"Data\" y los agregamos a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos:\n",
    "        # Si la cantidad de datos obtenidos es menor que el límite \"perpage\",\n",
    "        # significa que no hay más páginas que consultar.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código distinto de 200), mostramos el código de error y terminamos.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Una vez descargados todos los datos, los organizamos en una tabla con Pandas.\n",
    "df_any = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_any_anemia.csv\".\n",
    "output_file = \"df_any_anemia.csv\"\n",
    "df_any.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo se creó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871d90f",
   "metadata": {},
   "source": [
    "### ENCUESTA 2: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA LEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cc55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mld_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "# URL de la API del DHS para obtener datos de anemia infantil leve.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MLD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": cantidad máxima de datos que queremos recibir por solicitud (1000 aquí).\n",
    "# - \"page\": indica el número de página que solicitamos (iniciamos desde la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Empezamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para guardar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para realizar solicitudes a la API hasta que descarguemos todos los datos.\n",
    "while True:\n",
    "    # Realizamos la solicitud a la API con los parámetros configurados.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código 200 indica éxito).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Agregamos los datos obtenidos (clave \"Data\") a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si ya no hay más datos disponibles:\n",
    "        # Si el número de datos recibidos es menor al límite \"perpage\", hemos llegado al final.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, pasamos a la siguiente página incrementando el número de página.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (respuesta distinta de 200), mostramos un mensaje con el código de error.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Cuando terminamos de descargar los datos, los organizamos en una tabla usando pandas.\n",
    "df_mld = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mld_anemia.csv\".\n",
    "output_file = \"df_mld_anemia.csv\"\n",
    "df_mld.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d4460",
   "metadata": {},
   "source": [
    "### ENCUESTA 3: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA MODERADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mod_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de anemia infantil moderada.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MOD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": define el número máximo de registros a recibir por solicitud (en este caso, 1000).\n",
    "# - \"page\": indica el número de página que se solicita (empezamos en la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Lista vacía para almacenar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Ciclo para realizar solicitudes repetidas hasta que se descarguen todos los datos disponibles.\n",
    "while True:\n",
    "    # Realizamos una solicitud GET a la API utilizando la URL base y los parámetros definidos.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de estado 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manipular en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos de la clave \"Data\" y los agregamos a la lista \"all_data\".\n",
    "        # Usamos \"get\" para evitar errores si la clave no está presente.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos disponibles:\n",
    "        # Si el número de registros recibidos es menor que \"perpage\", significa que no hay más páginas.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si todavía hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código diferente de 200), mostramos el código de error y detenemos el proceso.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos descargados en una tabla (DataFrame) usando pandas.\n",
    "df_mod = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mod_anemia.csv\".\n",
    "output_file = \"df_mod_anemia.csv\"\n",
    "df_mod.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea84f9",
   "metadata": {},
   "source": [
    "### ENCUESTA 4: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA GRAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_sev_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS (Nutrición - Anemia infantil moderada)\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_SEV\"\n",
    "\n",
    "# Definir los parámetros para la solicitud (si soporta paginación)\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Número de registros por página (se solicita un máximo de 1000 registros por solicitud)\n",
    "    \"page\": 1         # Página inicial, comenzamos desde la primera página de resultados\n",
    "}\n",
    "\n",
    "# Lista para almacenar todos los datos que se vayan obteniendo\n",
    "all_data = []\n",
    "\n",
    "# Hacer varias solicitudes hasta obtener todos los datos (paginación)\n",
    "while True:\n",
    "    # Realizar la solicitud a la API utilizando los parámetros definidos\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        # Convertir la respuesta en formato JSON para manejar los datos\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraer la lista de datos (\"Data\") de la respuesta JSON y agregarla a all_data\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificar si hemos recibido menos registros de los solicitados, lo que indica que hemos llegado al final\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break\n",
    "        \n",
    "        # Incrementar el número de página para la siguiente solicitud\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # En caso de error, imprimir el código de estado de la respuesta\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Convertir los datos obtenidos (all_data) a un DataFrame de Pandas para facilitar su análisis\n",
    "df_sev = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "output_file = \"df_sev_anemia.csv\"\n",
    "df_sev.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Imprimir mensaje de éxito indicando que el archivo CSV fue creado correctamente\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4eafdc",
   "metadata": {},
   "source": [
    "# CUARTA FUENTE: KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c426899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Ruta al archivo 'kaggle.json' que contiene las credenciales de acceso a la API de Kaggle\n",
    "kaggle_file_path = 'kaggle.json'\n",
    "\n",
    "# Leer el archivo JSON que contiene las credenciales\n",
    "with open(kaggle_file_path, 'r') as file:\n",
    "    kaggle_api = json.load(file)\n",
    "\n",
    "# Extraer el 'username' y la 'key' de las credenciales de Kaggle\n",
    "kaggle_username = kaggle_api['username']  # Obtiene el nombre de usuario de Kaggle\n",
    "kaggle_key = kaggle_api['key']  # Obtiene la clave de la API de Kaggle\n",
    "\n",
    "# Configurar las variables de entorno con las credenciales para acceder a la API de Kaggle\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_username  # Establece la variable de entorno para el nombre de usuario\n",
    "os.environ['KAGGLE_KEY'] = kaggle_key  # Establece la variable de entorno para la clave de la API\n",
    "\n",
    "# Imprimir un mensaje de confirmación indicando que las credenciales han sido configuradas correctamente\n",
    "print(\"Credenciales de Kaggle configuradas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ejecutar el comando para listar datasets relacionados con \"child anemia\" en Kaggle y capturar la salida\n",
    "result = subprocess.run(\n",
    "    [\"kaggle\", \"datasets\", \"list\", \"-s\", \"child anemia\"],  # El comando Kaggle para buscar datasets\n",
    "    capture_output=True,  # Captura tanto la salida estándar como los errores\n",
    "    text=True  # Decirle a subprocess que el resultado debe ser tratado como texto (en lugar de bytes)\n",
    ")\n",
    "\n",
    "# Imprimir la salida del comando ejecutado\n",
    "print(result.stdout)  # Muestra el resultado del comando (en este caso, la lista de datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ba11f",
   "metadata": {},
   "source": [
    "### DATA 1: Factores que afectan el nivel de anemia en los niños (Estudio en Nigeria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset a descargar desde Kaggle\n",
    "dataset_name = \"adeolaadesina/factors-affecting-children-anemia-level\"\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd78a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"children anemia.csv\"  # El nombre del archivo CSV descargado\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_nigeria = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso Nigeria)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac045c44",
   "metadata": {},
   "source": [
    "### DATA 2: Encuesta Nacional de Familia y Salud (Estudio en ¿India?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e08084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset que quieres descargar desde Kaggle\n",
    "dataset_name = \"ravisinghiitbhu/nfhs5\"  # Identificador del dataset\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcfff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"Final.csv\"  # Nombre del archivo CSV descargado desde Kaggle\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_india = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso India)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa73104",
   "metadata": {},
   "source": [
    "# **Módulo Análisis de Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c3fd4",
   "metadata": {},
   "source": [
    "## API: World Bank Prevalencia de anemia infantil (% de anemia infantil entre los 6-59 meses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586ad13",
   "metadata": {},
   "source": [
    "## 1. Limpieza de Datos\n",
    "### 1.1 Primera revisión del archivo para observar sus columnas y contenido de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV con los datos sobre anemia del Banco Mundial\n",
    "file_path = 'world_bank_anemia.csv'  # Ruta al archivo CSV\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar una vista previa de los datos para verificar la carga y la estructura\n",
    "print(\"Primeras 5 filas del DataFrame:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nInformación general del DataFrame:\")\n",
    "print(data.info())\n",
    "\n",
    "# Obtener los nombres de las columnas para su posterior análisis\n",
    "columnas = data.columns.tolist()\n",
    "print(\"\\nNombres de las columnas:\")\n",
    "print(columnas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f100edc",
   "metadata": {},
   "source": [
    "### 1.2 Eliminamos las columnas innecesarias y filas sin valores de anemia, también redondeamos valores de anemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a68f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "archivo_original = \"world_bank_anemia.csv\"\n",
    "df = pd.read_csv(archivo_original)\n",
    "\n",
    "# Especificar columnas a eliminar (ajusta según tus necesidades)\n",
    "columnas_a_eliminar = [\"unit\", \"obs_status\", \"decimal\", \"indicator.id\",\n",
    "                      \"countryiso3code\", \"country.id\", \"indicator.value\"]\n",
    "\n",
    "# Limpiar y transformar los datos\n",
    "df['value'] = df['value'].round(1)  # Redondear a 1 decimal\n",
    "df_filtrado = df.drop(columns=columnas_a_eliminar)  # Eliminar columnas innecesarias\n",
    "world_bank_anemia_limpio = df_filtrado.dropna(subset=['value'])  # Eliminar filas con valores faltantes en 'value'\n",
    "\n",
    "# Verificar los resultados\n",
    "print(world_bank_anemia_limpio.head())  # Mostrar las primeras filas del DataFrame limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d17731",
   "metadata": {},
   "source": [
    "## 2. Filtrar\n",
    "### 2.1 Filtrar CSV: Separación por países"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6237873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV original\n",
    "archivo_csv = \"world_bank_anemia_limpio.csv\"  # Reemplaza con la ruta a tu archivo\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Filtrar las filas desde \"Afghanistan\" hasta \"Zimbabwe\" en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "filtro_paises = world_bank_anemia_limpio[ultima_columna].str.strip().isin([\"Afghanistan\", \"Zimbabwe\"])  # Filtrar inicio y fin\n",
    "\n",
    "# Obtener los índices del rango\n",
    "inicio = world_bank_anemia_limpio[filtro_paises].index.min()  # Índice de \"Afghanistan\"\n",
    "fin = world_bank_anemia_limpio[filtro_paises].index.max()  # Índice de \"Zimbabwe\"\n",
    "\n",
    "# Seleccionar los datos dentro de este rango\n",
    "df_paises = world_bank_anemia_limpio.iloc[inicio:fin + 1]  # Incluye ambas filas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5241485",
   "metadata": {},
   "source": [
    "### 2.1.1 Mejoramos el nombre de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar las columnas para una mejor comprensión\n",
    "df_paises = df_paises.rename(columns={\n",
    "    'date': 'year',  # Cambia 'date' a 'year'\n",
    "    'value': 'prevalencia (%)',  # Cambia 'value' a 'prevalencia (%)'\n",
    "    'country.value': 'pais'  # Cambia 'country.value' a 'pais'\n",
    "})\n",
    "\n",
    "# Guardar el DataFrame modificado como un nuevo archivo CSV\n",
    "archivo_csv_nuevo = \"world_bank_anemia_paises_listo.csv\"\n",
    "df_paises.to_csv(archivo_csv_nuevo, index=False)  # Guardar sin incluir el índice\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32273f6f",
   "metadata": {},
   "source": [
    "### 2.2 Agrupar por continentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "file_path = 'world_bank_anemia_paises_listo.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Diccionario para mapear países a continentes\n",
    "country_to_continent = {\n",
    "    \"Afghanistan\": \"Asia\",\n",
    "    \"Albania\": \"Europe\",\n",
    "    \"Algeria\": \"Africa\",\n",
    "    \"Andorra\": \"Europe\",\n",
    "    \"Angola\": \"Africa\",\n",
    "    \"Antigua and Barbuda\": \"North America\",\n",
    "    \"Argentina\": \"South America\",\n",
    "    \"Armenia\": \"Asia\",\n",
    "    \"Australia\": \"Oceania\",\n",
    "    \"Austria\": \"Europe\",\n",
    "    \"Azerbaijan\": \"Asia\",\n",
    "    \"Bahamas\": \"North America\",\n",
    "    \"Bahamas, The\": \"North America\",\n",
    "    \"Bahrain\": \"Asia\",\n",
    "    \"Bangladesh\": \"Asia\",\n",
    "    \"Barbados\": \"North America\",\n",
    "    \"Belarus\": \"Europe\",\n",
    "    \"Belgium\": \"Europe\",\n",
    "    \"Belize\": \"North America\",\n",
    "    \"Benin\": \"Africa\",\n",
    "    \"Bhutan\": \"Asia\",\n",
    "    \"Bolivia\": \"South America\",\n",
    "    \"Bosnia and Herzegovina\": \"Europe\",\n",
    "    \"Botswana\": \"Africa\",\n",
    "    \"Brazil\": \"South America\",\n",
    "    \"Brunei Darussalam\": \"Asia\",\n",
    "    \"Bulgaria\": \"Europe\",\n",
    "    \"Burkina Faso\": \"Africa\",\n",
    "    \"Burundi\": \"Africa\",\n",
    "    \"Cabo Verde\": \"Africa\",\n",
    "    \"Cambodia\": \"Asia\",\n",
    "    \"Cameroon\": \"Africa\",\n",
    "    \"Canada\": \"North America\",\n",
    "    \"Central African Republic\": \"Africa\",\n",
    "    \"Chad\": \"Africa\",\n",
    "    \"Chile\": \"South America\",\n",
    "    \"China\": \"Asia\",\n",
    "    \"Colombia\": \"South America\",\n",
    "    \"Comoros\": \"Africa\",\n",
    "    \"Congo, Dem. Rep.\": \"Africa\",\n",
    "    \"Congo, Rep.\": \"Africa\",\n",
    "    \"Costa Rica\": \"North America\",\n",
    "    \"Cote d'Ivoire\": \"Africa\",\n",
    "    \"Croatia\": \"Europe\",\n",
    "    \"Cuba\": \"North America\",\n",
    "    \"Cyprus\": \"Asia\",\n",
    "    \"Czech Republic\": \"Europe\",\n",
    "    \"Czechia\": \"Europe\",\n",
    "    \"Denmark\": \"Europe\",\n",
    "    \"Djibouti\": \"Africa\",\n",
    "    \"Dominica\": \"North America\",\n",
    "    \"Dominican Republic\": \"North America\",\n",
    "    \"Ecuador\": \"South America\",\n",
    "    \"Egypt\": \"Africa\",\n",
    "    \"Egypt, Arab Rep.\": \"Africa\",\n",
    "    \"El Salvador\": \"North America\",\n",
    "    \"Equatorial Guinea\": \"Africa\",\n",
    "    \"Eritrea\": \"Africa\",\n",
    "    \"Estonia\": \"Europe\",\n",
    "    \"Eswatini\": \"Africa\",\n",
    "    \"Ethiopia\": \"Africa\",\n",
    "    \"Fiji\": \"Oceania\",\n",
    "    \"Finland\": \"Europe\",\n",
    "    \"France\": \"Europe\",\n",
    "    \"Gabon\": \"Africa\",\n",
    "    \"Gambia\": \"Africa\",\n",
    "    \"Gambia, The\": \"Africa\",\n",
    "    \"Georgia\": \"Asia\",\n",
    "    \"Germany\": \"Europe\",\n",
    "    \"Ghana\": \"Africa\",\n",
    "    \"Greece\": \"Europe\",\n",
    "    \"Grenada\": \"North America\",\n",
    "    \"Guatemala\": \"North America\",\n",
    "    \"Guinea\": \"Africa\",\n",
    "    \"Guinea-Bissau\": \"Africa\",\n",
    "    \"Guyana\": \"South America\",\n",
    "    \"Haiti\": \"North America\",\n",
    "    \"Honduras\": \"North America\",\n",
    "    \"Hungary\": \"Europe\",\n",
    "    \"Iceland\": \"Europe\",\n",
    "    \"India\": \"Asia\",\n",
    "    \"Indonesia\": \"Asia\",\n",
    "    \"Iran\": \"Asia\",\n",
    "    \"Iran, Islamic Rep.\": \"Asia\",\n",
    "    \"Iraq\": \"Asia\",\n",
    "    \"Ireland\": \"Europe\",\n",
    "    \"Israel\": \"Asia\",\n",
    "    \"Italy\": \"Europe\",\n",
    "    \"Jamaica\": \"North America\",\n",
    "    \"Japan\": \"Asia\",\n",
    "    \"Jordan\": \"Asia\",\n",
    "    \"Kazakhstan\": \"Asia\",\n",
    "    \"Kenya\": \"Africa\",\n",
    "    \"Kiribati\": \"Oceania\",\n",
    "    \"Korea, Dem. People's Rep.\": \"Asia\",\n",
    "    \"Korea, Dem. Rep.\": \"Asia\",\n",
    "    \"Korea, Rep.\": \"Asia\",\n",
    "    \"Kuwait\": \"Asia\",\n",
    "    \"Kyrgyz Republic\": \"Asia\",\n",
    "    \"Kyrgyzstan\": \"Asia\",\n",
    "    \"Lao PDR\": \"Asia\",\n",
    "    \"Latvia\": \"Europe\",\n",
    "    \"Lebanon\": \"Asia\",\n",
    "    \"Lesotho\": \"Africa\",\n",
    "    \"Liberia\": \"Africa\",\n",
    "    \"Libya\": \"Africa\",\n",
    "    \"Liechtenstein\": \"Europe\",\n",
    "    \"Lithuania\": \"Europe\",\n",
    "    \"Luxembourg\": \"Europe\",\n",
    "    \"Madagascar\": \"Africa\",\n",
    "    \"Malawi\": \"Africa\",\n",
    "    \"Malaysia\": \"Asia\",\n",
    "    \"Maldives\": \"Asia\",\n",
    "    \"Mali\": \"Africa\",\n",
    "    \"Malta\": \"Europe\",\n",
    "    \"Marshall Islands\": \"Oceania\",\n",
    "    \"Mauritania\": \"Africa\",\n",
    "    \"Mauritius\": \"Africa\",\n",
    "    \"Mexico\": \"North America\",\n",
    "    \"Micronesia, Fed. Sts.\": \"Oceania\",\n",
    "    \"Moldova\": \"Europe\",\n",
    "    \"Monaco\": \"Europe\",\n",
    "    \"Mongolia\": \"Asia\",\n",
    "    \"Montenegro\": \"Europe\",\n",
    "    \"Morocco\": \"Africa\",\n",
    "    \"Mozambique\": \"Africa\",\n",
    "    \"Myanmar\": \"Asia\",\n",
    "    \"Namibia\": \"Africa\",\n",
    "    \"Nauru\": \"Oceania\",\n",
    "    \"Nepal\": \"Asia\",\n",
    "    \"Netherlands\": \"Europe\",\n",
    "    \"New Zealand\": \"Oceania\",\n",
    "    \"Nicaragua\": \"North America\",\n",
    "    \"Niger\": \"Africa\",\n",
    "    \"Nigeria\": \"Africa\",\n",
    "    \"North Macedonia\": \"Europe\",\n",
    "    \"Norway\": \"Europe\",\n",
    "    \"Oman\": \"Asia\",\n",
    "    \"Pakistan\": \"Asia\",\n",
    "    \"Palau\": \"Oceania\",\n",
    "    \"Panama\": \"North America\",\n",
    "    \"Papua New Guinea\": \"Oceania\",\n",
    "    \"Paraguay\": \"South America\",\n",
    "    \"Peru\": \"South America\",\n",
    "    \"Philippines\": \"Asia\",\n",
    "    \"Poland\": \"Europe\",\n",
    "    \"Portugal\": \"Europe\",\n",
    "    \"Qatar\": \"Asia\",\n",
    "    \"Romania\": \"Europe\",\n",
    "    \"Russian Federation\": \"Europe\",\n",
    "    \"Rwanda\": \"Africa\",\n",
    "    \"Samoa\": \"Oceania\",\n",
    "    \"San Marino\": \"Europe\",\n",
    "    \"Sao Tome and Principe\": \"Africa\",\n",
    "    \"Saudi Arabia\": \"Asia\",\n",
    "    \"Senegal\": \"Africa\",\n",
    "    \"Serbia\": \"Europe\",\n",
    "    \"Seychelles\": \"Africa\",\n",
    "    \"Sierra Leone\": \"Africa\",\n",
    "    \"Singapore\": \"Asia\",\n",
    "    \"Slovak Republic\": \"Europe\",\n",
    "    \"Slovenia\": \"Europe\",\n",
    "    \"Solomon Islands\": \"Oceania\",\n",
    "    \"Somalia\": \"Africa\",\n",
    "    \"South Africa\": \"Africa\",\n",
    "    \"South Sudan\": \"Africa\",\n",
    "    \"Spain\": \"Europe\",\n",
    "    \"Sri Lanka\": \"Asia\",\n",
    "    \"St. Kitts and Nevis\": \"North America\",\n",
    "    \"St. Lucia\": \"North America\",\n",
    "    \"St. Vincent and the Grenadines\": \"North America\",\n",
    "    \"Sudan\": \"Africa\",\n",
    "    \"Suriname\": \"South America\",\n",
    "    \"Sweden\": \"Europe\",\n",
    "    \"Switzerland\": \"Europe\",\n",
    "    \"Syrian Arab Republic\": \"Asia\",\n",
    "    \"Tajikistan\": \"Asia\",\n",
    "    \"Tanzania\": \"Africa\",\n",
    "    \"Thailand\": \"Asia\",\n",
    "    \"Timor-Leste\": \"Asia\",\n",
    "    \"Togo\": \"Africa\",\n",
    "    \"Tonga\": \"Oceania\",\n",
    "    \"Trinidad and Tobago\": \"North America\",\n",
    "    \"Tunisia\": \"Africa\",\n",
    "    \"Turkey\": \"Asia\",\n",
    "    \"Turkmenistan\": \"Asia\",\n",
    "    \"Tuvalu\": \"Oceania\",\n",
    "    \"Uganda\": \"Africa\",\n",
    "    \"Ukraine\": \"Europe\",\n",
    "    \"United Arab Emirates\": \"Asia\",\n",
    "    \"United Kingdom\": \"Europe\",\n",
    "    \"United States\": \"North America\",\n",
    "    \"Uruguay\": \"South America\",\n",
    "    \"Uzbekistan\": \"Asia\",\n",
    "    \"Vanuatu\": \"Oceania\",\n",
    "    \"Venezuela\": \"South America\",\n",
    "    \"Venezuela, RB\": \"South America\",\n",
    "    \"Vietnam\": \"Asia\",\n",
    "    \"Viet Nam\": \"Asia\",\n",
    "    \"West Bank and Gaza\": \"Asia\",\n",
    "    \"Yemen\": \"Asia\",\n",
    "    \"Yemen, Rep.\": \"Asia\",\n",
    "    \"Zambia\": \"Africa\",\n",
    "    \"Zimbabwe\": \"Africa\"\n",
    "}\n",
    "\n",
    "#Este diccionario define la asociación entre cada país y su respectivo continente. Los nombres de los países deben coincidir con los nombres en la columna `country.value` del archivo CSV cargado.\n",
    "\n",
    "# Crear la nueva columna \"Continente\"\n",
    "data['Continente'] = data['country.value'].map(country_to_continent) #Se agrega una nueva columna al DataFrame llamada `Continente`. Para cada país en la columna `country.value`, se asigna el continente correspondiente utilizando el diccionario `country_to_continent`.\n",
    "\n",
    "\n",
    "# Ordenar los países por continente y luego por nombre\n",
    "sorted_data = data.sort_values(by=['Continente', 'country.value']) #Los datos se ordenan primero por el continente (columna `Continente`) y luego por el nombre del país (columna `country.value`) de manera alfabética.\n",
    "\n",
    "# Guardar el archivo CSV resultante\n",
    "output_path = 'world_bank_continentes.csv'\n",
    "sorted_data.to_csv(output_path, index=False)  #Se guarda el DataFrame resultante en un nuevo archivo CSV llamado `world_bank_continentes.csv`. La opción `index=False` asegura que el índice del DataFrame no se incluya en el archivo.\n",
    "\n",
    "print(f\"Archivo generado: {output_path}\") #Se imprime un mensaje en la consola confirmando la generación del archivo CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e30ff8",
   "metadata": {},
   "source": [
    "### 2.3 Filtrar CSV: Separación por ingresos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a filtrar en la última columna\n",
    "valores_deseados = [\n",
    "    \"High income\",\n",
    "    \"Low & middle income\",\n",
    "    \"Low income\",\n",
    "    \"Middle income\",\n",
    "    \"Upper middle income\"\n",
    "]\n",
    "\n",
    "# Filtrar las filas que contienen estos valores en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna \n",
    "#Se identifica el nombre de la última columna del DataFrame `world_bank_anemia_limpio` accediendo al último elemento de la lista de nombres de columnas mediante el índice `-1`.\n",
    "\n",
    "world_bank_anemia_filtrado = world_bank_anemia_limpio[world_bank_anemia_limpio[ultima_columna].str.strip().isin(valores_deseados)]\n",
    "#En esta línea, se realiza el filtrado del DataFrame:\n",
    "#- `world_bank_anemia_limpio[ultima_columna]`: Selecciona los valores de la última columna.\n",
    "#- `.str.strip()`: Elimina espacios en blanco al inicio y al final de cada valor, asegurando coincidencias precisas.\n",
    "#- `.isin(valores_deseados)`: Verifica si cada valor pertenece a la lista `valores_deseados`.\n",
    "#- Las filas que cumplen estas condiciones se seleccionan y se asignan a un nuevo DataFrame llamado `world_bank_anemia_filtrado`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2c2d6",
   "metadata": {},
   "source": [
    "### 2.3.1 Mejoramos el nombre de las columnas y valor de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los nombres de las columnas\n",
    "world_bank_anemia_filtrado = world_bank_anemia_filtrado.rename(columns={\n",
    "    'date': 'year',\n",
    "    'value': 'prevalencia (%)',\n",
    "    'country.value': 'nivel de ingresos'\n",
    "})\n",
    "#En esta parte, se renombra las columnas del DataFrame `world_bank_anemia_filtrado` de la siguiente manera:\n",
    "#- `date` pasa a llamarse `year`.\n",
    "#- `value` pasa a llamarse `prevalencia (%)`.\n",
    "#- `country.value` pasa a llamarse `nivel de ingresos`.\n",
    "\n",
    "# Modificar los valores de la columna \"nivel de ingresos\"\n",
    "world_bank_anemia_filtrado['nivel de ingresos'] = world_bank_anemia_filtrado['nivel de ingresos'].replace({\n",
    "    'High income': 'Ingresos altos',\n",
    "    'Low & middle income': 'Ingresos bajos y medios',\n",
    "    'Low income': 'Bajos ingresos',\n",
    "    'Middle income': 'Ingreso medio',\n",
    "    'Upper middle income': 'Ingreso medio alto',\n",
    "    'Lower middle income': 'Ingreso medio bajo'\n",
    "})\n",
    "#Los valores de la columna `nivel de ingresos` se traducen o modifican según el siguiente mapeo:\n",
    "#- `High income` se convierte en `Ingresos altos`.\n",
    "#- `Low & middle income` se convierte en `Ingresos bajos y medios`.\n",
    "#- `Low income` se convierte en `Bajos ingresos`.\n",
    "#- `Middle income` se convierte en `Ingreso medio`.\n",
    "#- `Upper middle income` se convierte en `Ingreso medio alto`.\n",
    "#- `Lower middle income` se convierte en `Ingreso medio bajo`.\n",
    "\n",
    "#La función `replace` permite realizar estas transformaciones en toda la columna.\n",
    "\n",
    "\n",
    "# Guardar el nuevo archivo CSV con los nombres de columnas cambiados\n",
    "archivo_csv_nuevo = \"world_bank_anemia_ingresos_listo.csv\"\n",
    "world_bank_anemia_filtrado.to_csv(archivo_csv_nuevo, index=False)\n",
    "#El DataFrame modificado se guarda en un nuevo archivo CSV llamado `world_bank_anemia_ingresos_listo.csv`. La opción `index=False` asegura que no se incluya el índice del DataFrame en el archivo.\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\") #Se imprime un mensaje en la consola para confirmar que el archivo se ha guardado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfe85f",
   "metadata": {},
   "source": [
    "### 2.4 Filtrar CSV: A nivel mundial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758607a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a filtrar en la última columna\n",
    "valores_deseados = [\n",
    "    \"World\"\n",
    "]\n",
    "\n",
    "# Filtrar las filas que contienen estos valores en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "df_filtrado = world_bank_anemia_limpio[world_bank_anemia_limpio[ultima_columna].str.strip().isin(valores_deseados)]\n",
    "\n",
    "# Guardar en un nuevo archivo CSV\n",
    "nuevo_csv = \"world_bank_anemia_mundial.csv\"\n",
    "df_filtrado.to_csv(nuevo_csv, index=False)\n",
    "\n",
    "print(f\"Datos filtrados guardados en: {nuevo_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acf850",
   "metadata": {},
   "source": [
    "### 2.4.1 Mejoramos el nombre de las columnas y valor de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09573696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "archivo_csv = \"world_bank_anemia_mundial.csv\"  # Asegúrate de que el archivo esté en la misma carpeta o proporciona la ruta completa\n",
    "df = pd.read_csv(archivo_csv)\n",
    "#Se carga el archivo CSV denominado `world_bank_anemia_mundial.csv` en un DataFrame llamado `df` utilizando la función `read_csv` de `pandas`.\n",
    "#- Si el archivo no está en el directorio de trabajo actual, se debe proporcionar la ruta completa.\n",
    "\n",
    "# Cambiar los nombres de las columnas\n",
    "df = df.rename(columns={\n",
    "    'date': 'year',\n",
    "    'value': 'prevalencia (%)',\n",
    "    'country.value': 'nivel geográfico'\n",
    "})\n",
    "#Las columnas se renombran de la siguiente manera:\n",
    "#- `date` pasa a llamarse `year`.\n",
    "#- `value` pasa a llamarse `prevalencia (%)`.\n",
    "#- `country.value` pasa a llamarse `nivel geográfico`.\n",
    "#Esto se realiza mediante el método `rename`, proporcionando un diccionario que mapea los nombres antiguos a los nuevos.\n",
    "\n",
    "# Modificar los valores de la columna \"nivel geográfico\"\n",
    "df['nivel geográfico'] = df['nivel geográfico'].replace({\n",
    "    'World': 'Mundial'\n",
    "})\n",
    "#En la columna `nivel geográfico`, el valor `World` se reemplaza por `Mundial` para hacer el texto más comprensible.\n",
    "\n",
    "# Guardar el nuevo archivo CSV con los nombres de columnas cambiados\n",
    "archivo_csv_nuevo = \"world_bank_anemia_mundial_listo.csv\"\n",
    "df.to_csv(archivo_csv_nuevo, index=False)\n",
    "#El DataFrame modificado se guarda en un nuevo archivo CSV denominado `world_bank_anemia_mundial_listo.csv`.\n",
    "#- El parámetro `index=False` asegura que el índice del DataFrame no se incluya como una columna adicional en el archivo generado.\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\")\n",
    "#Se imprime un mensaje en la consola confirmando que el archivo se ha guardado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd86c1",
   "metadata": {},
   "source": [
    "# API: Demographic Health Survey (PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER/LEVE/MODERADO/SEVERO NIVEL DE ANEMIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaaa741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "# Cargar archivo para anemia general\n",
    "file_path = 'df_any_anemia.csv'\n",
    "any = pd.read_csv(file_path)\n",
    "\n",
    "#Cargar archivo para anemia leve\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "mild = pd.read_csv(file_path)\n",
    "\n",
    "#Cargar archivo para anemia moderada\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "mod = pd.read_csv(file_path)\n",
    "\n",
    "#Cargar archivo para anemia severa\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "sev = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd82ca2",
   "metadata": {},
   "source": [
    "## 1. Limpieza de Datos\n",
    "\n",
    "### 1.1 Eliminación de columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb467ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a eliminar\n",
    "columns_to_drop = ['DataId', 'SurveyId', 'Indicator', 'IsPreferred', 'SDRID', 'Precision', 'RegionId', 'SurveyType',\n",
    "'IndicatorId', 'CharacteristicOrder', 'CharacteristicLabel',  'ByVariableLabel', 'CIHigh', 'IsTotal', 'ByVariableId',\n",
    "                   'IndicatorOrder', 'DHS_CountryCode',  'CILow', 'LevelRank', 'CharacteristicId', 'CharacteristicCategory'\n",
    "                 , 'IndicatorType',\n",
    "                   'DenominatorUnweighted','DenominatorWeighted', \"SurveyYearLabel\", \"Value\"\n",
    "]\n",
    "\n",
    "# Eliminar las columnas no deseadas\n",
    "df_cleaned0 = any.drop(columns=columns_to_drop)\n",
    "df_cleaned1 = mild.drop(columns=columns_to_drop)\n",
    "df_cleaned2 = mod.drop(columns=columns_to_drop)\n",
    "df_cleaned3 = sev.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5653c7",
   "metadata": {},
   "source": [
    "## 1.2 Mejorar nombres de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo dataframe con las columnas especificadas\n",
    "df_combined = pd.DataFrame({\n",
    "    'Year': any['SurveyYear'],  # SurveyYear de 'any'\n",
    "    'Pais': any['CountryName'],  # CountryName de 'any'\n",
    "\n",
    "    'Valor Cualquier': any['Value'],  # Value de 'any' renombrado\n",
    "    '# Encuestas (any, sin ponderar)': any['DenominatorUnweighted'],  # DenominatorUnweighted de 'any'\n",
    "    '# Encuestas (any, ponderadas)': any['DenominatorWeighted'],  # DenominatorWeighted de 'any'\n",
    "\n",
    "    'Valor Leve': mild['Value'],  # Value de 'mild' renombrado\n",
    "    '# Encuestas (mild, sin ponderar)': mild['DenominatorUnweighted'],  # DenominatorUnweighted de 'mild'\n",
    "    '# Encuestas (mild, ponderadas)': mild['DenominatorWeighted'],  # DenominatorWeighted de 'mild'\n",
    "\n",
    "    'Valor Moderado': mod['Value'],  # Value de 'mod' renombrado\n",
    "    '# Encuestas (mod, sin ponderar)': mod['DenominatorUnweighted'],  # DenominatorUnweighted de 'mod'\n",
    "    '# Encuestas (mod, ponderadas)': mod['DenominatorWeighted'],  # DenominatorWeighted de 'mod'\n",
    "\n",
    "    'Valor Severo': sev['Value'],  # Value de 'sev' renombrado\n",
    "    '# Encuestas (sev, sin ponderar)': sev['DenominatorUnweighted'],  # DenominatorUnweighted de 'sev'\n",
    "    '# Encuestas (sev, ponderadas)': sev['DenominatorWeighted']  # DenominatorWeighted de 'sev'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Guardar el dataframe combinado como un nuevo archivo CSV\n",
    "output_file_combined = 'dhs_anemia_final.csv'\n",
    "df_combined.to_csv(output_file_combined, index=False)\n",
    "\n",
    "# Imprimir la ruta del archivo guardado\n",
    "print(f\"Archivo guardado en: {output_file_combined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e869f",
   "metadata": {},
   "source": [
    "# API KAGGLE (FACTORES QUE PODRIAN ESTAR INFLUENCIANDO EL NIVEL DE ANEMIA EN NIÑOS DE 0-59 MESES) - Caso: Nigeria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbf9d5",
   "metadata": {},
   "source": [
    "## Descripción del caso\n",
    "\n",
    "En este estudio, se recopilaron datos transversales de las Encuestas demográficas y de salud de Nigeria (NDHS) de 2018 para responder a preguntas de investigación sobre el efecto de la edad de las madres y otros factores socioeconómicos en el nivel de anemia de los niños de 0 a 59 meses en Nigeria. Las DHS son encuestas transversales de hogares representativas a nivel nacional que generalmente se realizan cada 5 años. Los datos de esta encuesta consideraron los 36 estados de Nigeria, así como el Territorio de la Capital Federal (FCT). La población objetivo de este estudio son los niños de 0 a 59 meses y las madres de 15 a 49 años. En esta encuesta, el ingreso del hogar se midió utilizando el índice de riqueza, la edad actual en grupos de 5 años se produce agrupando la edad actual en años completados, tipo de lugar de residencia donde el encuestado fue entrevistado como urbano o rural, la categorización se creó en función de si el número de punto de muestra o conglomerado se define como urbano o rural, el nivel más alto de educación alcanzado es una variable estandarizada que proporciona el nivel de educación en las siguientes categorías: Sin educación, Educación primaria, secundaria y superior, el número total de nacimientos en los últimos cinco años se define como todos los nacimientos en los meses 0 a 59 anteriores al mes de la entrevista, donde el mes 0 es el mes de la entrevista, la edad del encuestado en el primer nacimiento se calcula utilizando el CMC de la fecha de nacimiento del encuestado.\n",
    "\n",
    "Después de la depuración de los datos, se utilizó el método Chi cuadrado para probar las hipótesis sobre la posible relación que existe entre ciertos factores socioeconómicos y los niveles de anemia en niños de 0 a 59 meses. El nivel de anemia fue la variable predictora y las variables explicativas son la edad de la madre, el nivel de educación, el índice de riqueza, el nacimiento en los últimos cinco años, el uso de mosquiteros, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22df03b",
   "metadata": {},
   "source": [
    "# Diccionario de datos\n",
    "\n",
    "```Python\n",
    "Type of place of residence\n",
    "0: Rural\n",
    "1: Urban\n",
    "\n",
    "\n",
    "Highest educational level\n",
    "0: Higher\n",
    "1: No education\n",
    "2: Primary\n",
    "3: Secondary\n",
    "\n",
    "\n",
    "Wealth index combined\n",
    "0: Middle\n",
    "1: Poorer\n",
    "2: Poorest\n",
    "3: Richer\n",
    "4: Richest\n",
    "\n",
    "\n",
    "Anemia level\n",
    "0: Mild\n",
    "1: Moderate\n",
    "2: Not anemic\n",
    "3: Severe\n",
    "\n",
    "\n",
    "Have mosquito bed net for sleeping (from household questionnaire)\n",
    "0: No\n",
    "1: Yes\n",
    "\n",
    "\n",
    "Smokes cigarettes\n",
    "0: No\n",
    "1: Yes\n",
    "\n",
    "\n",
    "Current marital status\n",
    "0: Divorced\n",
    "1: Living with partner\n",
    "2: Married\n",
    "3: Never in union\n",
    "4: No longer living together/separated\n",
    "5: Widowed\n",
    "\n",
    "\n",
    "Currently residing with husband/partner\n",
    "0: Living with her\n",
    "1: Staying elsewhere\n",
    "\n",
    "\n",
    "When child put to breast\n",
    "0: 102.0\n",
    "1: 103.0\n",
    "2: 104.0\n",
    "... (continuando con valores similares)\n",
    "38: Days: 1\n",
    "39: Hours: 1\n",
    "40: Immediately\n",
    "\n",
    "\n",
    "Had fever in last two weeks\n",
    "0: Don't know\n",
    "1: No\n",
    "2: Yes\n",
    "\n",
    "\n",
    "Taking iron pills, sprinkles or syrup\n",
    "0: Don't know\n",
    "1: No\n",
    "2: Yes\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eca8bd",
   "metadata": {},
   "source": [
    "## 1. Implementacion de funciones para limpiar, ordenar y transformar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'children anemia.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar una vista previa de los datos para analizar la estructura\n",
    "data.head(), data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43091910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para limpiar, ordenar y transformar los datos\n",
    "def limpiar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia los datos eliminando columnas duplicadas, renombrando columnas y gestionando valores faltantes.\n",
    "    \"\"\"\n",
    "    # Eliminar columnas duplicadas o irrelevantes\n",
    "    columnas_a_eliminar = ['Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)',\n",
    "                           'Anemia level.1']\n",
    "    dataframe = dataframe.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "    # Renombrar columnas para mayor claridad\n",
    "    dataframe = dataframe.rename(columns={\n",
    "        'Age in 5-year groups': 'Age_Group',\n",
    "        'Type of place of residence': 'Residence_Type',\n",
    "        'Highest educational level': 'Education_Level',\n",
    "        'Wealth index combined': 'Wealth_Index',\n",
    "        'Births in last five years': 'Births_Last_5_Years',\n",
    "        'Age of respondent at 1st birth': 'Age_First_Birth',\n",
    "        'Anemia level': 'Anemia_Level',\n",
    "        'Have mosquito bed net for sleeping (from household questionnaire)': 'Mosquito_Net',\n",
    "        'Smokes cigarettes': 'Smokes',\n",
    "        'Current marital status': 'Marital_Status',\n",
    "        'Currently residing with husband/partner': 'Residing_With_Partner',\n",
    "        'When child put to breast': 'Breastfeeding_Timing',\n",
    "        'Had fever in last two weeks': 'Fever_Last_2_Weeks',\n",
    "        'Hemoglobin level adjusted for altitude (g/dl - 1 decimal)': 'Hemoglobin_Level',\n",
    "        'Taking iron pills, sprinkles or syrup': 'Iron_Supplements'\n",
    "    })\n",
    "\n",
    "    # Manejo de valores faltantes\n",
    "    dataframe['Anemia_Level'] = dataframe['Anemia_Level'].fillna('Unknown')  # Llenar valores faltantes de anemia con \"Unknown\"\n",
    "    dataframe = dataframe.dropna(subset=['Hemoglobin_Level', 'Education_Level'])  # Eliminar filas con valores críticos faltantes\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def transformar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Transforma los datos categóricos a variables numéricas y estandariza las columnas.\n",
    "    \"\"\"\n",
    "    # Convertir categorías a valores numéricos\n",
    "    categoricas_a_codificar = ['Residence_Type', 'Education_Level', 'Wealth_Index', 'Anemia_Level',\n",
    "                               'Mosquito_Net', 'Smokes', 'Marital_Status', 'Residing_With_Partner',\n",
    "                               'Breastfeeding_Timing', 'Fever_Last_2_Weeks', 'Iron_Supplements']\n",
    "\n",
    "    for columna in categoricas_a_codificar:\n",
    "        dataframe[columna] = dataframe[columna].astype('category').cat.codes\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'children anemia.csv'  # Reemplaza con la ruta del archivo en tu sistema\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Aplicar funciones al dataset\n",
    "datos_limpios = limpiar_datos(data)\n",
    "datos_transformados = transformar_datos(datos_limpios)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame transformado\n",
    "print(datos_transformados.head())\n",
    "\n",
    "# Guardar los datos transformados en un archivo CSV\n",
    "datos_transformados.to_csv('datos_limpios_transformados.csv', index=False)\n",
    "print(\"Datos guardados como 'datos_limpios_transformados.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493c51e",
   "metadata": {},
   "source": [
    "## 2. Calcular métricas como media, mediana, moda, y otras estadísticas relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be42b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_avanzadas(dataframe):\n",
    "    \"\"\"\n",
    "    Calcula métricas descriptivas avanzadas como percentiles, asimetría, curtosis y más.\n",
    "    \"\"\"\n",
    "    # Seleccionar columnas numéricas\n",
    "    columnas_numericas = dataframe.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "    # Crear un diccionario para almacenar las métricas\n",
    "    estadisticas = {}\n",
    "\n",
    "    for columna in columnas_numericas.columns:\n",
    "        estadisticas[columna] = {\n",
    "            'Media': columnas_numericas[columna].mean(),\n",
    "            'Mediana': columnas_numericas[columna].median(),\n",
    "            'Moda': columnas_numericas[columna].mode().iloc[0] if not columnas_numericas[columna].mode().empty else None,\n",
    "            'Desviación Estándar': columnas_numericas[columna].std(),\n",
    "            'Mínimo': columnas_numericas[columna].min(),\n",
    "            'Máximo': columnas_numericas[columna].max(),\n",
    "            'Rango': columnas_numericas[columna].max() - columnas_numericas[columna].min(),\n",
    "            'Percentil 25': columnas_numericas[columna].quantile(0.25),\n",
    "            'Percentil 75': columnas_numericas[columna].quantile(0.75),\n",
    "            'Asimetría': columnas_numericas[columna].skew(),\n",
    "            'Curtosis': columnas_numericas[columna].kurt(),\n",
    "            'Rango Intercuartílico (IQR)': columnas_numericas[columna].quantile(0.75) - columnas_numericas[columna].quantile(0.25),\n",
    "            'Coeficiente de Variación (CV)': columnas_numericas[columna].std() / columnas_numericas[columna].mean(),\n",
    "        }\n",
    "\n",
    "    # Convertir a un DataFrame para mejor visualización\n",
    "    estadisticas_df = pd.DataFrame(estadisticas).transpose()\n",
    "    return estadisticas_df\n",
    "\n",
    "\n",
    "# Calcular métricas avanzadas\n",
    "metricas_avanzadas = calcular_metricas_avanzadas(datos_transformados)\n",
    "\n",
    "# Mostrar las métricas avanzadas\n",
    "print(metricas_avanzadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1795277",
   "metadata": {},
   "source": [
    "## 3. Estructuras de datos (listas, pilas, colas) que faciliten el análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d0498",
   "metadata": {},
   "source": [
    "### 3.1 Lista\n",
    "\n",
    "Las listas son ideales para almacenar datos tabulares o registros específicos que se necesitan procesar en secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer datos relevantes y almacenarlos en una lista\n",
    "lista_anemia = datos_transformados[['Age_Group', 'Anemia_Level', 'Hemoglobin_Level']].values.tolist()\n",
    "\n",
    "# Ejemplo de acceso a los datos\n",
    "print(\"Ejemplo de registros en lista:\")\n",
    "print(lista_anemia[:5])  # Imprime los primeros 5 registros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684d1c3",
   "metadata": {},
   "source": [
    "### 3.2 Pila (Stack)\n",
    "\n",
    "Las pilas siguen el principio LIFO (Last In, First Out) y son útiles si los datos se necesitan procesar en orden inverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c33f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pila:\n",
    "    # Constructor de la clase Pila\n",
    "    def __init__(self):\n",
    "        self.stack = [] # Inicializamos una lista vacía que será nuestra pila\n",
    "\n",
    "    # Método para agregar un elemento a la pila\n",
    "    def push(self, item):\n",
    "        self.stack.append(item) # Agrega el elemento al final de la lista (pila)\n",
    "\n",
    "    # Método para eliminar y retornar el último elemento de la pila\n",
    "    def pop(self):\n",
    "        # Si la pila no está vacía, eliminamos el último elemento. Si está vacía, devolvemos None\n",
    "        return self.stack.pop() if not self.is_empty() else None\n",
    "\n",
    "    # Método para ver el último elemento de la pila sin eliminarlo\n",
    "    def peek(self):\n",
    "        # Si la pila no está vacía, retornamos el último elemento. Si está vacía, devolvemos None\n",
    "        return self.stack[-1] if not self.is_empty() else None\n",
    "\n",
    "    # Método para verificar si la pila está vacía\n",
    "    def is_empty(self):\n",
    "        return len(self.stack) == 0  # La pila está vacía si su longitud es 0\n",
    "\n",
    "# Crear una pila con los datos relevantes\n",
    "pila_anemia = Pila()\n",
    "# Iterar sobre las filas del DataFrame 'datos_transformados'\n",
    "for _, row in datos_transformados.iterrows():\n",
    "    # Crear un diccionario con el grupo de edad y nivel de anemia y agregarlo a la pila\n",
    "    pila_anemia.push({'Age_Group': row['Age_Group'], 'Anemia_Level': row['Anemia_Level']})\n",
    "\n",
    "# Ejemplo de uso de la pila\n",
    "print(\"Dato extraído de la pila:\", pila_anemia.pop())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba0311",
   "metadata": {},
   "source": [
    "### 3.3 Cola (Queue)\n",
    "\n",
    "Las colas siguen el principio FIFO (First In, First Out) y son útiles si los datos se deben procesar en el mismo orden en que se almacenaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d575a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Crear una cola con los datos relevantes\n",
    "cola_anemia = deque()\n",
    "\n",
    "# Iterar sobre las filas del DataFrame 'datos_transformados'\n",
    "for _, row in datos_transformados.iterrows():\n",
    "    # Crear un diccionario con el grupo de edad y el nivel de anemia y agregarlo a la cola\n",
    "    cola_anemia.append({'Age_Group': row['Age_Group'], 'Anemia_Level': row['Anemia_Level']})\n",
    "\n",
    "# Ejemplo de uso de la cola\n",
    "print(\"Dato extraído de la cola:\", cola_anemia.popleft())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24f61b",
   "metadata": {},
   "source": [
    "## API: Global Health Observatory - Prevalencia de anemia infantil (% de anemia infantil entre los 6-59 meses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38397a5",
   "metadata": {},
   "source": [
    "## 1. Analisis de datos inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#Se importan las librerías `requests` para realizar solicitudes HTTP y `pandas` para manipular y analizar los datos en formato tabular.\n",
    "\n",
    "# URL de la API para la prevalencia de anemia (sustituir con el código correcto)\n",
    "indicator_code = \"NUTRITION_ANAEMIA_CHILDREN_PREV\"  # Cambia a la API para prevalencia de anemia\n",
    "url = f\"https://ghoapi.azureedge.net/api/{indicator_code}\"\n",
    "\n",
    "#- Se define el código del indicador de la API (`NUTRITION_ANAEMIA_CHILDREN_PREV` en este caso).\n",
    "#- Se construye la URL para realizar la solicitud a la API utilizando el código del indicador.\n",
    "\n",
    "# Realizar la solicitud\n",
    "response = requests.get(url)\n",
    "#Se utiliza el método `get` de la librería `requests` para realizar una solicitud HTTP a la URL de la API.\n",
    "\n",
    "\n",
    "# Verificar que la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Extraer los datos en formato JSON\n",
    "#- Se verifica si la solicitud fue exitosa comprobando que el código de estado HTTP es `200`.\n",
    "#- Si la respuesta es exitosa, los datos se extraen en formato JSON utilizando el método `json` de la respuesta.\n",
    "\n",
    "    # Convertir los datos a un DataFrame\n",
    "    df = pd.json_normalize(data['value'])\n",
    "    #- Los datos extraídos del JSON (ubicados en la clave `value`) se convierten en un DataFrame de `pandas` usando `json_normalize`.\n",
    "\n",
    "    # Mostrar las primeras filas\n",
    "    print(df.head(48))\n",
    "    #Se imprime una vista previa de las primeras 48 filas del DataFrame para verificar la estructura de los datos.\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f\"Error al acceder a la API: {response.status_code}\")\n",
    "    #- Si la solicitud no es exitosa, se imprime un mensaje de error junto con el código de estado HTTP para facilitar la depuración."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f3d2e",
   "metadata": {},
   "source": [
    "## **2. Limpieza de datos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este fragmento de código verifica si hay valores nulos en el DataFrame y muestra la cantidad de valores nulos por columna.\n",
    "print(df.isnull().sum())\n",
    "\n",
    "##### Explicación detallada\n",
    "#1. **`df.isnull()`**:\n",
    "#   - Este método de pandas genera un nuevo DataFrame del mismo tamaño que `df`, donde cada celda contiene `True` si el valor correspondiente en el DataFrame original es nulo (`NaN`) y `False` si no lo es.\n",
    "\n",
    "#2. **`.sum()`**:\n",
    "#   - Este método se aplica a lo largo de las columnas del DataFrame generado por `isnull()`. Cuenta el número de valores `True` en cada columna, es decir, la cantidad de valores nulos por columna.\n",
    "\n",
    "#3. **`print()`**:\n",
    "#   - El resultado del conteo de valores nulos por columna se imprime en la salida estándar para que el usuario pueda revisarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6d448",
   "metadata": {},
   "source": [
    "### **2.1 Eliminación de filas y columnas sin datos**\n",
    "\n",
    "*   Elemento de la lista\n",
    "*   Elemento de la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código elimina valores nulos en un DataFrame utilizando el método `dropna()` de pandas. Se aborda tanto la eliminación de filas como de columnas que contienen valores nulos.\n",
    "\n",
    "# Eliminar filas con valores nulos\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Eliminar columnas con valores nulos\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "#### Explicación detallada\n",
    "#1. **`df.dropna()`**:\n",
    "#   - Este método elimina las filas del DataFrame que contienen al menos un valor nulo (`NaN`).\n",
    "#   - Devuelve un nuevo DataFrame (`df_cleaned`), sin modificar el DataFrame original (`df`).\n",
    "\n",
    "#2. **`df.dropna(axis=1)`**:\n",
    "#   - Este método elimina las columnas del DataFrame que contienen al menos un valor nulo.\n",
    "#   - El argumento `axis=1` indica que la operación se realiza sobre las columnas (en lugar de las filas, que es el valor predeterminado).\n",
    "\n",
    "#3. **Sobrescritura del DataFrame limpio**:\n",
    "#   - En este código, `df_cleaned` se sobrescribe al eliminar filas y luego columnas con valores nulos. Si necesitas conservar ambos resultados (sin filas nulas y sin columnas nulas), asigna cada operación a variables diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código imprime los nombres de las columnas del DataFrame `df_cleaned` después de realizar una limpieza, como la eliminación de filas y columnas con valores nulos.\n",
    "\n",
    "print(\"Columnas después de la limpieza:\")\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "#### Explicación detallada\n",
    "#1. **`print(\"Columnas después de la limpieza:\")`**:\n",
    "#   - Este comando imprime un mensaje descriptivo que indica al usuario que se mostrarán las columnas actuales del DataFrame tras la limpieza.\n",
    "\n",
    "#2. **`print(df_cleaned.columns)`**:\n",
    "#   - Este comando imprime los nombres de las columnas del DataFrame `df_cleaned`.\n",
    "#   - El atributo `columns` de un DataFrame devuelve un objeto `Index` que contiene los nombres de todas las columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3586ee3",
   "metadata": {},
   "source": [
    "### **2.2 Imputación de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd25d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas específicas\n",
    "# Asegúrate de que los nombres de las columnas coincidan exactamente con los del DataFrame\n",
    "columnas_deseadas = ['SpatialDimType', 'SpatialDim', 'Dim1Type', 'TimeDim','NumericValue', 'Low', 'High']\n",
    "# Elimina espacios extra en ' Dim1Type' y 'TimeDim '\n",
    "\n",
    "# Verificar si las columnas existen antes de seleccionarlas\n",
    "columnas_existentes = df_cleaned.columns\n",
    "columnas_deseadas = [col for col in columnas_deseadas if col in columnas_existentes]\n",
    "\n",
    "df_seleccion = df_cleaned[columnas_deseadas]\n",
    "\n",
    "print(df_seleccion.head(30))\n",
    "\n",
    "\n",
    "### Explicación detallada\n",
    "#1. **Definir columnas deseadas**:\n",
    "#   - Se crea una lista `columnas_deseadas` con los nombres de las columnas que queremos seleccionar.\n",
    "#   - Asegúrate de que los nombres de las columnas coincidan exactamente con los nombres en el DataFrame original (incluyendo espacios en blanco, si los hubiera).\n",
    "\n",
    "#2. **Verificar columnas existentes**:\n",
    "#   - El código obtiene todas las columnas actuales del DataFrame `df_cleaned` usando `df_cleaned.columns`.\n",
    "#- Filtra la lista `columnas_deseadas` para conservar solo aquellas columnas que existen en el DataFrame.\n",
    "\n",
    "\n",
    "#3. **Seleccionar columnas**:\n",
    "#   - Usa la lista filtrada `columnas_deseadas` para crear un nuevo DataFrame `df_seleccion` que contiene solo las columnas deseadas.\n",
    "\n",
    "#4. **Imprimir el resultado**:\n",
    "#  - Muestra las primeras 30 filas del DataFrame `df_seleccion` utilizando el método `head(30)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e24952",
   "metadata": {},
   "source": [
    "## 3. Organización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Este código realiza una limpieza y estandarización en la columna `SpatialDim` de un DataFrame.\n",
    "#Se asegura de que la columna contenga cadenas de texto, filtra valores no numéricos para encontrar la moda (el valor más frecuente) y\n",
    "#reemplaza los valores numéricos con la moda. Finalmente, muestra los primeros 30 registros del DataFrame para verificar el resultado.\n",
    "\n",
    "\n",
    "# Asegurando que la columna tiene valores correctos\n",
    "# Aquí supongo que df es tu DataFrame\n",
    "df['SpatialDim'] = df['SpatialDim'].astype(str)\n",
    "\n",
    "# Filtrar los valores no numéricos y encontrar la moda\n",
    "moda_no_numerica = df[~df['SpatialDim'].str.isnumeric()]['SpatialDim'].mode()[0]\n",
    "\n",
    "# Reemplazar los valores numéricos por la moda\n",
    "df['SpatialDim'] = df['SpatialDim'].apply(lambda x: moda_no_numerica if x.isnumeric() else x)\n",
    "\n",
    "# Mostrar los primeros registros para verificar\n",
    "print(df_seleccion.head(30))\n",
    "\n",
    "### Explicación detallada\n",
    "#1. **Convertir valores a cadenas**:\n",
    "#   - Se asegura que todos los valores en la columna `SpatialDim` sean cadenas utilizando `astype(str)`. Esto es importante para garantizar que las operaciones posteriores funcionen correctamente.\n",
    "\n",
    "#2. **Filtrar valores no numéricos**:\n",
    "#   - Se utiliza el método `~df['SpatialDim'].str.isnumeric()` para seleccionar los valores que no son numéricos.\n",
    "#   - Se calcula la moda (el valor más frecuente) entre los valores no numéricos usando `.mode()[0]`.\n",
    "\n",
    "#3. **Reemplazar valores numéricos**:\n",
    "#   - La función `apply` evalúa cada elemento de la columna `SpatialDim`.\n",
    "#   - Si el valor es numérico (`x.isnumeric()`), lo reemplaza con la moda no numérica. De lo contrario, conserva el valor original.\n",
    "\n",
    "#4. **Mostrar resultado**:\n",
    "#   - Se imprimen las primeras 30 filas del DataFrame modificado para verificar los cambios realizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ddea5",
   "metadata": {},
   "source": [
    "### **3.1 Obtener años únicos por país en un DataFrame ordenado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27214e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los años únicos por cada valor de SpatialDim\n",
    "years_by_spatialdim = df[df['SpatialDimType'] == 'COUNTRY'].groupby('SpatialDim')['TimeDim'].unique()\n",
    "#Este fragmento de código years_by_spatialdim = df[df['SpatialDimType'] == 'COUNTRY'] filtra el DataFrame df para seleccionar solo las filas en las que el valor de la columna SpatialDimType sea 'COUNTRY'.\n",
    "#Después de filtrar, se agrupan los datos por los valores de la columna SpatialDim.\n",
    "#Para cada grupo (valor único en SpatialDim), se extraen los valores únicos de la columna TimeDim (los años), utilizando .unique()\n",
    "# Convertir a un DataFrame para una mejor presentación\n",
    "\n",
    "result = years_by_spatialdim.apply(sorted).reset_index(name='Years')\n",
    "#Los años (que son valores únicos) se ordenan para que el resultado esté en un formato ascendente\n",
    "#El resultado de la agrupación se convierte en un DataFrame, restableciendo el índice y renombrando la columna con los años como Years.\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(result)\n",
    "#Finalmente, se imprime el DataFrame resultante que contiene una columna SpatialDim y una columna Years, que contiene los años únicos asociados a cada valor de SpatialDim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa255d04",
   "metadata": {},
   "source": [
    "#### **3.2 COMPARAR AÑOS CON MAYOR Y MENOR PROMEDIO USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar promedios anuales\n",
    "year_averages = []\n",
    "#Se crea una lista vacía llamada year_averages,\n",
    "#que se usará para almacenar las tuplas que contienen el año y su respectivo promedio de la columna NumericValue.\n",
    "\n",
    "# Calcular promedio por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    values = list(df[df['TimeDim'] == year]['NumericValue'])\n",
    "    avg = sum(values) / len(values)\n",
    "    year_averages.append((year, avg))\n",
    "\n",
    "#Se itera sobre cada año único en la columna TimeDim (df['TimeDim'].unique()), lo que asegura que se procesa cada año presente en los datos.\n",
    "#Para cada año, se filtran los valores correspondientes de la columna NumericValue (df[df['TimeDim'] == year]['NumericValue']) y se convierten en una lista.\n",
    "#Se calcula el promedio de esos valores utilizando sum(values) / len(values).\n",
    "#Se agrega una tupla (año, promedio) a la lista year_averages\n",
    "\n",
    "# Ordenar por promedio\n",
    "year_averages.sort(key=lambda x: x[1])\n",
    "\n",
    "#Se ordena la lista year_averages en función del valor del promedio (el segundo elemento de cada tupla) utilizando sort() con una función lambda que extrae el segundo elemento (x[1]).\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Año con menor promedio: {year_averages[0][0]} - Promedio: {year_averages[0][1]:.2f}\")\n",
    "print(f\"Año con mayor promedio: {year_averages[-1][0]} - Promedio: {year_averages[-1][1]:.2f}\")\n",
    "\n",
    "#Se imprime el año con el menor promedio (year_averages[0]) y el año con el mayor promedio (year_averages[-1]).\n",
    "#El formato :.2f asegura que los promedios se muestren con dos decimales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b619d",
   "metadata": {},
   "source": [
    "#### **4.1 PREVALENCIA DE ANEMIA POR CADA AÑO EN LOS DIFERENTES PAISES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar registros donde SpatialDimType sea \"COUNTRY\"\n",
    "df_filtered = df[df['SpatialDimType'] == 'COUNTRY']\n",
    "#Este fragmento filtra el DataFrame df para seleccionar solo las filas en las que el valor de la columna SpatialDimType es igual a 'COUNTRY'.\n",
    "#El resultado es almacenado en un nuevo DataFrame df_filtered.\n",
    "\n",
    "# Calcular el promedio de prevalencia de anemia por país y año\n",
    "average_anemia = df_filtered.groupby(['SpatialDim', 'TimeDim'])['NumericValue'].mean().reset_index()\n",
    "#El DataFrame filtrado df_filtered se agrupa por las columnas SpatialDim (representando el país) y TimeDim (representando el año).\n",
    "#Para cada combinación de país y año, se calcula el promedio de la columna NumericValue, que en este caso se asume que representa la prevalencia de anemia.\n",
    "#El resultado de la agrupación y el cálculo del promedio se convierte en un nuevo DataFrame con reset_index() para restaurar el índice y hacerlo más accesible\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "average_anemia.columns = ['Country', 'Year', 'AveragePrevalence']\n",
    "\n",
    "#Las columnas del DataFrame average_anemia se renombran a Country, Year y AveragePrevalence para mejorar la legibilidad y comprensión de los datos.\n",
    "\n",
    "# Mostrar los primeros registros del resultado\n",
    "print(average_anemia.head(30))\n",
    "\n",
    "#Finalmente, se imprimen las primeras 30 filas del DataFrame average_anemia utilizando .head(30).\n",
    "#Esto proporciona una vista preliminar de los resultados del cálculo de los promedios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18537e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.1.1 Descargar el archivo en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import pandas as pd\n",
    "\n",
    "#Se importa la librería files de Google Colab, que permite interactuar con archivos en el entorno de Colab.\n",
    "#También se importa pandas como pd, que es utilizado para manejar y manipular el DataFrame average_anemia\n",
    "\n",
    "# ... (Your existing code to generate average_anemia DataFrame) ...\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "average_anemia.to_csv('PREVALENCIA_DE_ANEMIA_POR_CADA_AÑO_EN_LOS_DIFERENTES_PAISES.csv', index=False)\n",
    "#Se guarda el DataFrame average_anemia en un archivo CSV. El nombre del archivo será 'PREVALENCIA_DE_ANEMIA_POR_CADA_AÑO_EN_LOS_DIFERENTES_PAISES.csv'.\n",
    "#El argumento index=False asegura que el índice del DataFrame no se incluya en el archivo CSV, para evitar la creación de una columna extra con los índices de las filas.\n",
    "\n",
    "# Download the CSV file\n",
    "files.download('PREVALENCIA_DE_ANEMIA_POR_CADA_AÑO_EN_LOS_DIFERENTES_PAISES.csv')\n",
    "\n",
    "#El archivo CSV generado se descarga automáticamente al entorno local del usuario mediante la función files.download().\n",
    "#El nombre del archivo descargado será el mismo que el utilizado en el paso anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ceb18",
   "metadata": {},
   "source": [
    "#### **4.2 PROMEDIO DE PREVALENCIA POR PAÍS USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88983598",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Lista para almacenar los promedios\n",
    "country_averages = []\n",
    "#Se crea una lista vacía llamada country_averages que almacenará las tuplas con el nombre del país y su correspondiente promedio de prevalencia de anemia.\n",
    "\n",
    "# Agrupar por país y calcular el promedio manualmente\n",
    "for country in df['SpatialDim'].unique():\n",
    "    if df[df['SpatialDim'] == country]['SpatialDimType'].iloc[0] == 'COUNTRY':\n",
    "        prevalences = list(df[df['SpatialDim'] == country]['NumericValue'])\n",
    "        avg_prevalence = sum(prevalences) / len(prevalences)\n",
    "        country_averages.append((country, avg_prevalence))\n",
    "\n",
    "#Se itera sobre cada país único en la columna SpatialDim utilizando df['SpatialDim'].unique(). Esto asegura que cada país sea procesado una vez.\n",
    "#Dentro de la iteración, se verifica si el valor de SpatialDimType para ese país es 'COUNTRY' en la primera fila de los registros del país (df[df['SpatialDim'] == country]['SpatialDimType'].iloc[0]). Esto garantiza que solo se procesen los países.\n",
    "#Para cada país, se obtienen los valores de prevalencia de anemia de la columna NumericValue correspondientes a ese país, convirtiéndolos en una lista con list(df[df['SpatialDim'] == country]['NumericValue']).\n",
    "#Se calcula el promedio de las prevalencias utilizando la fórmula sum(prevalences) / len(prevalences).\n",
    "#Se agrega una tupla (país, promedio de prevalencia) a la lista country_averages.\n",
    "\n",
    "# Mostrar los resultados\n",
    "for country, avg in country_averages:\n",
    "    print(f\"{country}: {avg:.2f}\")\n",
    "#Después de calcular los promedios para todos los países, se itera sobre la lista country_averages, y para cada tupla (country, avg),\n",
    "# se imprime el país y su promedio de prevalencia de anemia, con el promedio mostrado con dos decimales usando :.2f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e31b5",
   "metadata": {},
   "source": [
    "### 4.2.1 Descargar el archivo en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame a partir de los resultados\n",
    "results_df = pd.DataFrame(country_averages, columns=['Country', 'AveragePrevalence'])\n",
    "#Se crea un nuevo DataFrame results_df a partir de la lista country_averages, que contiene tuplas con el país y su promedio de prevalencia de anemia.\n",
    "#Cada tupla tiene dos elementos: el nombre del país y el promedio de prevalencia.\n",
    "#Se especifican los nombres de las columnas como ['Country', 'AveragePrevalence'] para que el DataFrame tenga una estructura clara y fácil de entender\n",
    "\n",
    "# Guardar el DataFrame como archivo CSV\n",
    "results_df.to_csv('PROMEDIO_DE_PREVALENCIA_POR_PAÍS_USANDO_LISTAS_gho.csv', index=False)\n",
    "#El DataFrame results_df se guarda en un archivo CSV con el nombre 'PROMEDIO_DE_PREVALENCIA_POR_PAÍS_USANDO_LISTAS_gho.csv'.\n",
    "#El parámetro index=False asegura que el índice del DataFrame no se incluya como una columna adicional en el archivo CSV, resultando en un archivo más limpio y fácil de leer.\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('PROMEDIO_DE_PREVALENCIA_POR_PAÍS_USANDO_LISTAS_gho.csv')\n",
    "\n",
    "#Se importa la librería files de Google Colab, que permite interactuar con archivos en el entorno de Colab.\n",
    "#La función files.download() se utiliza para descargar el archivo CSV generado a la máquina local del usuario.\n",
    "#Esto facilita la transferencia del archivo desde Colab a un entorno local para su uso posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ad67c",
   "metadata": {},
   "source": [
    "#### **4.3 RANGO DE PREVALENCIA POR AÑO USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear una pila para almacenar rangos por año\n",
    "ranges_stack = []\n",
    "#Se crea una lista vacía llamada ranges_stack,\n",
    "#que se usará para almacenar tuplas que contienen el año, el valor mínimo, el valor máximo y el rango (diferencia entre el máximo y el mínimo) de los valores de prevalencia para cada año.\n",
    "\n",
    "# Agrupar por año\n",
    "# Iterar sobre los años únicos en la columna 'TimeDim' para calcular los valores por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    # Obtener los valores de prevalencia de anemia para el año actual\n",
    "    values = list(df[df['TimeDim'] == year]['NumericValue'])\n",
    "    # Calcular el valor máximo y mínimo para el año\n",
    "    max_val = max(values)\n",
    "    min_val = min(values)\n",
    "    # Calcular el rango como la diferencia entre el valor máximo y el mínimo\n",
    "    year_range = max_val - min_val\n",
    "    # Almacenar los resultados (año, mínimo, máximo y rango) en la lista\n",
    "    ranges_stack.append((year, min_val, max_val, year_range))\n",
    "\n",
    "# Crear un DataFrame con las columnas correspondientes\n",
    "ranges_df = pd.DataFrame(ranges_stack, columns=['Año', 'Min', 'Max', 'Rango'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(ranges_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1d4f5",
   "metadata": {},
   "source": [
    "###### **4.3.1 DESCARGAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ea9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "ranges_df.to_csv('RANGO_DE_PREVALENCIA_POR_AÑO_USANDO_LISTAS_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('RANGO_DE_PREVALENCIA_POR_AÑO_USANDO_LISTAS_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36e003",
   "metadata": {},
   "source": [
    "#### **4.4 CALCULAR LA MEDIANA DE PREVALENCIA USANDO COLAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add369b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "# Calcular la mediana por año\n",
    "medians_queue = deque()\n",
    "#Se importa deque de la librería collections.\n",
    "#deque es una estructura de datos eficiente para agregar y eliminar elementos de ambos extremos de una lista.\n",
    "#En este caso, se usa para almacenar los resultados de las medianas por año.\n",
    "\n",
    "# Agrupar por año\n",
    "# Iterar sobre los años únicos en la columna 'TimeDim' para calcular la mediana por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    # Obtener y ordenar los valores de prevalencia de anemia para el año actual\n",
    "    values = sorted(list(df[df['TimeDim'] == year]['NumericValue']))\n",
    "    # Calcular el número de valores\n",
    "    n = len(values)\n",
    "    # Calcular la mediana según si el número de valores es par o impar\n",
    "    if n % 2 == 0:  # Si hay un número par de valores\n",
    "        median = (values[n // 2 - 1] + values[n // 2]) / 2\n",
    "    else:  # Si hay un número impar de valores\n",
    "        median = values[n // 2]\n",
    "    # Almacenar el año y la mediana en la cola\n",
    "    medians_queue.append((year, median))\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "medians_df = pd.DataFrame(medians_queue, columns=['Año', 'Mediana'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(medians_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff3044",
   "metadata": {},
   "source": [
    "##### **4.4.1 GUARDAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f447e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "medians_df.to_csv('LA_MEDIANA_DE_PREVALENCIA_USANDO_COLAS_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('LA_MEDIANA_DE_PREVALENCIA_USANDO_COLAS_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f9472",
   "metadata": {},
   "source": [
    "#### **4.5 COMPARAR PAÍSES CON MÁS ESTABILIDAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1912b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista vacía para almacenar el rango de prevalencia por país\n",
    "country_ranges = []\n",
    "\n",
    "# Calcular rango por país\n",
    "for country in df['SpatialDim'].unique():\n",
    "    # Verificar que el tipo de dimensión espacial sea 'COUNTRY'\n",
    "    if df[df['SpatialDim'] == country]['SpatialDimType'].iloc[0] == 'COUNTRY':\n",
    "        # Obtener los valores de prevalencia de anemia para el país\n",
    "        values = list(df[df['SpatialDim'] == country]['NumericValue'])\n",
    "        # Calcular el rango como la diferencia entre el valor máximo y el mínimo\n",
    "        country_range = max(values) - min(values)\n",
    "        # Almacenar el país y su rango en la lista\n",
    "        country_ranges.append((country, country_range))\n",
    "\n",
    "# Ordenar por rango\n",
    "country_ranges.sort(key=lambda x: x[1])\n",
    "\n",
    "# Convertir a un DataFrame\n",
    "ranges_df = pd.DataFrame(country_ranges, columns=['País', 'Rango'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(ranges_df)  # Mostrar los 60 países más estables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651cf962",
   "metadata": {},
   "source": [
    "#### **4.5.1 DESCARGAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "ranges_df.to_csv('COMPARAR_PAÍSES_CON_MÁS_ESTABILIDAD_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('COMPARAR_PAÍSES_CON_MÁS_ESTABILIDAD_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8521f3",
   "metadata": {},
   "source": [
    "## 5. Visualización de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594410b3",
   "metadata": {},
   "source": [
    "### 5.1 Paquetes requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddadfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - pandas: libreria para la manipulación y análisis de datos.\n",
    "import pandas as pd\n",
    "# - matplotlib: es una librería utilizada para crear visualizaciones estáticas, animadas e interactivas.\n",
    "# - pyplot: proporciona una interfaz de scripting similar a MATLAB.\n",
    "import matplotlib.pyplot as plt\n",
    "# - numpy: librería que soporta arrays y matrices multidimensionales.\n",
    "import numpy as np\n",
    "# - ipywidgets: para crear widgets interactivos en Jupyter Notebooks para mejorar la interactividad de las celdas.\n",
    "import ipywidgets as widgets\n",
    "# - plotly.express: para hacer graficos interactivos, no funcionaba en mapamundi.\n",
    "import plotly.express as px \n",
    "# - interact: facilita la creación de widgets interactivos que se actualizan dinámicamente en función de las entradas del usuario.\n",
    "from ipywidgets import interact\n",
    "# - display: se utiliza para mostrar objetos en la salida del Jupyter Notebook.\n",
    "# - clear_output: se utiliza para limpiar la salida.\n",
    "from IPython.display import display, clear_output\n",
    "# - Wedge: se utiliza para crear figuras en forma de cuña en los gráficos, como en gráficos circulares o de pastel.\n",
    "from matplotlib.patches import Wedge\n",
    "# - table: se utiliza para mostrar DataFrames de pandas como tablas en gráficos matplotlib.\n",
    "from pandas.plotting import table\n",
    "# - make_subplots: para poder poner subgraficos categorizados.\n",
    "from plotly.subplots import make_subplots\n",
    "# - go: contiene herramientas para crear gráficos complejos y detallados con plotly.\n",
    "import plotly.graph_objects as go\n",
    "# - random: para generar números aleatorios en Python.\n",
    "import random\n",
    "# - seaborn: proporciona una interfaz de alto nivel para dibujar gráficos estadísticos atractivos y complejos.\n",
    "import seaborn as sns\n",
    "\n",
    "#Para el mapamundi\n",
    "# se instala la libreria folium para crear mapas interactivos y visualizaciones geoespaciales.\n",
    "#!pip install folium\n",
    "#import folium\n",
    "\n",
    "# se instala la libreria geopandas para facilitar el trabajo con datos geoespaciales.\n",
    "#!pip install geopandas\n",
    "# se instala la libreria geopy para facilitar la geocodificación (convertir direcciones en coordenadas geográficas) y la realización de cálculos geográficos.\n",
    "#!pip install geopy\n",
    "\n",
    "#No se podía poner el filtro dinámico, gpt comentó instalar --> #jupyter nbextension enable --py widgetsnbextension\n",
    "#generaba un error porque la versión de Jupyter no lo soportaba.\n",
    "#Por lo que se actualizo con este código --> pip install --upgrade jupyter jupyterlab ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5e3e5",
   "metadata": {},
   "source": [
    "### 5.2 Anemia infantil a través del tiempo (2000-2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803328ed",
   "metadata": {},
   "source": [
    "#### 5.2.1 Anemia infantil a nivel mundial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuente: Banco Mundial\n",
    "\n",
    "# cargar datos: utiliza pandas para leer el archivo CSV llamado world_bank_anemia_mundial_listo.csv y almacenarlo en un DataFrame llamado data_historico\n",
    "data_historico = pd.read_csv(r\"world_bank_anemia_mundial_listo.csv\")\n",
    "\n",
    "# crea un gráfico de líneas utilizando plotly.express.\n",
    "fig = px.line(\n",
    "    data_historico, # DataFrame que contiene los datos.\n",
    "    x=\"year\", # define el eje X como la columna \"year\".\n",
    "    y=\"prevalencia (%)\", # define el eje Y como la columna \"prevalencia (%)\".\n",
    "    markers=True, # agrega marcadores a los puntos de datos.\n",
    "    title=\"Prevalencia de anemia (en %), 2000-2019\", # agrega titulo al gráfico.\n",
    "    labels={\"year\": \"Año\", \"prevalencia (%)\": \"Prevalencia (%)\"} # etiquetas personalizadas para los ejes.\n",
    ")\n",
    "\n",
    "# personalizar las trazas del gráfico.\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"Prevalencia: %{y:.1f}%\", # etiquetas personalizadas para los ejes.\n",
    "    line=dict(color=\"blue\"), # cambia el color de la línea a azul.\n",
    "    marker=dict(size=8) # ajusta el tamaño de los marcadores a 8.\n",
    ")\n",
    "# personalizar el diseño del gráfico.\n",
    "fig.update_layout(\n",
    "    yaxis=dict(title=\"Prevalencia (%)\", range=[10, 50]), # título del eje Y y rango de valores.\n",
    "    xaxis=dict(\n",
    "        tickangle=-90,  # rotar las etiquetas de los años.\n",
    "        tickmode='array',  # mostrar todos los años.\n",
    "        tickvals=data_historico[\"year\"],  # asegura que todos los años se muestren.\n",
    "        title=\"\"  # eliminar el título del eje X.\n",
    "    ),\n",
    "    title=dict(font=dict(size=18)), # tamaño de fuente del título del gráfico.\n",
    "    template=\"simple_white\" # estilo del gráfico.\n",
    ")\n",
    "\n",
    "# mostrar el gráfico interactivo en la salida del notebook.\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a17f4",
   "metadata": {},
   "source": [
    "#### 5.2.2 Prevalencia de anemia infantil según nivel de ingreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuente: Banco Mundial\n",
    "\n",
    "# cargar datos: utiliza pandas para leer el archivo CSV llamado world_bank_anemia_ingresos_listo.csv y almacenarlo en un DataFrame llamado data_nivelingresos.\n",
    "data_nivelingresos = pd.read_csv(r\"world_bank_anemia_ingresos_listo.csv\")\n",
    "\n",
    "# convertir los valores de la columna 'year' a numéricos usando la función pd.to_numeric, reemplazando cualquier valor no convertible con NaN.\n",
    "data_nivelingresos['year'] = pd.to_numeric(data_nivelingresos['year'], errors='coerce')\n",
    "# elimina las filas con datos faltantes en las columnas 'year' y 'prevalencia (%)' usando la función dropna.\n",
    "data_nivelingresos = data_nivelingresos.dropna(subset=['year', 'prevalencia (%)'])\n",
    "# convertir los valores de la columna 'year' a enteros usando la función astype(int)\n",
    "data_nivelingresos['year'] = data_nivelingresos['year'].astype(int)\n",
    "\n",
    "# crea un gráfico de líneas interactivo utilizando plotly.express.\n",
    "fig = px.line(data_nivelingresos, # DataFrame que contiene los datos.\n",
    "              x='year', # define el eje X como la columna 'year'.\n",
    "              y='prevalencia (%)', # define el eje Y como la columna 'prevalencia (%)'.\n",
    "              color='nivel de ingresos', # colorea las líneas según el nivel de ingresos.\n",
    "              markers=True, # agrega marcadores a los puntos de datos.\n",
    "              title='Prevalencia histórica de anemia por nivel de ingresos', # título del gráfico.\n",
    "              labels={'prevalencia (%)': 'Prevalencia (%)', 'year': 'Año'}) # etiquetas personalizadas para los ejes.\n",
    "\n",
    "# eliminar la leyenda del gráfico.\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# añadir el nombre del nivel de ingresos cerca del último punto disponible y alineado verticalmente.\n",
    "y_offset = 0.1  # ajuste de distancia entre los nombres de los niveles.\n",
    "for i, level in enumerate(data_nivelingresos['nivel de ingresos'].unique()):\n",
    "    level_data = data_nivelingresos[data_nivelingresos['nivel de ingresos'] == level]\n",
    "    last_row = level_data[level_data['year'] == level_data['year'].max()]\n",
    "    if not last_row.empty:\n",
    "        last_year = last_row['year'].values[0]\n",
    "        last_value = last_row['prevalencia (%)'].values[0]\n",
    "        \n",
    "        # añadir la anotación en la posición deseada.\n",
    "        fig.add_annotation(\n",
    "            x=last_year + 0.4,  # posición horizontal cerca del último punto.\n",
    "            y=last_value + (y_offset * i),  # posición vertical con ajuste para separar los nombres.\n",
    "            text=level,  # texto con el nombre del nivel de ingresos.\n",
    "            showarrow=False,  # sin flecha.\n",
    "            font=dict(size=10),  # tamaño de la fuente.\n",
    "            xanchor='left',  # alineación del texto a la izquierda.\n",
    "            align='left',  # alineación del texto a la izquierda.\n",
    "        )\n",
    "\n",
    "# mejorar el diseño del gráfico.\n",
    "# mode='lines+markers': asegura que las líneas y los marcadores se muestren.\n",
    "# hovertemplate='Prevalencia: %{y}': solo muestra la prevalencia en el tooltip.\n",
    "fig.update_traces(mode='lines+markers', hovertemplate='Prevalencia: %{y}')\n",
    "fig.update_layout(\n",
    "    xaxis_title='Año', # título del eje X.\n",
    "    yaxis_title='Prevalencia (%)', # título del eje Y.\n",
    "    xaxis=dict(\n",
    "        title=None,  # quitar el título del eje X.\n",
    "        tickmode='array', # define el modo de los ticks.\n",
    "        tickvals=sorted(\n",
    "            data_nivelingresos['year'].unique()), # asegura que todos los años se muestren.\n",
    "        showline=True, # muestra la línea del eje.\n",
    "        linecolor='black', # color de la línea del eje.\n",
    "        ticks='outside',  # muestra las marcas de graduación hacia afuera.\n",
    "        tickwidth=1,  # define el grosor de las marcas.\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "            showline=True,  # muestra la línea del eje Y.\n",
    "            linewidth=1,  # define el grosor de la línea.\n",
    "            linecolor='black'  # define el color de la línea.\n",
    "    ),\n",
    "    xaxis_tickangle=-90,  # rota las etiquetas del eje X 90 grados.\n",
    "    plot_bgcolor='white', # define el color de fondo del gráfico.\n",
    "    font=dict(size=12), # define el tamaño de la fuente.\n",
    "    title_x=0.5,  # centrar el título\n",
    ")\n",
    "\n",
    "# mostrar el gráfico interactivo en la salida del notebook.\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b35b9",
   "metadata": {},
   "source": [
    "#### 5.3.3 Prevalencia de anemia infantil por país (Multiselección) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27580ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuente: Banco Mundial\n",
    "\n",
    "# Cargar datos: Utiliza pandas para leer el archivo CSV llamado world_bank_anemia_ingresos_listo.csv y almacenarlo en un DataFrame llamado data_historico_pais_est.\n",
    "data_historico_pais_est = pd.read_csv(r\"world_bank_anemia_paises_listo.csv\")\n",
    "data_historico_pais_est['year'] = pd.to_numeric(data_historico_pais_est['year'], errors='coerce')\n",
    "data_historico_pais_est['year'] = data_historico_pais_est['year'].astype(int)\n",
    "\n",
    "# Obtener una lista de países únicos y los ordena alfabéticamente.\n",
    "countries = sorted(data_historico_pais_est['pais'].unique())\n",
    "\n",
    "# Asignar un color único a cada país.\n",
    "def assign_colors(countries): # asigna un color aleatorio (en formato RGBA) a cada país y devuelve un diccionario con los colores.\n",
    "    colors = {}\n",
    "    for country in countries:\n",
    "        colors[country] = f'rgba({random.randint(0,255)},{random.randint(0,255)},{random.randint(0,255)}, 0.8)'\n",
    "    return colors\n",
    "\n",
    "colors = assign_colors(countries)\n",
    "\n",
    "# Función para completar los años faltantes y hacer líneas continuas.\n",
    "def completar_anios(data, country):\n",
    "    # Filtrar datos del país.\n",
    "    country_data = data[data['pais'] == country].copy()\n",
    "\n",
    "    # Generar el rango completo de años.\n",
    "    all_years = pd.DataFrame({'year': range(country_data['year'].min(), country_data['year'].max() + 1)})\n",
    "\n",
    "    # Unir con los datos originales y llenar los valores faltantes mediante interpolación.\n",
    "    completed_data = pd.merge(all_years, country_data, on='year', how='left')\n",
    "    completed_data['prevalencia (%)'] = completed_data['prevalencia (%)'].interpolate()\n",
    "\n",
    "    # Añadir el nombre del país.\n",
    "    completed_data['pais'] = country\n",
    "    return completed_data\n",
    "\n",
    "# Función para graficar prevalencias históricas de anemia basadas en los países seleccionados.\n",
    "def plot_selected_countries_plotly(countries_selected):\n",
    "    if not countries_selected:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Por favor selecciona al menos un país.\")\n",
    "        return\n",
    "\n",
    "    # Crear una figura.\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for country in countries_selected:\n",
    "        # Completar los años faltantes.\n",
    "        country_data = completar_anios(data_historico_pais_est, country)\n",
    "\n",
    "        # Dividir los datos en tres segmentos.\n",
    "        before_2020 = country_data[country_data['year'] < 2020]\n",
    "        between_2020_2030 = country_data[(country_data['year'] >= 2020) & (country_data['year'] <= 2030)]\n",
    "        after_2030 = country_data[country_data['year'] > 2030]\n",
    "\n",
    "        # Obtener el color para el país.\n",
    "        country_color = colors[country]\n",
    "\n",
    "        # Añadir el segmento antes de 2020 (línea continua).\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=before_2020['year'],\n",
    "                y=before_2020['prevalencia (%)'],\n",
    "                mode='lines+markers',\n",
    "                name=country,\n",
    "                hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",  # Personalizar el tooltip sin el símbolo '%'.\n",
    "                line=dict(color=country_color)  # Usamos el color del país.\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Añadir el segmento entre 2020 y 2030 (línea punteada).\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=between_2020_2030['year'],\n",
    "                y=between_2020_2030['prevalencia (%)'],\n",
    "                mode='lines+markers',\n",
    "                name=country,\n",
    "                hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",  # Personalizar el tooltip sin el símbolo '%'.\n",
    "                line=dict(dash='dot', color=country_color)  # Usamos el mismo color del país para la línea punteada.\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Añadir el segmento después de 2030 (línea continua).\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=after_2030['year'],\n",
    "                y=after_2030['prevalencia (%)'],\n",
    "                mode='lines+markers',\n",
    "                name=country,\n",
    "                hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",  # Personalizar el tooltip sin el símbolo '%'.\n",
    "                line=dict(color=country_color)  # Usamos el color del país.\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Colocar el nombre del país ligeramente desplazado a la derecha de 2030.\n",
    "        year_2030_data = country_data[country_data['year'] == 2019]\n",
    "        if not year_2030_data.empty:\n",
    "            # Obtenemos el valor de prevalencia para 2030.\n",
    "            prev_2030 = year_2030_data['prevalencia (%)'].values[0]\n",
    "            fig.add_annotation(\n",
    "                x=2019 + 1.2,  # Desplazamos un poco a la derecha de 2030.\n",
    "                y=prev_2030,\n",
    "                text=country,\n",
    "                showarrow=False,\n",
    "                font=dict(size=10, color='black'),\n",
    "                xanchor='left',  # Alineación del texto a la izquierda.\n",
    "                align='left'  # Alineación del texto a la izquierda.\n",
    "            )\n",
    "\n",
    "    # Ajustar el diseño del gráfico.\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Prevalencia histórica de anemia',\n",
    "            'x': 0.5,  # Centrar el título.\n",
    "            'xanchor': 'center',  # Asegurar que el anclaje sea en el centro.\n",
    "        },\n",
    "        xaxis=dict(\n",
    "            title=None,  # Quitar el título del eje X.\n",
    "            tickangle=-90, # Rotar las etiquetas del eje X 90 grados.\n",
    "            showline=True, # Mostrar la línea del eje X.\n",
    "            linecolor='black', # Definir el color de la línea del eje X.\n",
    "            ticks='outside',  # Mostrar marcas de graduación principales hacia el exterior.\n",
    "            tickwidth=1,  # Grosor de las marcas de graduación.\n",
    "            tickvals=list(\n",
    "                range(\n",
    "                    data_historico_pais_est['year'].min(), \n",
    "                    data_historico_pais_est['year'].max() + 1\n",
    "                )\n",
    "            )  # Asegurar que todos los años estén en el eje X.\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showline=True,  # Mostrar la línea del eje Y.\n",
    "            linewidth=1,  # Definir el grosor de la línea.\n",
    "            linecolor='black'  # Definir el color de la línea.\n",
    "        ),\n",
    "        showlegend=False,  # Quitar la leyenda.\n",
    "        yaxis_title='Prevalencia (%)', # Definir el título del eje Y.\n",
    "        legend_title='Países', # Definir el titulo de la leyenda\n",
    "        template='plotly_white', # Aplica la plantilla de diseño 'plotly_white'.\n",
    "        width=850  # Establece el ancho del gráfico a 850 píxeles.\n",
    "    )\n",
    "\n",
    "    # Mostrar el gráfico en el área de salida.\n",
    "    with output_area:\n",
    "        # Limpia la salida existente en el área de salida antes de mostrar el nuevo gráfico.\n",
    "        clear_output(wait=True)\n",
    "        # Muestra el gráfico interactivo.\n",
    "        fig.show()\n",
    "\n",
    "# Función para manejar la actualización dinámica del gráfico.\n",
    "def update_plot(change=None):\n",
    "    # Obtener los países seleccionados.\n",
    "    selected_countries = [cb.description for cb in checkboxes if cb.value]\n",
    "\n",
    "    # Actualizar el gráfico.\n",
    "    plot_selected_countries_plotly(selected_countries)\n",
    "\n",
    "# Crear checkboxes para cada país.\n",
    "# Usar ipywidgets para crear una lista de checkboxes, donde cada checkbox corresponde a un país y está inicialmente desmarcada\n",
    "checkboxes = [widgets.Checkbox(value=False, description=country) for country in countries]\n",
    "\n",
    "# Agregar un evento a cada checkbox.\n",
    "for cb in checkboxes:\n",
    "    cb.observe(update_plot, names='value')\n",
    "\n",
    "# Crear un contenedor para los checkboxes con barra de desplazamiento.\n",
    "checkbox_box = widgets.VBox(checkboxes, layout=widgets.Layout(overflow='auto', height='300px', width='200px'))\n",
    "\n",
    "# Crear un área de salida para el gráfico.\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Mostrar los checkboxes y el área de salida.\n",
    "display(widgets.HBox([checkbox_box, output_area]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7c238",
   "metadata": {},
   "source": [
    "#### 5.3.4 Clasificación de la importancia de la anemia infantil en la salud pública, por país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d728874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuente: Banco Mundial\n",
    "\n",
    "# Cargar datos: usar pandas para leer el archivo CSV llamado dhs_anemia_final.csv y almacenarlo en un data frame llamado data_ind_anemia\n",
    "data_ind_anemia = pd.read_csv(r\"dhs_anemia_final.csv\")\n",
    "# Usar la funcion drop para eliminar ciertas columnas del DataFrame.\n",
    "data_ind_anemia.drop(data_ind_anemia.columns[[3, 4, 5, 6, 7, 8, 9, 10]], axis=1, inplace=True)\n",
    "# Renombrar las columnas del DataFrame para mayor claridad.\n",
    "data_ind_anemia.rename(\n",
    "    columns={\n",
    "    'Valor Cualquier': 'Valor\\nReal',\n",
    "    'Valor Severo' : 'Valor\\nsevero',\n",
    "    '# Encuestas (sev, sin ponderar)': '# Encuestas\\n(sin ponderar)',\n",
    "    '# Encuestas (sev, ponderadas)': '# Encuestas\\n(ponderadas)'\n",
    "    }, \n",
    "    inplace=True) \n",
    "\n",
    "# Función para crear un velocímetro estilizado.\n",
    "def plot_stylized_gauge(ax, value, country, min_val=0, max_val=100):\n",
    "    levels = [\"Baja\", \"Moderada\", \"Alta\"] # Niveles del velocímetro.\n",
    "    colors = [\"#32CD32\", \"#FFD700\", \"#FF4D4D\"]  # Colores verde, amarillo y rojo.\n",
    "    thresholds = [0, 20, 40, 100] # Umbrales de los niveles.\n",
    "\n",
    "    # Definir el ángulo de inicio y fin del semicírculo.\n",
    "    start_angle = 180  # Inicio del semicírculo en 180° (sentido antihorario).\n",
    "    end_angle = 0 # Fin del semicírculo.\n",
    "\n",
    "    for i, (level, color) in enumerate(zip(levels, colors)):\n",
    "\n",
    "        # Calcular los ángulos para cada nivel en función de los umbrales.\n",
    "        start = start_angle - (start_angle - end_angle) * (thresholds[i + 1] - min_val) / (max_val - min_val)\n",
    "        end = start_angle - (start_angle - end_angle) * (thresholds[i] - min_val) / (max_val - min_val)\n",
    "        \n",
    "        # Dibujar sección usando Wedge (un sector circular).\n",
    "        wedge = Wedge(center=(0, 0), r=1, theta1=start, theta2=end, facecolor=color, edgecolor=\"white\")\n",
    "        ax.add_patch(wedge)\n",
    "\n",
    "        # Posicionar texto indicando los niveles.\n",
    "        mid_angle = (start + end) / 2\n",
    "        x_text = np.cos(np.radians(mid_angle)) * 0.7\n",
    "        y_text = np.sin(np.radians(mid_angle)) * 0.7\n",
    "        ax.text(x_text, y_text, level, ha=\"center\", va=\"center\", fontsize=14, color=\"white\")\n",
    "\n",
    "    # Dibujar la aguja indicando el valor actual (en sentido antihorario).\n",
    "    value_angle = start_angle - (start_angle - end_angle) * (value - min_val) / (max_val - min_val)\n",
    "    x_needle = np.cos(np.radians(value_angle)) * 0.9\n",
    "    y_needle = np.sin(np.radians(value_angle)) * 0.9\n",
    "    ax.plot([0, x_needle], [0, y_needle], color=\"black\", linewidth=2)\n",
    "\n",
    "    # Agregar el valor actual y el nombre del país en el centro del velocímetro.\n",
    "    ax.text(0, -0.2, f\"{value}\", ha=\"center\", va=\"center\", fontsize=18, weight=\"bold\")\n",
    "    ax.text(0, -0.35, country, ha=\"center\", va=\"center\", fontsize=12, style=\"italic\")\n",
    "\n",
    "    # Ajustar los límites y ocultar ejes.\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-0.0025, 1.2)  # Mostrar solo el semicírculo superior.\n",
    "    ax.set_aspect('equal')  # Relación de aspecto 1:1 para un semicírculo perfecto.\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Función para graficar la tabla de prevalencia.\n",
    "def plot_paises(paises):\n",
    "    # Filtrar los datos para el país seleccionado.\n",
    "    data_paises = data_ind_anemia[data_ind_anemia['Pais'] == paises]\n",
    "    \n",
    "    # Obtener el valor \"severo\" del año más reciente.\n",
    "    latest_year = data_paises['Year'].max()\n",
    "    severe_value = data_paises[data_paises['Year'] == latest_year]['Valor\\nReal'].values[0] \n",
    "\n",
    "    # Crear figura con dos subgráficos (uno para la tabla y otro para el velocímetro).\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))  # Tamaño de la figura.\n",
    "\n",
    "    # Mostrar la tabla en el primer subgráfico.\n",
    "    ax1.axis('off')  # Apagar los ejes para la tabla.\n",
    "    \n",
    "    # Crear la tabla usando ax.table.\n",
    "    table_data = data_paises.values\n",
    "    table_columns = data_paises.columns\n",
    "    table = ax1.table(cellText=table_data, colLabels=table_columns, loc='center', cellLoc='center')\n",
    "\n",
    "    # Personalizar el estilo de la tabla.\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "\n",
    "    # Ajustar las celdas (bordes, colores, tamaño).\n",
    "    for (i, j), cell in table.get_celld().items():\n",
    "        cell.set_edgecolor('black')\n",
    "        cell.set_linewidth(1.2)\n",
    "        if i == 0:  # Encabezados.\n",
    "            cell.set_height(0.25)\n",
    "            cell.set_facecolor('#4CAF50')\n",
    "            cell.set_text_props(ha='center', va='center', color='white', weight='bold', fontsize=10)\n",
    "        else:  # Filas de datos.\n",
    "            cell.set_facecolor('#f9f9f9')\n",
    "            cell.set_text_props(color='black', fontsize=10)\n",
    "        if j == 0:  # Primera columna.\n",
    "            cell.set_facecolor('#d3d3d3')\n",
    "            cell.set_text_props(color='black', weight='bold')\n",
    "            \n",
    "    # Ajustar el ancho de las columnas basado en el texto.\n",
    "    col_widths = [max(len(str(cell)) for cell in data_paises[col].tolist() + [col]) for col in data_paises.columns]\n",
    "    total_width = sum(col_widths)\n",
    "    for i, width in enumerate(col_widths):\n",
    "        table.auto_set_column_width(i)  # Ajustar automáticamente.\n",
    "        table.get_celld()[(0, i)].set_width(width / total_width * 2)  # Normalizar al tamaño del gráfico\n",
    "\n",
    "    # Mostrar el velocímetro en el segundo subgráfico.\n",
    "    value = data_paises['Valor\\nReal'].values[0]  # Suponiendo que 'Valor Cualquier' es el valor que usas.\n",
    "    plot_stylized_gauge(ax2, severe_value, paises)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Crear el selector interactivo\n",
    "# Genera una interfaz interactiva que permite seleccionar países para mostrar la tabla y el velocímetro.\n",
    "lista_paises = data_ind_anemia['Pais'].unique()\n",
    "interact(plot_paises, paises=lista_paises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d920f0f1",
   "metadata": {},
   "source": [
    "### 5.3. **SEGUNDA PARTE = MAPAMUNDI INTERACTIVO (niveles máximos y mínimos de anemia infantil por país y años respectivos)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ad6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - pandas: para manipular datos tabulares.\n",
    "import pandas as pd\n",
    "# - folium: para crear mapas interactivos.\n",
    "import folium\n",
    "# - Nominatim de geopy: para obtener coordenadas geográficas.\n",
    "from geopy.geocoders import Nominatim\n",
    "# - tqdm: para mostrar barras de progreso.\n",
    "from tqdm import tqdm\n",
    "# - json: para manejar datos en formato JSON.\n",
    "import json\n",
    "# - os: para interactuar con el sistema de archivos.\n",
    "import os\n",
    "\n",
    "# Cargar datos desde un archivo CSV llamado 'world_bank_continentes.csv' y almacenarlo en un DataFrame llamado df.\n",
    "df = pd.read_csv(r\"world_bank_continentes.csv\")\n",
    "print(df.head()) # Muestra las primeras filas del DataFrame para verificar la estructura de los datos.\n",
    "\n",
    "# Configurar el geolocalizador usando la API de Nominatim.\n",
    "geolocator = Nominatim(user_agent=\"geoapi\")\n",
    "\n",
    "# Definir una función para obtener coordenadas de un país y almacenarlas en un archivo de caché para optimizar futuras consultas.\n",
    "def obtener_coordenadas(pais, cache_file=\"coordenadas_cache.json\"):\n",
    "    # Comprueba si ya existe un archivo de caché.\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, 'r') as f:\n",
    "            cache = json.load(f) # Carga el contenido del archivo JSON en un diccionario.\n",
    "    else:\n",
    "        cache = {} # Crea un diccionario vacío si el archivo no existe.\n",
    "\n",
    "    # Si el país ya está en el caché, retorna sus coordenadas.\n",
    "    if pais in cache:\n",
    "        return cache[pais]\n",
    "\n",
    "    try:\n",
    "        location = geolocator.geocode(pais) # Obtiene la ubicación del país usando Nominatim.\n",
    "        if location:\n",
    "            coordenadas = (location.latitude, location.longitude) # Obtiene latitud y longitud.\n",
    "            cache[pais] = coordenadas  # Almacena las coordenadas en el caché.\n",
    "            # Guarda el caché en un archivo JSON para futuras búsquedas.\n",
    "            with open(cache_file, 'w') as f:\n",
    "                json.dump(cache, f)\n",
    "            return coordenadas\n",
    "        else:\n",
    "            return None, None # Si no se encuentra el país, retorna valores nulos.\n",
    "    except Exception as e:\n",
    "        print(f\"Error obteniendo coordenadas para {pais}: {e}\") # Maneja errores de geolocalización.\n",
    "        return None, None\n",
    "\n",
    "# Habilitar el uso de barras de progreso con pandas.\n",
    "tqdm.pandas()  \n",
    "\n",
    "# Aplicar la función de obtención de coordenadas a cada fila en la columna 'country.value'.\n",
    "coordenadas = df[\"country.value\"].progress_apply(obtener_coordenadas)\n",
    "\n",
    "# Desempaquetar las coordenadas en columnas separadas de latitud y longitud.\n",
    "df[\"latitude\"], df[\"longitude\"] = zip(*coordenadas)\n",
    "\n",
    "# Mostrar las columnas relevantes para verificar si las coordenadas se agregaron correctamente.\n",
    "print(df[['country.value', 'latitude', 'longitude']].head())\n",
    "\n",
    "# Filtrar filas sin coordenadas (si es necesario).\n",
    "df = df.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "\n",
    "# Agrupar datos por país y obtener el máximo y mínimo de prevalencia.\n",
    "df_grouped = df.groupby('country.value').agg(\n",
    "    max_prevalencia=('value', 'max'), # Máximo valor de prevalencia.\n",
    "    min_prevalencia=('value', 'min') # Mínimo valor de prevalencia.\n",
    ").reset_index()\n",
    "\n",
    "# Obtener los años correspondientes para los valores máximos y mínimos.\n",
    "df_max_min_years = df.loc[df.groupby('country.value')['value'].idxmax()][['country.value', 'date']].rename(columns={'date': 'max_year'})\n",
    "df_min_years = df.loc[df.groupby('country.value')['value'].idxmin()][['country.value', 'date']].rename(columns={'date': 'min_year'})\n",
    "\n",
    "# Combina los datos agrupados con los años y las coordenadas.\n",
    "df_map = pd.merge(df_grouped, df_max_min_years, on='country.value')\n",
    "df_map = pd.merge(df_map, df_min_years, on='country.value')\n",
    "df_map = pd.merge(df_map, df[['country.value', 'latitude', 'longitude']].drop_duplicates(), on='country.value')\n",
    "\n",
    "# Verificar si se unieron correctamente las coordenadas y los valores.\n",
    "print(df_map[['country.value', 'latitude', 'longitude', 'max_prevalencia', 'max_year', 'min_prevalencia', 'min_year']].head())\n",
    "\n",
    "# Crear un mapa base centrado en coordenadas globales con un nivel de zoom inicial.\n",
    "world_map = folium.Map(location=[0, 0], zoom_start=2)\n",
    "\n",
    "# Agregar marcadores agrupados con MarkerCluster.\n",
    "from folium.plugins import MarkerCluster\n",
    "marker_cluster = MarkerCluster().add_to(world_map)\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame combinado y agrega marcadores circulares al mapa.\n",
    "for _, row in df_map.iterrows():\n",
    "    tooltip_text = (\n",
    "        f\"País: {row['country.value']}<br>\"\n",
    "        f\"Máximo valor: {row['max_prevalencia']} (Año: {row['max_year']})<br>\"\n",
    "        f\"Mínimo valor: {row['min_prevalencia']} (Año: {row['min_year']})\"\n",
    "    )\n",
    "\n",
    "    # Agregar un marcador circular al mapa con información emergente (tooltip).\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']], # Coordenadas del marcador.\n",
    "        radius=10,  # Radio del círculo.\n",
    "        color='blue', # Color del borde.\n",
    "        fill=True, # Habilita el relleno.\n",
    "        fill_color='cyan', # Color del relleno.\n",
    "        fill_opacity=0.7, # Opacidad del relleno.\n",
    "        tooltip=tooltip_text,  # Texto emergente al pasar el cursor.\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Guardar el mapa como un archivo HTML.\n",
    "world_map.save(\"mapa_prevalencia_max_min.html\")\n",
    "\n",
    "# Muestra el mapa interactivo en el entorno de ejecución.\n",
    "world_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6673b9d4",
   "metadata": {},
   "source": [
    "### 5.4. PREDICCIONES HIPOTÉTICAS DE DE LAS PREVALENCIAS DE LA ANEMIA INFANTIL 2020 - 2030 (sin considerar factor covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb177b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Para cargar, procesar y analizar datos en estructuras como DataFrame.\n",
    "import matplotlib.pyplot as plt # Para crear visualizaciones como gráficos de líneas, barras, histogramas, etc.\n",
    "import numpy as np # Para trabajar con arreglos multidimensionales y realizar cálculos matemáticos avanzados.\n",
    "import ipywidgets as widgets # Para crear elementos interactivos (como deslizadores, menús desplegables, y botones).\n",
    "import plotly.express as px #Para hacer graficos interactivos, no funcionaba en mapamundi.\n",
    "from ipywidgets import interact # Para enlazar elementos interactivos (como deslizadores) a funciones Python para que se actualicen dinámicamente\n",
    "from IPython.display import display, clear_output # - display: Muestra elementos dinámicos o resultados en una celda.\n",
    "                                                  # - clear_output: Limpia el contenido de salida de una celda para actualizarla con nuevos resultados.\n",
    "from matplotlib.patches import Wedge # Para crear formas circulares, como secciones de pastel, en gráficos.\n",
    "from pandas.plotting import table # Para agregar tablas de datos a gráficos de matplotlib.\n",
    "import plotly.graph_objects as go # Para crear gráficos interactivos avanzados y personalizables.\n",
    "import random # Para generar números aleatorios y realizar operaciones relacionadas con la aleatoriedad.\n",
    "from scipy.stats import linregress # realiza análisis de regresión lineal simple, devolviendo parámetros como pendiente, intercepto, valor p, y coeficiente de correlación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90579c",
   "metadata": {},
   "source": [
    "#### 5.4.1. Proyección de anemia infantil a nivel mundial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde un archivo CSV llamado 'world_bank_anemia_mundial_listo.csv' y almacenarlo en un DataFrame llamado data_historico_est\n",
    "data_historico_est = pd.read_csv(r\"world_bank_anemia_mundial_listo.csv\")\n",
    "\n",
    "# Ordenamos los datos por año de forma ascendente (aseguramos que estén en orden cronológico)\n",
    "data_historico_est = data_historico_est.sort_values(by='year', ascending=True)\n",
    "\n",
    "# Calcular el factor de crecimiento promedio (promedio de las variaciones porcentuales año tras año)\n",
    "factor_crecimiento = (data_historico_est['prevalencia (%)'].pct_change().mean() + 1)  # Para que sea un factor de multiplicación\n",
    "\n",
    "# Lista para almacenar los datos con las estimaciones proyectadas\n",
    "datos_con_estimaciones = []\n",
    "\n",
    "# Agregar los datos originales al conjunto de datos de estimaciones\n",
    "for _, row in data_historico_est.iterrows():\n",
    "    datos_con_estimaciones.append({\n",
    "        'year': row['year'],\n",
    "        'nivel geográfico': row['nivel geográfico'],  # Usar nivel_geografico\n",
    "        'prevalencia (%)': row['prevalencia (%)']\n",
    "    })\n",
    "\n",
    "# Proyectar valores desde 2020 hasta 2030 usando el factor de crecimiento\n",
    "ultima_prevalencia = data_historico_est['prevalencia (%)'].iloc[-1]  # Obtiene el último valor conocido (2019)\n",
    "\n",
    "# El último valor de 'nivel_geografico' será el mismo en las proyecciones\n",
    "nivel_geografico = data_historico_est['nivel geográfico'].iloc[0] # Obtiene el nivel geográfico del primer registro\n",
    "\n",
    "for year in range(2020, 2031): # Itera desde 2020 hasta 2030\n",
    "    ultima_prevalencia *= factor_crecimiento  # Aplicar el factor de crecimiento\n",
    "    datos_con_estimaciones.append({\n",
    "        'year': year,\n",
    "        'nivel geográfico': 'Mundial',  # Mantener el mismo nivel_geografico\n",
    "        'prevalencia (%)': ultima_prevalencia\n",
    "    })\n",
    "\n",
    "# Convertir los datos con estimaciones a un DataFrame\n",
    "data_historico_est = pd.DataFrame(datos_con_estimaciones)\n",
    "\n",
    "# Reordenar las columnas para que aparezcan como 'year', 'prevalencia (%)' y 'nivel_geografico'\n",
    "data_historico_est = data_historico_est[['year', 'prevalencia (%)', 'nivel geográfico']]\n",
    "\n",
    "# Mostrar el DataFrame con las estimaciones\n",
    "#print(data_historico_est) #Corroborar el resultado\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Crear el gráfico de línea interactivo para los datos históricos y de proyección\n",
    "fig = go.Figure()\n",
    "\n",
    "# Agregar datos históricos al gráfico\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=data_historico_est[data_historico_est['year'] < 2020]['year'],\n",
    "        y=data_historico_est[data_historico_est['year'] < 2020]['prevalencia (%)'],\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='blue'),\n",
    "        marker=dict(size=8),\n",
    "        name=\" \"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Agregar datos proyectados (2020-2030) al gráfico\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=data_historico_est[data_historico_est['year'] >= 2020]['year'],\n",
    "        y=data_historico_est[data_historico_est['year'] >= 2020]['prevalencia (%)'],\n",
    "        mode='lines+markers',\n",
    "        line=dict(dash='dot', color='blue'),  # Línea punteada para proyecciones\n",
    "        marker=dict(size=8),\n",
    "        name=\" \"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Configurar las etiquetas y diseño del gráfico\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"Prevalencia: %{y:.1f}%\",  # Mostrar solo la prevalencia en el tooltip\n",
    "    line=dict(color=\"blue\"),\n",
    "    marker=dict(size=8)\n",
    ")\n",
    "\n",
    "# Personalizar diseño del gráfico\n",
    "fig.update_layout(\n",
    "    title=\"Prevalencia de anemia (en %), 2000-2030\",  # Título global del gráfico\n",
    "    xaxis=dict(\n",
    "        tickangle=-90,  # Rotar las etiquetas de los años\n",
    "        tickmode='array',  # Mostrar todos los años\n",
    "        tickvals=data_historico_est[\"year\"],  # Asegura que todos los años se muestren\n",
    "        title=None\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Prevalencia (%)\",\n",
    "        range=[10, 50] # Rango fijo para el eje Y\n",
    "    ),\n",
    "    template=\"simple_white\",\n",
    "    showlegend=False  # Ocultar la leyenda\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ea9b9",
   "metadata": {},
   "source": [
    "#### 5.4.2. Proyección de anemia infantil según el nivel de ingreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde un archivo CSV llamado 'world_bank_anemia_ingresos_listo.csv'\n",
    "data = pd.read_csv(r\"world_bank_anemia_ingresos_listo.csv\")\n",
    "\n",
    "# Limpiar nombres de columnas (por si tienen espacios adicionales)\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Lista para almacenar los datos originales y las estimaciones\n",
    "datos_con_estimaciones = []\n",
    "\n",
    "# Obtener la lista de niveles de ingresos únicos\n",
    "niveles_ingresos_unicos = data['nivel de ingresos'].unique()\n",
    "\n",
    "for nivel in niveles_ingresos_unicos:\n",
    "    # Filtrar los datos para el nivel de ingresos actual\n",
    "    datos_nivel = data[data['nivel de ingresos'] == nivel].sort_values(by='year')\n",
    "    \n",
    "    # Calcular las variaciones anuales porcentuales\n",
    "    datos_nivel['variacion'] = datos_nivel['prevalencia (%)'].pct_change()\n",
    "    \n",
    "    # Calcular el promedio de la variación porcentual (ignorando valores nulos)\n",
    "    factor_crecimiento = datos_nivel['variacion'].mean() + 1  # Agregar 1 para obtener el factor multiplicativo\n",
    "    \n",
    "    # Agregar los datos originales del nivel de ingresos al conjunto de datos\n",
    "    for _, row in datos_nivel.iterrows():\n",
    "        datos_con_estimaciones.append({\n",
    "            'year': row['year'],\n",
    "            'nivel de ingresos': row['nivel de ingresos'],\n",
    "            'prevalencia (%)': row['prevalencia (%)']\n",
    "        })\n",
    "    \n",
    "    # Proyectar valores desde 2020 hasta 2030 usando el factor de crecimiento\n",
    "    ultima_prevalencia = datos_nivel['prevalencia (%)'].iloc[-1]  # Último valor conocido (2019)\n",
    "    for year in range(2020, 2031):\n",
    "        ultima_prevalencia *= factor_crecimiento  # Aplicar el factor de crecimiento\n",
    "        datos_con_estimaciones.append({\n",
    "            'year': year,\n",
    "            'nivel de ingresos': nivel,\n",
    "            'prevalencia (%)': ultima_prevalencia\n",
    "        })\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "data_nivelingresos = pd.DataFrame(datos_con_estimaciones) # Data estimada hasta el 2030\n",
    "\n",
    "# Asegurarse de que los datos de 'year' sean numéricos\n",
    "data_nivelingresos['year'] = pd.to_numeric(data_nivelingresos['year'], errors='coerce')\n",
    "data_nivelingresos = data_nivelingresos.dropna(subset=['year', 'prevalencia (%)'])  # Eliminar filas con datos faltantes\n",
    "data_nivelingresos['year'] = data_nivelingresos['year'].astype(int)\n",
    "\n",
    "# Crear el gráfico interactivo con Plotly\n",
    "fig = px.line(data_nivelingresos, x='year', y='prevalencia (%)', color='nivel de ingresos',\n",
    "              markers=True, title='Prevalencia histórica de anemia por nivel de ingresos',\n",
    "              labels={'prevalencia (%)': 'Prevalencia (%)', 'year': 'Año'})\n",
    "\n",
    "# Eliminar la leyenda\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# Añadir el nombre del nivel de ingresos cerca del último punto disponible y alineado verticalmente\n",
    "y_offset = 0.1  # Ajuste de distancia entre los nombres de los niveles\n",
    "for i, level in enumerate(data_nivelingresos['nivel de ingresos'].unique()):\n",
    "    level_data = data_nivelingresos[data_nivelingresos['nivel de ingresos'] == level]\n",
    "    last_row = level_data[level_data['year'] == level_data['year'].max()]\n",
    "    if not last_row.empty:\n",
    "        last_year = last_row['year'].values[0]\n",
    "        last_value = last_row['prevalencia (%)'].values[0]\n",
    "        \n",
    "        # Añadir la anotación en la posición deseada\n",
    "        fig.add_annotation(\n",
    "            x=last_year + 0.4,  # Posición horizontal cerca del último punto\n",
    "            y=last_value + (y_offset * i),  # Posición vertical con ajuste para separar los nombres\n",
    "            text=level,  # Texto con el nombre del nivel de ingresos\n",
    "            showarrow=False,  # Sin flecha\n",
    "            font=dict(size=10),  # Tamaño de la fuente\n",
    "            xanchor='left',  # Alineación del texto a la izquierda\n",
    "            align='left',  # Alineación del texto a la izquierda\n",
    "        )\n",
    "\n",
    "# Mejorar el diseño del gráfico\n",
    "fig.update_traces(mode='lines+markers', hovertemplate='Prevalencia: %{y}')  # Solo mostrar prevalencia en el tooltip\n",
    "fig.update_layout(\n",
    "    xaxis_title='Año',\n",
    "    yaxis_title='Prevalencia (%)',\n",
    "    xaxis=dict(\n",
    "        title=None,  # Quitar el título del eje X\n",
    "        tickmode='array', \n",
    "        tickvals=sorted(\n",
    "            data_nivelingresos['year'].unique()),\n",
    "        showline=True,\n",
    "        linecolor='black',\n",
    "        ticks='outside',  # Mostrar marcas de graduación principales hacia el exterior\n",
    "        tickwidth=1,  # Grosor de las marcas de graduación\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "            showline=True,  # Mostrar la línea del eje Y\n",
    "            linewidth=1,  # Definir el grosor de la línea\n",
    "            linecolor='black'  # Definir el color de la línea\n",
    "    ),\n",
    "    xaxis_tickangle=-90,  # Girar el eje de los años en sentido opuesto\n",
    "    plot_bgcolor='white',\n",
    "    font=dict(size=12),\n",
    "    title_x=0.5,  # Centrar el título\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d12f3",
   "metadata": {},
   "source": [
    "#### 5.4.3. Predicción de la prevalencia de anemia infantil por país (Multiselección)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde un archivo CSV llamado 'world_bank_anemia_paises_listo.csv'\n",
    "data = pd.read_csv(r\"world_bank_anemia_paises_listo.csv\")\n",
    "\n",
    "# Limpiar nombres de columnas (por si tienen espacios adicionales)\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Lista para almacenar los datos originales y las estimaciones\n",
    "datos_con_estimaciones = []\n",
    "\n",
    "# Obtener la lista de países únicos\n",
    "paises_unicos = data['pais'].unique()\n",
    "\n",
    "for pais in paises_unicos:\n",
    "    # Filtrar los datos para el país actual\n",
    "    datos_pais = data[data['pais'] == pais].sort_values(by='year')\n",
    "    \n",
    "    # Calcular las variaciones anuales porcentuales\n",
    "    datos_pais['variacion'] = datos_pais['prevalencia (%)'].pct_change()\n",
    "    \n",
    "    # Calcular el promedio de la variación porcentual (ignorando valores nulos)\n",
    "    factor_crecimiento = datos_pais['variacion'].mean() + 1  # Agregar 1 para obtener el factor multiplicativo\n",
    "    \n",
    "    # Agregar los datos originales del país al conjunto de datos\n",
    "    for _, row in datos_pais.iterrows():\n",
    "        datos_con_estimaciones.append({\n",
    "            'year': row['year'],\n",
    "            'pais': row['pais'],\n",
    "            'prevalencia (%)': row['prevalencia (%)']\n",
    "        })\n",
    "    \n",
    "    # Proyectar valores desde 2020 hasta 2030 usando el factor de crecimiento\n",
    "    ultima_prevalencia = datos_pais['prevalencia (%)'].iloc[-1]  # Último valor conocido (2019)\n",
    "    for year in range(2020, 2031):\n",
    "        ultima_prevalencia *= factor_crecimiento  # Aplicar el factor de crecimiento\n",
    "        datos_con_estimaciones.append({\n",
    "            'year': year,\n",
    "            'pais': pais,\n",
    "            'prevalencia (%)': ultima_prevalencia\n",
    "        })\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "data_historico_pais_est = pd.DataFrame(datos_con_estimaciones) #Data con estimación hasta el 2030\n",
    "\n",
    "# Transformar la variable 'year' a entero\n",
    "data_historico_pais_est['year'] = pd.to_numeric(data_historico_pais_est['year'], errors='coerce')\n",
    "data_historico_pais_est['year'] = data_historico_pais_est['year'].astype(int)\n",
    "\n",
    "# Obtener la lista de países únicos\n",
    "country_data = sorted(data_historico_pais_est['pais'].unique())\n",
    "\n",
    "# Generar colores aleatorios para cada país\n",
    "colors = {country: f\"#{random.randint(0, 0xFFFFFF):06x}\" for country in country_data}\n",
    "\n",
    "# Función para completar los años faltantes\n",
    "def completar_anios(df, country):\n",
    "    country_data = df[df['pais'] == country]\n",
    "    all_years = pd.DataFrame({'year': range(df['year'].min(), df['year'].max() + 1)})\n",
    "    completed_data = pd.merge(all_years, country_data, on='year', how='left')\n",
    "    completed_data['prevalencia (%)'] = completed_data['prevalencia (%)'].interpolate()\n",
    "    completed_data['pais'] = completed_data['pais'].fillna(country)\n",
    "    return completed_data\n",
    "\n",
    "# Función para obtener estadísticas y generar mensajes\n",
    "def obtener_estadisticas_mensaje(country_df):\n",
    "    # Calcular el promedio histórico entre 2000 y 2019\n",
    "    historical_data = country_df[(country_df['year'] >= 2000) & (country_df['year'] <= 2019)]\n",
    "    avg_prevalence_2000_2019 = historical_data['prevalencia (%)'].mean()\n",
    "\n",
    "    # Calcular la tasa de disminución promedio anual hasta 2030\n",
    "    future_data = country_df[(country_df['year'] > 2019) & (country_df['year'] <= 2030)]\n",
    "    if len(future_data) > 1:\n",
    "        slope, _, _, _, _ = linregress(future_data['year'], future_data['prevalencia (%)'])\n",
    "        annual_decrease_rate = -slope\n",
    "    else:\n",
    "        annual_decrease_rate = 0\n",
    "\n",
    "    mensaje = (\n",
    "        f\"Para {country_df['pais'].iloc[0]}, la prevalencia de anemia tuvo un promedio de \"\n",
    "        f\"{avg_prevalence_2000_2019:.2f}% entre 2000 y 2019. \"\n",
    "        f\"Con base en las proyecciones, se estima que la prevalencia disminuirá a una tasa promedio anual de \"\n",
    "        f\"{annual_decrease_rate:.2f}% hacia el año 2030.\"\n",
    "    )\n",
    "    return mensaje\n",
    "\n",
    "# Función para graficar prevalencias históricas y mostrar estadísticas\n",
    "def plot_selected_countries_plotly(countries_selected):\n",
    "    if not countries_selected:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Por favor selecciona al menos un país.\")\n",
    "        return\n",
    "\n",
    "    fig = go.Figure()\n",
    "    mensajes = []\n",
    "\n",
    "    for country in countries_selected:\n",
    "        country_data = completar_anios(data_historico_pais_est, country)\n",
    "        mensaje = obtener_estadisticas_mensaje(country_data)\n",
    "        mensajes.append(mensaje)\n",
    "\n",
    "        before_2020 = country_data[country_data['year'] < 2020]\n",
    "        between_2020_2030 = country_data[(country_data['year'] >= 2020) & (country_data['year'] <= 2030)]\n",
    "        after_2030 = country_data[country_data['year'] > 2030]\n",
    "\n",
    "        country_color = colors[country]\n",
    "\n",
    "        # Segmento antes de 2020\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=before_2020['year'], y=before_2020['prevalencia (%)'],\n",
    "            mode='lines+markers', name=country,\n",
    "            hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",\n",
    "            line=dict(color=country_color)\n",
    "        ))\n",
    "\n",
    "        # Segmento entre 2020 y 2030\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=between_2020_2030['year'], y=between_2020_2030['prevalencia (%)'],\n",
    "            mode='lines+markers', name=country,\n",
    "            hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",\n",
    "            line=dict(dash='dot', color=country_color)\n",
    "        ))\n",
    "\n",
    "        # Segmento después de 2030\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=after_2030['year'], y=after_2030['prevalencia (%)'],\n",
    "            mode='lines+markers', name=country,\n",
    "            hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",\n",
    "            line=dict(color=country_color)\n",
    "        ))\n",
    "        \n",
    "        # Colocar el nombre del país ligeramente desplazado a la derecha de 2030\n",
    "        year_2030_data = country_data[country_data['year'] == 2030]\n",
    "        if not year_2030_data.empty:\n",
    "            # Obtenemos el valor de prevalencia para 2030\n",
    "            prev_2030 = year_2030_data['prevalencia (%)'].values[0]\n",
    "            fig.add_annotation(\n",
    "                x=2030 + 1,  # Desplazamos un poco a la derecha de 2030\n",
    "                y=prev_2030,\n",
    "                text=country,\n",
    "                showarrow=False,\n",
    "                font=dict(size=10, color='black'),\n",
    "                xanchor='left',  # Alineación del texto a la izquierda\n",
    "                align='left'  # Alineación del texto a la izquierda\n",
    "            )\n",
    "\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        fig.update_layout(\n",
    "            title={'text': 'Prevalencia histórica de anemia', 'x': 0.5, 'xanchor': 'center'},\n",
    "            xaxis=dict(title=None, tickangle=-90, showline=True, linecolor='black', ticks='outside', tickwidth=1),\n",
    "            yaxis=dict(showline=True, linewidth=1, linecolor='black', title='Prevalencia (%)'),\n",
    "            template='plotly_white', width=850, showlegend=False\n",
    "        )\n",
    "        fig.show()\n",
    "        for mensaje in mensajes:\n",
    "            print(mensaje)\n",
    "\n",
    "# Función para actualizar el gráfico dinámicamente\n",
    "def update_plot(change=None):\n",
    "    selected_countries = [cb.description for cb in checkboxes if cb.value]\n",
    "    plot_selected_countries_plotly(selected_countries)\n",
    "\n",
    "# Crear checkboxes para cada país\n",
    "checkboxes = [widgets.Checkbox(value=False, description=country) for country in country_data]\n",
    "for cb in checkboxes:\n",
    "    cb.observe(update_plot, names='value')\n",
    "\n",
    "# Crear contenedor de checkboxes y área de salida\n",
    "checkbox_box = widgets.VBox(checkboxes, layout=widgets.Layout(overflow='auto', height='300px', width='200px'))\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Mostrar checkboxes y gráfico\n",
    "display(widgets.HBox([checkbox_box, output_area]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87cf472",
   "metadata": {},
   "source": [
    "### 5.5 **CUARTA PARTE = ANALISIS DE LOS FACTORES QUE MÁS PUEDEN AFECTAR A LA ANEMIA INFANTIL (CASO EXCLUSIVO DE NIGERIA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73600721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuente: encuesta Nigeria\n",
    "## Transformación de las variables a categóricas\n",
    "\n",
    "# Cargar el archivo CSV datos_limpios_transformados.csv\n",
    "import pandas as pd\n",
    "data = pd.read_csv(r\"datos_limpios_transformados.csv\", sep=';')\n",
    "\n",
    "# Tratar la variable 'Smokes' como categórica\n",
    "data['Smokes'] = data['Smokes'].map({0: 'No', 1: 'Sí'})\n",
    "\n",
    "# Tratar la variable 'Anemia_Level' como categórica \n",
    "anemia_mapping = {0: 'Medio', 1: 'Moderado', 2: 'No anémico', 3: 'Severo'}\n",
    "data['Anemia_Level'] = data['Anemia_Level'].map(anemia_mapping)\n",
    "\n",
    "# Tratar la variable 'Wealth_Index' como categórica con las nuevas categorías\n",
    "wealth_mapping = {\n",
    "    0: 'Medio',\n",
    "    1: 'Pobre',\n",
    "    2: 'Pobreza extrema',\n",
    "    3: 'Rico',\n",
    "    4: 'Riqueza alta'\n",
    "}\n",
    "data['Wealth_Index'] = data['Wealth_Index'].map(wealth_mapping)\n",
    "\n",
    "\n",
    "# Tratar la variable 'Iron_Supplements' como categórica\n",
    "data['Iron_Supplements'] = data['Iron_Supplements'].map({0: 'No sabe', 1: 'No', 2: 'Si'})\n",
    "\n",
    "# Tratar la variable 'Iron_Supplements' como categórica\n",
    "data['Residence_Type'] = data['Residence_Type'].map({0: 'Rural', 1: 'Urbana'})\n",
    "\n",
    "# Verificar los cambios\n",
    "# print(data[['Smokes', 'Anemia_Level', 'Wealth_Index', 'Iron_Supplements','Residence_Type']].head()) #para verificar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d1df7",
   "metadata": {},
   "source": [
    "## 5.5.1 Nivel de anemia infantil según nivel de riqueza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px # Para hacer graficos interactivos\n",
    "import pandas as pd # Para cargar, procesar y analizar datos en estructuras como DataFrame.\n",
    "\n",
    "# Contar las observaciones para cada combinación de 'Anemia_Level' y 'Wealth_Index'\n",
    "contado = data.groupby(['Anemia_Level', 'Wealth_Index']).size().reset_index(name='Count')\n",
    "\n",
    "# Calcular el total por cada categoría de 'Wealth_Index'\n",
    "contado['Total_Wealth_Index'] = contado.groupby('Wealth_Index')['Count'].transform('sum')\n",
    "\n",
    "# Calcular el porcentaje dentro de cada 'Wealth_Index'\n",
    "contado['Percentage'] = (contado['Count'] / contado['Total_Wealth_Index']) * 100\n",
    "\n",
    "# Redondear los porcentajes a un solo decimal\n",
    "contado['Percentage'] = contado['Percentage'].round(1)\n",
    "\n",
    "# Definir el orden específico para 'Wealth_Index'\n",
    "orden_wealth = ['Pobreza extrema', 'Pobre', 'Medio', 'Rico', 'Riqueza alta']\n",
    "\n",
    "# Definir el orden específico para 'Anemia_Level'\n",
    "orden_anemia = ['No anémico', 'Moderado', 'Medio', 'Severo']\n",
    "\n",
    "# Convertir 'Wealth_Index' y 'Anemia_Level' en variables categóricas con el orden especificado\n",
    "contado['Wealth_Index'] = pd.Categorical(contado['Wealth_Index'], categories=orden_wealth, ordered=True)\n",
    "contado['Anemia_Level'] = pd.Categorical(contado['Anemia_Level'], categories=orden_anemia, ordered=True)\n",
    "\n",
    "# Asegurarse de que los datos estén ordenados según las categorías especificadas\n",
    "contado = contado.sort_values(by=['Wealth_Index', 'Anemia_Level'])\n",
    "\n",
    "# Crear un gráfico de barras apiladas horizontales\n",
    "fig = px.bar(contado, \n",
    "             x='Percentage', \n",
    "             y='Wealth_Index', \n",
    "             color='Anemia_Level', \n",
    "             orientation='h', \n",
    "             title='Nivel de anemia para cada nivel de riqueza',\n",
    "             labels={'Percentage': 'Porcentaje (%)', 'Wealth_Index': 'Wealth Index'},\n",
    "             hover_data={'Percentage': True, 'Anemia_Level': False, 'Wealth_Index': False})  # Mostrar solo el porcentaje en el tooltip\n",
    "\n",
    "# Personalizar el layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Porcentaje (%)',\n",
    "    yaxis_title='',\n",
    "    barmode='stack',  # Apilar las barras\n",
    "    bargap=0.15,  # Separación entre barras\n",
    "    plot_bgcolor='white',  # Fondo blanco para el gráfico\n",
    "    legend_title=\"Niveles de anemia\"  # Cambiar el título de la leyenda\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa46c980",
   "metadata": {},
   "source": [
    "## 5.5.2 Nivel de anemia infantil según el consumo de suplementos de hierro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px # facilita la creación de widgets interactivos que se actualizan dinámicamente en función de las entradas del usuario.\n",
    "from plotly.subplots import make_subplots # para poder poner subgraficos categorizados.\n",
    "\n",
    "# Filtrar los datos según el valor de Iron_Supplements\n",
    "data_yes = data[data['Iron_Supplements'] == 'Si']\n",
    "data_no = data[data['Iron_Supplements'] == 'No']\n",
    "\n",
    "# Contar la frecuencia de cada categoría de Anemia_Level\n",
    "counts_yes = data_yes['Anemia_Level'].value_counts().reset_index()\n",
    "counts_yes.columns = ['Anemia_Level', 'Count']\n",
    "\n",
    "counts_no = data_no['Anemia_Level'].value_counts().reset_index()\n",
    "counts_no.columns = ['Anemia_Level', 'Count']\n",
    "\n",
    "# Gráfico para Iron_Supplements = Sí\n",
    "fig_yes = px.pie(\n",
    "    counts_yes,\n",
    "    names='Anemia_Level',\n",
    "    values='Count',\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "    custom_data=['Count']  # Datos para el tooltip personalizado\n",
    ")\n",
    "\n",
    "fig_yes.update_traces(\n",
    "    hovertemplate=\"N°: %{customdata[0]}<br>Nivel de anemia: %{label}<extra></extra>\",\n",
    "    pull=[0.05] * len(counts_yes)  # Espaciado entre segmentos\n",
    ")\n",
    "\n",
    "# Gráfico para Iron_Supplements = No\n",
    "fig_no = px.pie(\n",
    "    counts_no,\n",
    "    names='Anemia_Level',\n",
    "    values='Count',\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "    custom_data=['Count']  # Datos para el tooltip personalizado\n",
    ")\n",
    "\n",
    "fig_no.update_traces(\n",
    "    hovertemplate=\"N°: %{customdata[0]}<br>Nivel de anemia: %{label}<extra></extra>\",\n",
    "    pull=[0.05] * len(counts_no)  # Espaciado entre segmentos\n",
    ")\n",
    "\n",
    "# Crear subplots para mostrar los gráficos lado a lado\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, \n",
    "    specs=[[{'type': 'domain'}, {'type': 'domain'}]], \n",
    "    subplot_titles=(\n",
    "        \"Distribución de Anemia_Level (Iron_Supplements = Sí)\", \n",
    "        \"Distribución de Anemia_Level (Iron_Supplements = No)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Añadir el gráfico de \"Sí\"\n",
    "fig.add_traces(fig_yes.data, rows=1, cols=1)\n",
    "\n",
    "# Añadir el gráfico de \"No\"\n",
    "fig.add_traces(fig_no.data, rows=1, cols=2)\n",
    "\n",
    "# Configurar el diseño general\n",
    "fig.update_layout(\n",
    "    showlegend=True,  # Mantener una única leyenda\n",
    "    legend_title=\"Niveles de Anemia\",\n",
    "    legend=dict(x=0.5, y=-0.2, orientation=\"h\", xanchor=\"center\"),  # Leyenda centrada debajo\n",
    "    annotations=[  # Mover los títulos directamente sobre los gráficos\n",
    "        dict(text=\"Niveles de anemia en consumidores de hierro\", x=0.18, y=1.1, font_size=14, showarrow=False),\n",
    "        dict(text=\"Niveles de anemia en NO consumidores de hierro\", x=0.82, y=1.1, font_size=14, showarrow=False)\n",
    "    ],\n",
    "    margin=dict(t=50)  # Ajustar espacio superior\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641a63e",
   "metadata": {},
   "source": [
    "## 5.5.3 Nivel de anemia infantil según el tipo de residencia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Para el análisis y manipulación de datos en Python.\n",
    "import plotly.express as px # Para crear visualizaciones interactivas.\n",
    "\n",
    "# Contar las observaciones por combinación de 'Anemia_Level' y 'Residence_Type', especificando 'observed=False'\n",
    "data_count_res = data.groupby(['Anemia_Level', 'Residence_Type'], observed=False).size().reset_index(name='count')\n",
    "\n",
    "# Modificar los valores de 'count' a negativos cuando 'Residence_Type' sea 'Rural'\n",
    "data_count_res['count'] = data_count_res.apply(lambda row: -row['count'] if row['Residence_Type'] == 'Rural' else row['count'], axis=1)\n",
    "\n",
    "# Calcular el porcentaje tomando el valor absoluto de 'count'\n",
    "total_per_anemia = data_count_res.groupby('Anemia_Level', observed=False)['count'].transform(lambda x: x.abs().sum())\n",
    "data_count_res['percentage'] = (data_count_res['count'].abs() / total_per_anemia) * 100\n",
    "\n",
    "# Crear el gráfico de barras horizontales apiladas con Plotly y cambiar la paleta de colores\n",
    "fig = px.bar(\n",
    "    data_count_res, \n",
    "    x='count', # Datos para el eje X\n",
    "    y='Anemia_Level', # Datos para el eje Y\n",
    "    color='Residence_Type', # Colorea las barras según el tipo de residencia.\n",
    "    orientation='h', # Especifica que las barras deben ser horizontales.\n",
    "    title='Nivel de anemia según el tipo de residencia', # Define el título del gráfico.\n",
    "    labels={'count': 'Número de Observaciones', 'Anemia_Level': 'Nivel de Anemia', 'Residence_Type': 'Tipo de Residencia'}, #Renombra las columnas del eje y la leyenda.\n",
    "    hover_data={'percentage': ':.1f%', 'count': True}, \n",
    "    color_discrete_sequence=[\"#1f77b4\", \"#ff7f0e\"],  # Paleta de colores personalizada\n",
    "    category_orders={\"Anemia_Level\": [\"Severo\", \"Medio\", \"Moderado\", \"No anémico\"]}  # Ordena los niveles de anemia de la manera especificada.\n",
    ")\n",
    "\n",
    "# Personalizar el tooltip para mostrar el número absoluto de observaciones y el porcentaje\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<b>N°:</b> %{customdata[0]:.0f} <br><b>Porcent.:</b> %{customdata[0]:.1f}%<extra></extra>\"\n",
    ")\n",
    "\n",
    "# Ocultar los valores del eje X colocando el color del texto en blanco\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',  # Fondo blanco del gráfico\n",
    "    xaxis=dict(\n",
    "        showticklabels=False,  # Ocultar los valores del eje X\n",
    "        title=None,  # Título del eje X\n",
    "        linecolor='black',  # Color de la línea del eje X\n",
    "        linewidth=1  # Grosor de la línea del eje X\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickfont=dict(color='black'),  # Cambiar el color de las etiquetas del eje Y a negro\n",
    "        linecolor='black',  # Color de la línea del eje Y\n",
    "        linewidth=1  # Grosor de la línea del eje Y\n",
    "    ),\n",
    "    title=dict(font=dict(size=18, color='black')),  # Color del título\n",
    "    template=\"simple_white\"  # Estilo de plantilla blanca\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

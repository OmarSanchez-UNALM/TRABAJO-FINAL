{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6a716e",
   "metadata": {},
   "source": [
    "# PRIMERA FUENTE DE DATOS: World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fa858-7856-46d3-8310-6a52568fffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - requests: para obtener datos de Internet.\n",
    "# - pandas: para organizar los datos en tablas.\n",
    "# - json: para trabajar con información en formato JSON.\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API del Banco Mundial donde están los datos de anemia infantil.\n",
    "base_url = \"http://api.worldbank.org/v2/country/ALL/indicator/SH.ANM.CHLD.ZS\"\n",
    "\n",
    "# Indicamos a la API que queremos los datos en formato JSON.\n",
    "params = {\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía donde guardaremos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Enviamos la solicitud a la API.\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Verificamos si la solicitud fue exitosa (código 200 significa éxito).\n",
    "if response.status_code == 200:\n",
    "    # Convertimos la respuesta de la API en un formato que Python pueda entender (JSON).\n",
    "    data = response.json()\n",
    "    \n",
    "    # Revisamos si hay datos útiles en la respuesta.\n",
    "    if len(data) > 1:  # Los datos que necesitamos están en la segunda parte de la respuesta.\n",
    "        all_data = data[1]  # Guardamos esos datos en nuestra lista.\n",
    "    else:\n",
    "        print(\"No se encontraron datos en la respuesta.\")\n",
    "else:\n",
    "    # Si ocurre un error, mostramos el código de error.\n",
    "    print(\"Error al obtener los datos:\", response.status_code)\n",
    "\n",
    "# Ahora, organizamos los datos en una tabla usando pandas.\n",
    "df_worldbank = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV (una hoja de cálculo).\n",
    "output_file = \"world_bank_anemia.csv\"\n",
    "df_worldbank.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo sin incluir índices.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70b340",
   "metadata": {},
   "source": [
    "# SEGUNDA FUENTE: Global Health Observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API para datos de nutrición y anemia infantil.\n",
    "base_url = \"https://ghoapi.azureedge.net/api/NUTRITION_ANAEMIA_CHILDREN_NUM\"\n",
    "\n",
    "# Configuramos los parámetros para obtener los datos en partes (paginación):\n",
    "# - \"$top\": cuántos registros obtener por solicitud.\n",
    "# - \"$skip\": cuántos registros saltar para la siguiente solicitud.\n",
    "params = {\n",
    "    \"$top\": 1000,  # Pedimos 1000 registros por solicitud.\n",
    "    \"$skip\": 0     # Empezamos desde el inicio.\n",
    "}\n",
    "\n",
    "# Lista vacía para guardar todos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para seguir pidiendo datos hasta que no queden más.\n",
    "while True:\n",
    "    # Hacemos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Si la solicitud fue exitosa:\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en un formato JSON y agregamos los datos a nuestra lista.\n",
    "        data = response.json()\n",
    "        all_data.extend(data[\"value\"])  # Extendemos la lista con los nuevos datos.\n",
    "        \n",
    "        # Si la cantidad de datos obtenidos es menor que \"$top\", significa que no hay más datos.\n",
    "        if len(data[\"value\"]) < params[\"$top\"]:\n",
    "            break  # Terminamos el ciclo.\n",
    "        \n",
    "        # Si hay más datos, incrementamos \"$skip\" para pedir la siguiente página.\n",
    "        params[\"$skip\"] += params[\"$top\"]\n",
    "    else:\n",
    "        # Si ocurre un error, mostramos el código de error y terminamos el ciclo.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos en una tabla con pandas.\n",
    "df_anemia = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV.\n",
    "output_file = \"nutrition_anemia_children.csv\"\n",
    "df_anemia.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25d6c",
   "metadata": {},
   "source": [
    "# TERCERA FUENTE: DHS Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ffa11",
   "metadata": {},
   "source": [
    "### ENCUESTA 1: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER TIPO DE ANEMIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de nutrición (anemia en este caso).\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_ANY\"\n",
    "\n",
    "# Parámetros que se enviarán a la API:\n",
    "# - \"perpage\": número máximo de registros por solicitud (aquí pedimos 1000).\n",
    "# - \"page\": indica el número de la página que estamos solicitando (empezamos en la 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Máximo de registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la página 1.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para almacenar todos los datos obtenidos de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para descargar todos los datos disponibles en la API.\n",
    "while True:\n",
    "    # Realizamos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de respuesta 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta de la API a formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos dentro de la clave \"Data\" y los agregamos a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos:\n",
    "        # Si la cantidad de datos obtenidos es menor que el límite \"perpage\",\n",
    "        # significa que no hay más páginas que consultar.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código distinto de 200), mostramos el código de error y terminamos.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Una vez descargados todos los datos, los organizamos en una tabla con Pandas.\n",
    "df_any = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_any_anemia.csv\".\n",
    "output_file = \"df_any_anemia.csv\"\n",
    "df_any.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo se creó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871d90f",
   "metadata": {},
   "source": [
    "### ENCUESTA 2: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA LEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cc55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mld_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "# URL de la API del DHS para obtener datos de anemia infantil leve.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MLD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": cantidad máxima de datos que queremos recibir por solicitud (1000 aquí).\n",
    "# - \"page\": indica el número de página que solicitamos (iniciamos desde la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Empezamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para guardar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para realizar solicitudes a la API hasta que descarguemos todos los datos.\n",
    "while True:\n",
    "    # Realizamos la solicitud a la API con los parámetros configurados.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código 200 indica éxito).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Agregamos los datos obtenidos (clave \"Data\") a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si ya no hay más datos disponibles:\n",
    "        # Si el número de datos recibidos es menor al límite \"perpage\", hemos llegado al final.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, pasamos a la siguiente página incrementando el número de página.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (respuesta distinta de 200), mostramos un mensaje con el código de error.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Cuando terminamos de descargar los datos, los organizamos en una tabla usando pandas.\n",
    "df_mld = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mld_anemia.csv\".\n",
    "output_file = \"df_mld_anemia.csv\"\n",
    "df_mld.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d4460",
   "metadata": {},
   "source": [
    "### ENCUESTA 3: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA MODERADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mod_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de anemia infantil moderada.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MOD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": define el número máximo de registros a recibir por solicitud (en este caso, 1000).\n",
    "# - \"page\": indica el número de página que se solicita (empezamos en la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Lista vacía para almacenar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Ciclo para realizar solicitudes repetidas hasta que se descarguen todos los datos disponibles.\n",
    "while True:\n",
    "    # Realizamos una solicitud GET a la API utilizando la URL base y los parámetros definidos.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de estado 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manipular en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos de la clave \"Data\" y los agregamos a la lista \"all_data\".\n",
    "        # Usamos \"get\" para evitar errores si la clave no está presente.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos disponibles:\n",
    "        # Si el número de registros recibidos es menor que \"perpage\", significa que no hay más páginas.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si todavía hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código diferente de 200), mostramos el código de error y detenemos el proceso.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos descargados en una tabla (DataFrame) usando pandas.\n",
    "df_mod = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mod_anemia.csv\".\n",
    "output_file = \"df_mod_anemia.csv\"\n",
    "df_mod.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea84f9",
   "metadata": {},
   "source": [
    "### ENCUESTA 4: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA GRAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_sev_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS (Nutrición - Anemia infantil moderada)\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_SEV\"\n",
    "\n",
    "# Definir los parámetros para la solicitud (si soporta paginación)\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Número de registros por página (se solicita un máximo de 1000 registros por solicitud)\n",
    "    \"page\": 1         # Página inicial, comenzamos desde la primera página de resultados\n",
    "}\n",
    "\n",
    "# Lista para almacenar todos los datos que se vayan obteniendo\n",
    "all_data = []\n",
    "\n",
    "# Hacer varias solicitudes hasta obtener todos los datos (paginación)\n",
    "while True:\n",
    "    # Realizar la solicitud a la API utilizando los parámetros definidos\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        # Convertir la respuesta en formato JSON para manejar los datos\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraer la lista de datos (\"Data\") de la respuesta JSON y agregarla a all_data\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificar si hemos recibido menos registros de los solicitados, lo que indica que hemos llegado al final\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break\n",
    "        \n",
    "        # Incrementar el número de página para la siguiente solicitud\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # En caso de error, imprimir el código de estado de la respuesta\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Convertir los datos obtenidos (all_data) a un DataFrame de Pandas para facilitar su análisis\n",
    "df_sev = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "output_file = \"df_sev_anemia.csv\"\n",
    "df_sev.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Imprimir mensaje de éxito indicando que el archivo CSV fue creado correctamente\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4eafdc",
   "metadata": {},
   "source": [
    "# CUARTA FUENTE: KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c426899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Ruta al archivo 'kaggle.json' que contiene las credenciales de acceso a la API de Kaggle\n",
    "kaggle_file_path = 'kaggle.json'\n",
    "\n",
    "# Leer el archivo JSON que contiene las credenciales\n",
    "with open(kaggle_file_path, 'r') as file:\n",
    "    kaggle_api = json.load(file)\n",
    "\n",
    "# Extraer el 'username' y la 'key' de las credenciales de Kaggle\n",
    "kaggle_username = kaggle_api['username']  # Obtiene el nombre de usuario de Kaggle\n",
    "kaggle_key = kaggle_api['key']  # Obtiene la clave de la API de Kaggle\n",
    "\n",
    "# Configurar las variables de entorno con las credenciales para acceder a la API de Kaggle\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_username  # Establece la variable de entorno para el nombre de usuario\n",
    "os.environ['KAGGLE_KEY'] = kaggle_key  # Establece la variable de entorno para la clave de la API\n",
    "\n",
    "# Imprimir un mensaje de confirmación indicando que las credenciales han sido configuradas correctamente\n",
    "print(\"Credenciales de Kaggle configuradas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ejecutar el comando para listar datasets relacionados con \"child anemia\" en Kaggle y capturar la salida\n",
    "result = subprocess.run(\n",
    "    [\"kaggle\", \"datasets\", \"list\", \"-s\", \"child anemia\"],  # El comando Kaggle para buscar datasets\n",
    "    capture_output=True,  # Captura tanto la salida estándar como los errores\n",
    "    text=True  # Decirle a subprocess que el resultado debe ser tratado como texto (en lugar de bytes)\n",
    ")\n",
    "\n",
    "# Imprimir la salida del comando ejecutado\n",
    "print(result.stdout)  # Muestra el resultado del comando (en este caso, la lista de datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ba11f",
   "metadata": {},
   "source": [
    "### DATA 1: Factores que afectan el nivel de anemia en los niños (Estudio en Nigeria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset a descargar desde Kaggle\n",
    "dataset_name = \"adeolaadesina/factors-affecting-children-anemia-level\"\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd78a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"children anemia.csv\"  # El nombre del archivo CSV descargado\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_nigeria = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso Nigeria)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac045c44",
   "metadata": {},
   "source": [
    "### DATA 2: Encuesta Nacional de Familia y Salud (Estudio en ¿India?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e08084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset que quieres descargar desde Kaggle\n",
    "dataset_name = \"ravisinghiitbhu/nfhs5\"  # Identificador del dataset\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcfff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"Final.csv\"  # Nombre del archivo CSV descargado desde Kaggle\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_india = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso India)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa73104",
   "metadata": {},
   "source": [
    "# **Módulo Análisis de Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c3fd4",
   "metadata": {},
   "source": [
    "## API: World Bank Prevalencia de anemia infantil (% de anemia infantil entre los 6-59 meses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586ad13",
   "metadata": {},
   "source": [
    "## 1. Limpieza de Datos\n",
    "### 1.1 Primera revisión del archivo para observar sus columnas y contenido de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'world_bank_anemia.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar una vista previa de los datos para analizar la estructura\n",
    "data.head(), data.info()\n",
    "\n",
    "# Obtener el nombre de las columnas\n",
    "columnas = data.columns.tolist()\n",
    "\n",
    "print(\"Nombres de las columnas:\", columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f100edc",
   "metadata": {},
   "source": [
    "### 1.2 Eliminamos las columnas innecesarias y filas sin valores de anemia, también redondeamos valores de anemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a68f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV original\n",
    "archivo_original = \"world_bank_anemia.csv\"  # Nombre de tu archivo\n",
    "df = pd.read_csv(archivo_original)\n",
    "\n",
    "# Especificar las columnas a eliminar\n",
    "columnas_a_eliminar = [\"unit\", \"obs_status\", \"decimal\", \"indicator.id\",\"countryiso3code\",\"country.id\", \"indicator.value\"]  # Cambia según lo que quieras eliminar\n",
    "\n",
    "# Redondear los valores de la columna \"value\" a 1 decimal\n",
    "df['value'] = df['value'].round(1)\n",
    "\n",
    "# Eliminar las columnas especificadas\n",
    "df_filtrado = df.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Eliminar filas donde la columna 'value' esté vacía\n",
    "world_bank_anemia_limpio = df_filtrado.dropna(subset=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d17731",
   "metadata": {},
   "source": [
    "## 2. Filtrar\n",
    "### 2.1 Filtrar CSV: Separación por países"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6237873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV original\n",
    "archivo_csv = \"world_bank_anemia_limpio.csv\"  # Reemplaza con la ruta a tu archivo\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Filtrar las filas desde \"Afghanistan\" hasta \"Zimbabwe\" en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "filtro_paises = world_bank_anemia_limpio[ultima_columna].str.strip().isin([\"Afghanistan\", \"Zimbabwe\"])  # Filtrar inicio y fin\n",
    "\n",
    "# Obtener los índices del rango\n",
    "inicio = world_bank_anemia_limpio[filtro_paises].index.min()  # Índice de \"Afghanistan\"\n",
    "fin = world_bank_anemia_limpio[filtro_paises].index.max()  # Índice de \"Zimbabwe\"\n",
    "\n",
    "# Seleccionar los datos dentro de este rango\n",
    "df_paises = world_bank_anemia_limpio.iloc[inicio:fin + 1]  # Incluye ambas filas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5241485",
   "metadata": {},
   "source": [
    "### 2.1.1 Mejoramos el nombre de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los nombres de las columnas\n",
    "df_paises = df_paises.rename(columns={\n",
    "    'date': 'year',\n",
    "    'value': 'prevalencia (%)',\n",
    "    'country.value': 'pais'\n",
    "})\n",
    "\n",
    "# Guardar el nuevo archivo CSV con los nombres de columnas cambiados\n",
    "archivo_csv_nuevo = \"world_bank_anemia_paises_listo.csv\"\n",
    "df.to_csv(archivo_csv_nuevo, index=False)\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32273f6f",
   "metadata": {},
   "source": [
    "### 2.2 Agrupar por continentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "file_path = 'world_bank_anemia_paises_listo.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Diccionario para mapear países a continentes\n",
    "country_to_continent = {\n",
    "    \"Afghanistan\": \"Asia\",\n",
    "    \"Albania\": \"Europe\",\n",
    "    \"Algeria\": \"Africa\",\n",
    "    \"Andorra\": \"Europe\",\n",
    "    \"Angola\": \"Africa\",\n",
    "    \"Antigua and Barbuda\": \"North America\",\n",
    "    \"Argentina\": \"South America\",\n",
    "    \"Armenia\": \"Asia\",\n",
    "    \"Australia\": \"Oceania\",\n",
    "    \"Austria\": \"Europe\",\n",
    "    \"Azerbaijan\": \"Asia\",\n",
    "    \"Bahamas\": \"North America\",\n",
    "    \"Bahamas, The\": \"North America\",\n",
    "    \"Bahrain\": \"Asia\",\n",
    "    \"Bangladesh\": \"Asia\",\n",
    "    \"Barbados\": \"North America\",\n",
    "    \"Belarus\": \"Europe\",\n",
    "    \"Belgium\": \"Europe\",\n",
    "    \"Belize\": \"North America\",\n",
    "    \"Benin\": \"Africa\",\n",
    "    \"Bhutan\": \"Asia\",\n",
    "    \"Bolivia\": \"South America\",\n",
    "    \"Bosnia and Herzegovina\": \"Europe\",\n",
    "    \"Botswana\": \"Africa\",\n",
    "    \"Brazil\": \"South America\",\n",
    "    \"Brunei Darussalam\": \"Asia\",\n",
    "    \"Bulgaria\": \"Europe\",\n",
    "    \"Burkina Faso\": \"Africa\",\n",
    "    \"Burundi\": \"Africa\",\n",
    "    \"Cabo Verde\": \"Africa\",\n",
    "    \"Cambodia\": \"Asia\",\n",
    "    \"Cameroon\": \"Africa\",\n",
    "    \"Canada\": \"North America\",\n",
    "    \"Central African Republic\": \"Africa\",\n",
    "    \"Chad\": \"Africa\",\n",
    "    \"Chile\": \"South America\",\n",
    "    \"China\": \"Asia\",\n",
    "    \"Colombia\": \"South America\",\n",
    "    \"Comoros\": \"Africa\",\n",
    "    \"Congo, Dem. Rep.\": \"Africa\",\n",
    "    \"Congo, Rep.\": \"Africa\",\n",
    "    \"Costa Rica\": \"North America\",\n",
    "    \"Cote d'Ivoire\": \"Africa\",\n",
    "    \"Croatia\": \"Europe\",\n",
    "    \"Cuba\": \"North America\",\n",
    "    \"Cyprus\": \"Asia\",\n",
    "    \"Czech Republic\": \"Europe\",\n",
    "    \"Czechia\": \"Europe\",\n",
    "    \"Denmark\": \"Europe\",\n",
    "    \"Djibouti\": \"Africa\",\n",
    "    \"Dominica\": \"North America\",\n",
    "    \"Dominican Republic\": \"North America\",\n",
    "    \"Ecuador\": \"South America\",\n",
    "    \"Egypt\": \"Africa\",\n",
    "    \"Egypt, Arab Rep.\": \"Africa\",\n",
    "    \"El Salvador\": \"North America\",\n",
    "    \"Equatorial Guinea\": \"Africa\",\n",
    "    \"Eritrea\": \"Africa\",\n",
    "    \"Estonia\": \"Europe\",\n",
    "    \"Eswatini\": \"Africa\",\n",
    "    \"Ethiopia\": \"Africa\",\n",
    "    \"Fiji\": \"Oceania\",\n",
    "    \"Finland\": \"Europe\",\n",
    "    \"France\": \"Europe\",\n",
    "    \"Gabon\": \"Africa\",\n",
    "    \"Gambia\": \"Africa\",\n",
    "    \"Gambia, The\": \"Africa\",\n",
    "    \"Georgia\": \"Asia\",\n",
    "    \"Germany\": \"Europe\",\n",
    "    \"Ghana\": \"Africa\",\n",
    "    \"Greece\": \"Europe\",\n",
    "    \"Grenada\": \"North America\",\n",
    "    \"Guatemala\": \"North America\",\n",
    "    \"Guinea\": \"Africa\",\n",
    "    \"Guinea-Bissau\": \"Africa\",\n",
    "    \"Guyana\": \"South America\",\n",
    "    \"Haiti\": \"North America\",\n",
    "    \"Honduras\": \"North America\",\n",
    "    \"Hungary\": \"Europe\",\n",
    "    \"Iceland\": \"Europe\",\n",
    "    \"India\": \"Asia\",\n",
    "    \"Indonesia\": \"Asia\",\n",
    "    \"Iran\": \"Asia\",\n",
    "    \"Iran, Islamic Rep.\": \"Asia\",\n",
    "    \"Iraq\": \"Asia\",\n",
    "    \"Ireland\": \"Europe\",\n",
    "    \"Israel\": \"Asia\",\n",
    "    \"Italy\": \"Europe\",\n",
    "    \"Jamaica\": \"North America\",\n",
    "    \"Japan\": \"Asia\",\n",
    "    \"Jordan\": \"Asia\",\n",
    "    \"Kazakhstan\": \"Asia\",\n",
    "    \"Kenya\": \"Africa\",\n",
    "    \"Kiribati\": \"Oceania\",\n",
    "    \"Korea, Dem. People's Rep.\": \"Asia\",\n",
    "    \"Korea, Dem. Rep.\": \"Asia\",\n",
    "    \"Korea, Rep.\": \"Asia\",\n",
    "    \"Kuwait\": \"Asia\",\n",
    "    \"Kyrgyz Republic\": \"Asia\",\n",
    "    \"Kyrgyzstan\": \"Asia\",\n",
    "    \"Lao PDR\": \"Asia\",\n",
    "    \"Latvia\": \"Europe\",\n",
    "    \"Lebanon\": \"Asia\",\n",
    "    \"Lesotho\": \"Africa\",\n",
    "    \"Liberia\": \"Africa\",\n",
    "    \"Libya\": \"Africa\",\n",
    "    \"Liechtenstein\": \"Europe\",\n",
    "    \"Lithuania\": \"Europe\",\n",
    "    \"Luxembourg\": \"Europe\",\n",
    "    \"Madagascar\": \"Africa\",\n",
    "    \"Malawi\": \"Africa\",\n",
    "    \"Malaysia\": \"Asia\",\n",
    "    \"Maldives\": \"Asia\",\n",
    "    \"Mali\": \"Africa\",\n",
    "    \"Malta\": \"Europe\",\n",
    "    \"Marshall Islands\": \"Oceania\",\n",
    "    \"Mauritania\": \"Africa\",\n",
    "    \"Mauritius\": \"Africa\",\n",
    "    \"Mexico\": \"North America\",\n",
    "    \"Micronesia, Fed. Sts.\": \"Oceania\",\n",
    "    \"Moldova\": \"Europe\",\n",
    "    \"Monaco\": \"Europe\",\n",
    "    \"Mongolia\": \"Asia\",\n",
    "    \"Montenegro\": \"Europe\",\n",
    "    \"Morocco\": \"Africa\",\n",
    "    \"Mozambique\": \"Africa\",\n",
    "    \"Myanmar\": \"Asia\",\n",
    "    \"Namibia\": \"Africa\",\n",
    "    \"Nauru\": \"Oceania\",\n",
    "    \"Nepal\": \"Asia\",\n",
    "    \"Netherlands\": \"Europe\",\n",
    "    \"New Zealand\": \"Oceania\",\n",
    "    \"Nicaragua\": \"North America\",\n",
    "    \"Niger\": \"Africa\",\n",
    "    \"Nigeria\": \"Africa\",\n",
    "    \"North Macedonia\": \"Europe\",\n",
    "    \"Norway\": \"Europe\",\n",
    "    \"Oman\": \"Asia\",\n",
    "    \"Pakistan\": \"Asia\",\n",
    "    \"Palau\": \"Oceania\",\n",
    "    \"Panama\": \"North America\",\n",
    "    \"Papua New Guinea\": \"Oceania\",\n",
    "    \"Paraguay\": \"South America\",\n",
    "    \"Peru\": \"South America\",\n",
    "    \"Philippines\": \"Asia\",\n",
    "    \"Poland\": \"Europe\",\n",
    "    \"Portugal\": \"Europe\",\n",
    "    \"Qatar\": \"Asia\",\n",
    "    \"Romania\": \"Europe\",\n",
    "    \"Russian Federation\": \"Europe\",\n",
    "    \"Rwanda\": \"Africa\",\n",
    "    \"Samoa\": \"Oceania\",\n",
    "    \"San Marino\": \"Europe\",\n",
    "    \"Sao Tome and Principe\": \"Africa\",\n",
    "    \"Saudi Arabia\": \"Asia\",\n",
    "    \"Senegal\": \"Africa\",\n",
    "    \"Serbia\": \"Europe\",\n",
    "    \"Seychelles\": \"Africa\",\n",
    "    \"Sierra Leone\": \"Africa\",\n",
    "    \"Singapore\": \"Asia\",\n",
    "    \"Slovak Republic\": \"Europe\",\n",
    "    \"Slovenia\": \"Europe\",\n",
    "    \"Solomon Islands\": \"Oceania\",\n",
    "    \"Somalia\": \"Africa\",\n",
    "    \"South Africa\": \"Africa\",\n",
    "    \"South Sudan\": \"Africa\",\n",
    "    \"Spain\": \"Europe\",\n",
    "    \"Sri Lanka\": \"Asia\",\n",
    "    \"St. Kitts and Nevis\": \"North America\",\n",
    "    \"St. Lucia\": \"North America\",\n",
    "    \"St. Vincent and the Grenadines\": \"North America\",\n",
    "    \"Sudan\": \"Africa\",\n",
    "    \"Suriname\": \"South America\",\n",
    "    \"Sweden\": \"Europe\",\n",
    "    \"Switzerland\": \"Europe\",\n",
    "    \"Syrian Arab Republic\": \"Asia\",\n",
    "    \"Tajikistan\": \"Asia\",\n",
    "    \"Tanzania\": \"Africa\",\n",
    "    \"Thailand\": \"Asia\",\n",
    "    \"Timor-Leste\": \"Asia\",\n",
    "    \"Togo\": \"Africa\",\n",
    "    \"Tonga\": \"Oceania\",\n",
    "    \"Trinidad and Tobago\": \"North America\",\n",
    "    \"Tunisia\": \"Africa\",\n",
    "    \"Turkey\": \"Asia\",\n",
    "    \"Turkmenistan\": \"Asia\",\n",
    "    \"Tuvalu\": \"Oceania\",\n",
    "    \"Uganda\": \"Africa\",\n",
    "    \"Ukraine\": \"Europe\",\n",
    "    \"United Arab Emirates\": \"Asia\",\n",
    "    \"United Kingdom\": \"Europe\",\n",
    "    \"United States\": \"North America\",\n",
    "    \"Uruguay\": \"South America\",\n",
    "    \"Uzbekistan\": \"Asia\",\n",
    "    \"Vanuatu\": \"Oceania\",\n",
    "    \"Venezuela\": \"South America\",\n",
    "    \"Venezuela, RB\": \"South America\",\n",
    "    \"Vietnam\": \"Asia\",\n",
    "    \"Viet Nam\": \"Asia\",\n",
    "    \"West Bank and Gaza\": \"Asia\",\n",
    "    \"Yemen\": \"Asia\",\n",
    "    \"Yemen, Rep.\": \"Asia\",\n",
    "    \"Zambia\": \"Africa\",\n",
    "    \"Zimbabwe\": \"Africa\"\n",
    "}\n",
    "\n",
    "# Crear la nueva columna \"Continente\"\n",
    "data['Continente'] = data['country.value'].map(country_to_continent)\n",
    "\n",
    "# Ordenar los países por continente y luego por nombre\n",
    "sorted_data = data.sort_values(by=['Continente', 'country.value'])\n",
    "\n",
    "# Guardar el archivo CSV resultante\n",
    "output_path = 'world_bank_continentes.csv'\n",
    "sorted_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo generado: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e30ff8",
   "metadata": {},
   "source": [
    "### 2.3 Filtrar CSV: Separación por ingresos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a filtrar en la última columna\n",
    "valores_deseados = [\n",
    "    \"High income\",\n",
    "    \"Low & middle income\",\n",
    "    \"Low income\",\n",
    "    \"Middle income\",\n",
    "    \"Upper middle income\"\n",
    "]\n",
    "\n",
    "# Filtrar las filas que contienen estos valores en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "world_bank_anemia_filtrado = world_bank_anemia_limpio[world_bank_anemia_limpio[ultima_columna].str.strip().isin(valores_deseados)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2c2d6",
   "metadata": {},
   "source": [
    "### 2.3.1 Mejoramos el nombre de las columnas y valor de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los nombres de las columnas\n",
    "world_bank_anemia_filtrado = world_bank_anemia_filtrado.rename(columns={\n",
    "    'date': 'year',\n",
    "    'value': 'prevalencia (%)',\n",
    "    'country.value': 'nivel de ingresos'\n",
    "})\n",
    "\n",
    "# Modificar los valores de la columna \"nivel de ingresos\"\n",
    "world_bank_anemia_filtrado['nivel de ingresos'] = world_bank_anemia_filtrado['nivel de ingresos'].replace({\n",
    "    'High income': 'Ingresos altos',\n",
    "    'Low & middle income': 'Ingresos bajos y medios',\n",
    "    'Low income': 'Bajos ingresos',\n",
    "    'Middle income': 'Ingreso medio',\n",
    "    'Upper middle income': 'Ingreso medio alto',\n",
    "    'Lower middle income': 'Ingreso medio bajo'\n",
    "})\n",
    "\n",
    "# Guardar el nuevo archivo CSV con los nombres de columnas cambiados\n",
    "archivo_csv_nuevo = \"world_bank_anemia_ingresos_listo.csv\"\n",
    "world_bank_anemia_filtrado.to_csv(archivo_csv_nuevo, index=False)\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfe85f",
   "metadata": {},
   "source": [
    "### 2.4 Filtrar CSV: A nivel mundial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758607a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a filtrar en la última columna\n",
    "valores_deseados = [\n",
    "    \"World\"\n",
    "]\n",
    "\n",
    "# Filtrar las filas que contienen estos valores en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "df_filtrado = world_bank_anemia_limpio[world_bank_anemia_limpio[ultima_columna].str.strip().isin(valores_deseados)]\n",
    "\n",
    "# Guardar en un nuevo archivo CSV\n",
    "nuevo_csv = \"world_bank_anemia_mundial.csv\"\n",
    "df_filtrado.to_csv(nuevo_csv, index=False)\n",
    "\n",
    "print(f\"Datos filtrados guardados en: {nuevo_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acf850",
   "metadata": {},
   "source": [
    "### 2.4.1 Mejoramos el nombre de las columnas y valor de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09573696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "archivo_csv = \"world_bank_anemia_mundial.csv\"  # Asegúrate de que el archivo esté en la misma carpeta o proporciona la ruta completa\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Cambiar los nombres de las columnas\n",
    "df = df.rename(columns={\n",
    "    'date': 'year',\n",
    "    'value': 'prevalencia (%)',\n",
    "    'country.value': 'nivel geográfico'\n",
    "})\n",
    "\n",
    "# Modificar los valores de la columna \"nivel de ingresos\"\n",
    "df['nivel geográfico'] = df['nivel geográfico'].replace({\n",
    "    'World': 'Mundial'\n",
    "})\n",
    "\n",
    "# Guardar el nuevo archivo CSV con los nombres de columnas cambiados\n",
    "archivo_csv_nuevo = \"world_bank_anemia_mundial_listo.csv\"\n",
    "df.to_csv(archivo_csv_nuevo, index=False)\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10867ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a filtrar en la última columna\n",
    "valores_deseados = [\n",
    "    \"World\"\n",
    "]\n",
    "\n",
    "# Filtrar las filas que contienen estos valores en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "df_filtrado = world_bank_anemia_limpio[world_bank_anemia_limpio[ultima_columna].str.strip().isin(valores_deseados)]\n",
    "\n",
    "# Guardar en un nuevo archivo CSV\n",
    "nuevo_csv = \"world_bank_anemia_mundial.csv\"\n",
    "df_filtrado.to_csv(nuevo_csv, index=False)\n",
    "\n",
    "print(f\"Datos filtrados guardados en: {nuevo_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd86c1",
   "metadata": {},
   "source": [
    "# API: Demographic Health Survey (PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER/LEVE/MODERADO/SEVERO NIVEL DE ANEMIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaaa741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'df_any_anemia.csv'\n",
    "any = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "mild = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "mod = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "sev = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd82ca2",
   "metadata": {},
   "source": [
    "## 1. Limpieza de Datos\n",
    "\n",
    "### 1.1 Eliminación de columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb467ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a eliminar\n",
    "columns_to_drop = ['DataId', 'SurveyId', 'Indicator', 'IsPreferred', 'SDRID', 'Precision', 'RegionId', 'SurveyType',\n",
    "'IndicatorId', 'CharacteristicOrder', 'CharacteristicLabel',  'ByVariableLabel', 'CIHigh', 'IsTotal', 'ByVariableId',\n",
    "                   'IndicatorOrder', 'DHS_CountryCode',  'CILow', 'LevelRank', 'CharacteristicId', 'CharacteristicCategory'\n",
    "                 , 'IndicatorType',\n",
    "                   'DenominatorUnweighted','DenominatorWeighted', \"SurveyYearLabel\", \"Value\"\n",
    "]\n",
    "\n",
    "# Eliminar las columnas no deseadas\n",
    "df_cleaned0 = any.drop(columns=columns_to_drop)\n",
    "df_cleaned1 = mild.drop(columns=columns_to_drop)\n",
    "df_cleaned2 = mod.drop(columns=columns_to_drop)\n",
    "df_cleaned3 = sev.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5653c7",
   "metadata": {},
   "source": [
    "## 1.2 Mejorar nombres de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo dataframe con las columnas especificadas\n",
    "df_combined = pd.DataFrame({\n",
    "    'Year': any['SurveyYear'],  # SurveyYear de 'any'\n",
    "    'Pais': any['CountryName'],  # CountryName de 'any'\n",
    "\n",
    "    'Valor Cualquier': any['Value'],  # Value de 'any' renombrado\n",
    "    '# Encuestas (any, sin ponderar)': any['DenominatorUnweighted'],  # DenominatorUnweighted de 'any'\n",
    "    '# Encuestas (any, ponderadas)': any['DenominatorWeighted'],  # DenominatorWeighted de 'any'\n",
    "\n",
    "    'Valor Leve': mild['Value'],  # Value de 'mild' renombrado\n",
    "    '# Encuestas (mild, sin ponderar)': mild['DenominatorUnweighted'],  # DenominatorUnweighted de 'mild'\n",
    "    '# Encuestas (mild, ponderadas)': mild['DenominatorWeighted'],  # DenominatorWeighted de 'mild'\n",
    "\n",
    "    'Valor Moderado': mod['Value'],  # Value de 'mod' renombrado\n",
    "    '# Encuestas (mod, sin ponderar)': mod['DenominatorUnweighted'],  # DenominatorUnweighted de 'mod'\n",
    "    '# Encuestas (mod, ponderadas)': mod['DenominatorWeighted'],  # DenominatorWeighted de 'mod'\n",
    "\n",
    "    'Valor Severo': sev['Value'],  # Value de 'sev' renombrado\n",
    "    '# Encuestas (sev, sin ponderar)': sev['DenominatorUnweighted'],  # DenominatorUnweighted de 'sev'\n",
    "    '# Encuestas (sev, ponderadas)': sev['DenominatorWeighted']  # DenominatorWeighted de 'sev'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Guardar el dataframe combinado como un nuevo archivo CSV\n",
    "output_file_combined = 'dhs_anemia_final.csv'\n",
    "df_combined.to_csv(output_file_combined, index=False)\n",
    "\n",
    "# Imprimir la ruta del archivo guardado\n",
    "print(f\"Archivo guardado en: {output_file_combined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e869f",
   "metadata": {},
   "source": [
    "# API KAGGLE (FACTORES QUE PODRIAN ESTAR INFLUENCIANDO EL NIVEL DE ANEMIA EN NIÑOS DE 0-59 MESES) - Caso: Nigeria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbf9d5",
   "metadata": {},
   "source": [
    "## Descripción del caso\n",
    "\n",
    "En este estudio, se recopilaron datos transversales de las Encuestas demográficas y de salud de Nigeria (NDHS) de 2018 para responder a preguntas de investigación sobre el efecto de la edad de las madres y otros factores socioeconómicos en el nivel de anemia de los niños de 0 a 59 meses en Nigeria. Las DHS son encuestas transversales de hogares representativas a nivel nacional que generalmente se realizan cada 5 años. Los datos de esta encuesta consideraron los 36 estados de Nigeria, así como el Territorio de la Capital Federal (FCT). La población objetivo de este estudio son los niños de 0 a 59 meses y las madres de 15 a 49 años. En esta encuesta, el ingreso del hogar se midió utilizando el índice de riqueza, la edad actual en grupos de 5 años se produce agrupando la edad actual en años completados, tipo de lugar de residencia donde el encuestado fue entrevistado como urbano o rural, la categorización se creó en función de si el número de punto de muestra o conglomerado se define como urbano o rural, el nivel más alto de educación alcanzado es una variable estandarizada que proporciona el nivel de educación en las siguientes categorías: Sin educación, Educación primaria, secundaria y superior, el número total de nacimientos en los últimos cinco años se define como todos los nacimientos en los meses 0 a 59 anteriores al mes de la entrevista, donde el mes 0 es el mes de la entrevista, la edad del encuestado en el primer nacimiento se calcula utilizando el CMC de la fecha de nacimiento del encuestado.\n",
    "\n",
    "Después de la depuración de los datos, se utilizó el método Chi cuadrado para probar las hipótesis sobre la posible relación que existe entre ciertos factores socioeconómicos y los niveles de anemia en niños de 0 a 59 meses. El nivel de anemia fue la variable predictora y las variables explicativas son la edad de la madre, el nivel de educación, el índice de riqueza, el nacimiento en los últimos cinco años, el uso de mosquiteros, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22df03b",
   "metadata": {},
   "source": [
    "# Diccionario de datos\n",
    "\n",
    "```Python\n",
    "Type of place of residence\n",
    "0: Rural\n",
    "1: Urban\n",
    "\n",
    "\n",
    "Highest educational level\n",
    "0: Higher\n",
    "1: No education\n",
    "2: Primary\n",
    "3: Secondary\n",
    "\n",
    "\n",
    "Wealth index combined\n",
    "0: Middle\n",
    "1: Poorer\n",
    "2: Poorest\n",
    "3: Richer\n",
    "4: Richest\n",
    "\n",
    "\n",
    "Anemia level\n",
    "0: Mild\n",
    "1: Moderate\n",
    "2: Not anemic\n",
    "3: Severe\n",
    "\n",
    "\n",
    "Have mosquito bed net for sleeping (from household questionnaire)\n",
    "0: No\n",
    "1: Yes\n",
    "\n",
    "\n",
    "Smokes cigarettes\n",
    "0: No\n",
    "1: Yes\n",
    "\n",
    "\n",
    "Current marital status\n",
    "0: Divorced\n",
    "1: Living with partner\n",
    "2: Married\n",
    "3: Never in union\n",
    "4: No longer living together/separated\n",
    "5: Widowed\n",
    "\n",
    "\n",
    "Currently residing with husband/partner\n",
    "0: Living with her\n",
    "1: Staying elsewhere\n",
    "\n",
    "\n",
    "When child put to breast\n",
    "0: 102.0\n",
    "1: 103.0\n",
    "2: 104.0\n",
    "... (continuando con valores similares)\n",
    "38: Days: 1\n",
    "39: Hours: 1\n",
    "40: Immediately\n",
    "\n",
    "\n",
    "Had fever in last two weeks\n",
    "0: Don't know\n",
    "1: No\n",
    "2: Yes\n",
    "\n",
    "\n",
    "Taking iron pills, sprinkles or syrup\n",
    "0: Don't know\n",
    "1: No\n",
    "2: Yes\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eca8bd",
   "metadata": {},
   "source": [
    "## 1. Implementacion de funciones para limpiar, ordenar y transformar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'children anemia.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar una vista previa de los datos para analizar la estructura\n",
    "data.head(), data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43091910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para limpiar, ordenar y transformar los datos\n",
    "def limpiar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia los datos eliminando columnas duplicadas, renombrando columnas y gestionando valores faltantes.\n",
    "    \"\"\"\n",
    "    # Eliminar columnas duplicadas o irrelevantes\n",
    "    columnas_a_eliminar = ['Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)',\n",
    "                           'Anemia level.1']\n",
    "    dataframe = dataframe.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "    # Renombrar columnas para mayor claridad\n",
    "    dataframe = dataframe.rename(columns={\n",
    "        'Age in 5-year groups': 'Age_Group',\n",
    "        'Type of place of residence': 'Residence_Type',\n",
    "        'Highest educational level': 'Education_Level',\n",
    "        'Wealth index combined': 'Wealth_Index',\n",
    "        'Births in last five years': 'Births_Last_5_Years',\n",
    "        'Age of respondent at 1st birth': 'Age_First_Birth',\n",
    "        'Anemia level': 'Anemia_Level',\n",
    "        'Have mosquito bed net for sleeping (from household questionnaire)': 'Mosquito_Net',\n",
    "        'Smokes cigarettes': 'Smokes',\n",
    "        'Current marital status': 'Marital_Status',\n",
    "        'Currently residing with husband/partner': 'Residing_With_Partner',\n",
    "        'When child put to breast': 'Breastfeeding_Timing',\n",
    "        'Had fever in last two weeks': 'Fever_Last_2_Weeks',\n",
    "        'Hemoglobin level adjusted for altitude (g/dl - 1 decimal)': 'Hemoglobin_Level',\n",
    "        'Taking iron pills, sprinkles or syrup': 'Iron_Supplements'\n",
    "    })\n",
    "\n",
    "    # Manejo de valores faltantes\n",
    "    dataframe['Anemia_Level'] = dataframe['Anemia_Level'].fillna('Unknown')  # Llenar valores faltantes de anemia con \"Unknown\"\n",
    "    dataframe = dataframe.dropna(subset=['Hemoglobin_Level', 'Education_Level'])  # Eliminar filas con valores críticos faltantes\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def transformar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Transforma los datos categóricos a variables numéricas y estandariza las columnas.\n",
    "    \"\"\"\n",
    "    # Convertir categorías a valores numéricos\n",
    "    categoricas_a_codificar = ['Residence_Type', 'Education_Level', 'Wealth_Index', 'Anemia_Level',\n",
    "                               'Mosquito_Net', 'Smokes', 'Marital_Status', 'Residing_With_Partner',\n",
    "                               'Breastfeeding_Timing', 'Fever_Last_2_Weeks', 'Iron_Supplements']\n",
    "\n",
    "    for columna in categoricas_a_codificar:\n",
    "        dataframe[columna] = dataframe[columna].astype('category').cat.codes\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'children anemia.csv'  # Reemplaza con la ruta del archivo en tu sistema\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Aplicar funciones al dataset\n",
    "datos_limpios = limpiar_datos(data)\n",
    "datos_transformados = transformar_datos(datos_limpios)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame transformado\n",
    "print(datos_transformados.head())\n",
    "\n",
    "# Guardar los datos transformados en un archivo CSV\n",
    "datos_transformados.to_csv('datos_limpios_transformados.csv', index=False)\n",
    "print(\"Datos guardados como 'datos_limpios_transformados.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493c51e",
   "metadata": {},
   "source": [
    "## 2. Calcular métricas como media, mediana, moda, y otras estadísticas relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be42b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_avanzadas(dataframe):\n",
    "    \"\"\"\n",
    "    Calcula métricas descriptivas avanzadas como percentiles, asimetría, curtosis y más.\n",
    "    \"\"\"\n",
    "    # Seleccionar columnas numéricas\n",
    "    columnas_numericas = dataframe.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "    # Crear un diccionario para almacenar las métricas\n",
    "    estadisticas = {}\n",
    "\n",
    "    for columna in columnas_numericas.columns:\n",
    "        estadisticas[columna] = {\n",
    "            'Media': columnas_numericas[columna].mean(),\n",
    "            'Mediana': columnas_numericas[columna].median(),\n",
    "            'Moda': columnas_numericas[columna].mode().iloc[0] if not columnas_numericas[columna].mode().empty else None,\n",
    "            'Desviación Estándar': columnas_numericas[columna].std(),\n",
    "            'Mínimo': columnas_numericas[columna].min(),\n",
    "            'Máximo': columnas_numericas[columna].max(),\n",
    "            'Rango': columnas_numericas[columna].max() - columnas_numericas[columna].min(),\n",
    "            'Percentil 25': columnas_numericas[columna].quantile(0.25),\n",
    "            'Percentil 75': columnas_numericas[columna].quantile(0.75),\n",
    "            'Asimetría': columnas_numericas[columna].skew(),\n",
    "            'Curtosis': columnas_numericas[columna].kurt(),\n",
    "            'Rango Intercuartílico (IQR)': columnas_numericas[columna].quantile(0.75) - columnas_numericas[columna].quantile(0.25),\n",
    "            'Coeficiente de Variación (CV)': columnas_numericas[columna].std() / columnas_numericas[columna].mean(),\n",
    "        }\n",
    "\n",
    "    # Convertir a un DataFrame para mejor visualización\n",
    "    estadisticas_df = pd.DataFrame(estadisticas).transpose()\n",
    "    return estadisticas_df\n",
    "\n",
    "\n",
    "# Calcular métricas avanzadas\n",
    "metricas_avanzadas = calcular_metricas_avanzadas(datos_transformados)\n",
    "\n",
    "# Mostrar las métricas avanzadas\n",
    "print(metricas_avanzadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1795277",
   "metadata": {},
   "source": [
    "## 3. Estructuras de datos (listas, pilas, colas) que faciliten el análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d0498",
   "metadata": {},
   "source": [
    "### 3.1 Lista\n",
    "\n",
    "Las listas son ideales para almacenar datos tabulares o registros específicos que se necesitan procesar en secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer datos relevantes y almacenarlos en una lista\n",
    "lista_anemia = datos_transformados[['Age_Group', 'Anemia_Level', 'Hemoglobin_Level']].values.tolist()\n",
    "\n",
    "# Ejemplo de acceso a los datos\n",
    "print(\"Ejemplo de registros en lista:\")\n",
    "print(lista_anemia[:5])  # Imprime los primeros 5 registros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684d1c3",
   "metadata": {},
   "source": [
    "### 3.2 Pila (Stack)\n",
    "\n",
    "Las pilas siguen el principio LIFO (Last In, First Out) y son útiles si los datos se necesitan procesar en orden inverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c33f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pila:\n",
    "    def __init__(self):\n",
    "        self.stack = []\n",
    "\n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.stack.pop() if not self.is_empty() else None\n",
    "\n",
    "    def peek(self):\n",
    "        return self.stack[-1] if not self.is_empty() else None\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.stack) == 0\n",
    "\n",
    "# Crear una pila con los datos relevantes\n",
    "pila_anemia = Pila()\n",
    "for _, row in datos_transformados.iterrows():\n",
    "    pila_anemia.push({'Age_Group': row['Age_Group'], 'Anemia_Level': row['Anemia_Level']})\n",
    "\n",
    "# Ejemplo de uso de la pila\n",
    "print(\"Dato extraído de la pila:\", pila_anemia.pop())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba0311",
   "metadata": {},
   "source": [
    "### 3.3 Cola (Queue)\n",
    "\n",
    "Las colas siguen el principio FIFO (First In, First Out) y son útiles si los datos se deben procesar en el mismo orden en que se almacenaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d575a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Crear una cola con los datos relevantes\n",
    "cola_anemia = deque()\n",
    "for _, row in datos_transformados.iterrows():\n",
    "    cola_anemia.append({'Age_Group': row['Age_Group'], 'Anemia_Level': row['Anemia_Level']})\n",
    "\n",
    "# Ejemplo de uso de la cola\n",
    "print(\"Dato extraído de la cola:\", cola_anemia.popleft())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24f61b",
   "metadata": {},
   "source": [
    "## API: Global Health Observatory - Prevalencia de anemia infantil (% de anemia infantil entre los 6-59 meses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38397a5",
   "metadata": {},
   "source": [
    "## 1. Analisis de datos inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la API para la prevalencia de anemia (sustituir con el código correcto)\n",
    "indicator_code = \"NUTRITION_ANAEMIA_CHILDREN_PREV\"  # Cambia a la API para prevalencia de anemia\n",
    "url = f\"https://ghoapi.azureedge.net/api/{indicator_code}\"\n",
    "\n",
    "# Realizar la solicitud\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificar que la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Extraer los datos en formato JSON\n",
    "\n",
    "    # Convertir los datos a un DataFrame\n",
    "    df = pd.json_normalize(data['value'])\n",
    "    # Mostrar las primeras filas\n",
    "    print(df.head(48))\n",
    "\n",
    "else:\n",
    "    print(f\"Error al acceder a la API: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f3d2e",
   "metadata": {},
   "source": [
    "## **2. Limpieza de datos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6d448",
   "metadata": {},
   "source": [
    "### **2.1 Eliminación de filas y columnas sin datos**\n",
    "\n",
    "*   Elemento de la lista\n",
    "*   Elemento de la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Eliminar columnas con valores nulos\n",
    "df_cleaned = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columnas después de la limpieza:\")\n",
    "print(df_cleaned.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3586ee3",
   "metadata": {},
   "source": [
    "### **2.2 Imputación de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd25d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas específicas\n",
    "# Asegúrate de que los nombres de las columnas coincidan exactamente con los del DataFrame\n",
    "columnas_deseadas = ['SpatialDimType', 'SpatialDim', 'Dim1Type', 'TimeDim','NumericValue', 'Low', 'High']\n",
    "# Elimina espacios extra en ' Dim1Type' y 'TimeDim '\n",
    "\n",
    "# Verificar si las columnas existen antes de seleccionarlas\n",
    "columnas_existentes = df_cleaned.columns\n",
    "columnas_deseadas = [col for col in columnas_deseadas if col in columnas_existentes]\n",
    "\n",
    "df_seleccion = df_cleaned[columnas_deseadas]\n",
    "\n",
    "print(df_seleccion.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e24952",
   "metadata": {},
   "source": [
    "## 3. Organización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Asegurando que la columna tiene valores correctos\n",
    "# Aquí supongo que df es tu DataFrame\n",
    "df['SpatialDim'] = df['SpatialDim'].astype(str)\n",
    "\n",
    "# Filtrar los valores no numéricos y encontrar la moda\n",
    "moda_no_numerica = df[~df['SpatialDim'].str.isnumeric()]['SpatialDim'].mode()[0]\n",
    "\n",
    "# Reemplazar los valores numéricos por la moda\n",
    "df['SpatialDim'] = df['SpatialDim'].apply(lambda x: moda_no_numerica if x.isnumeric() else x)\n",
    "\n",
    "# Mostrar los primeros registros para verificar\n",
    "print(df_seleccion.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ddea5",
   "metadata": {},
   "source": [
    "### **3.1 Obtener años únicos por país en un DataFrame ordenado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27214e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los años únicos por cada valor de SpatialDim\n",
    "years_by_spatialdim = df[df['SpatialDimType'] == 'COUNTRY'].groupby('SpatialDim')['TimeDim'].unique()\n",
    "\n",
    "# Convertir a un DataFrame para una mejor presentación\n",
    "result = years_by_spatialdim.apply(sorted).reset_index(name='Years')\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa255d04",
   "metadata": {},
   "source": [
    "#### **3.2 COMPARAR AÑOS CON MAYOR Y MENOR PROMEDIO USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar promedios anuales\n",
    "year_averages = []\n",
    "\n",
    "# Calcular promedio por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    values = list(df[df['TimeDim'] == year]['NumericValue'])\n",
    "    avg = sum(values) / len(values)\n",
    "    year_averages.append((year, avg))\n",
    "\n",
    "# Ordenar por promedio\n",
    "year_averages.sort(key=lambda x: x[1])\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Año con menor promedio: {year_averages[0][0]} - Promedio: {year_averages[0][1]:.2f}\")\n",
    "print(f\"Año con mayor promedio: {year_averages[-1][0]} - Promedio: {year_averages[-1][1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b619d",
   "metadata": {},
   "source": [
    "#### **4.1 PREVALENCIA DE ANEMIA POR CADA AÑO EN LOS DIFERENTES PAISES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe06dd",
   "metadata": {},
   "source": [
    "# Filtrar registros donde SpatialDimType sea \"COUNTRY\"\n",
    "df_filtered = df[df['SpatialDimType'] == 'COUNTRY']\n",
    "\n",
    "# Calcular el promedio de prevalencia de anemia por país y año\n",
    "average_anemia = df_filtered.groupby(['SpatialDim', 'TimeDim'])['NumericValue'].mean().reset_index()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "average_anemia.columns = ['Country', 'Year', 'AveragePrevalence']\n",
    "\n",
    "# Mostrar los primeros registros del resultado\n",
    "print(average_anemia.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18537e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.1.1 Descargar el archivo en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import pandas as pd\n",
    "\n",
    "# ... (Your existing code to generate average_anemia DataFrame) ...\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "average_anemia.to_csv('PREVALENCIA_DE_ANEMIA_POR_CADA_AÑO_EN_LOS_DIFERENTES_PAISES.csv', index=False)\n",
    "\n",
    "# Download the CSV file\n",
    "files.download('PREVALENCIA_DE_ANEMIA_POR_CADA_AÑO_EN_LOS_DIFERENTES_PAISES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ceb18",
   "metadata": {},
   "source": [
    "#### **4.2 PROMEDIO DE PREVALENCIA POR PAÍS USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88983598",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Lista para almacenar los promedios\n",
    "country_averages = []\n",
    "\n",
    "# Agrupar por país y calcular el promedio manualmente\n",
    "for country in df['SpatialDim'].unique():\n",
    "    if df[df['SpatialDim'] == country]['SpatialDimType'].iloc[0] == 'COUNTRY':\n",
    "        prevalences = list(df[df['SpatialDim'] == country]['NumericValue'])\n",
    "        avg_prevalence = sum(prevalences) / len(prevalences)\n",
    "        country_averages.append((country, avg_prevalence))\n",
    "\n",
    "# Mostrar los resultados\n",
    "for country, avg in country_averages:\n",
    "    print(f\"{country}: {avg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e31b5",
   "metadata": {},
   "source": [
    "### 4.2.1 Descargar el archivo en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame a partir de los resultados\n",
    "results_df = pd.DataFrame(country_averages, columns=['Country', 'AveragePrevalence'])\n",
    "\n",
    "# Guardar el DataFrame como archivo CSV\n",
    "results_df.to_csv('PROMEDIO_DE_PREVALENCIA_POR_PAÍS_USANDO_LISTAS_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('PROMEDIO_DE_PREVALENCIA_POR_PAÍS_USANDO_LISTAS_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ad67c",
   "metadata": {},
   "source": [
    "#### **4.3 RANGO DE PREVALENCIA POR AÑO USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear una pila para almacenar rangos por año\n",
    "ranges_stack = []\n",
    "\n",
    "# Agrupar por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    values = list(df[df['TimeDim'] == year]['NumericValue'])\n",
    "    max_val = max(values)\n",
    "    min_val = min(values)\n",
    "    year_range = max_val - min_val\n",
    "    ranges_stack.append((year, min_val, max_val, year_range))\n",
    "\n",
    "# Crear un DataFrame con las columnas correspondientes\n",
    "ranges_df = pd.DataFrame(ranges_stack, columns=['Año', 'Min', 'Max', 'Rango'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(ranges_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1d4f5",
   "metadata": {},
   "source": [
    "###### **4.3.1 DESCARGAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ea9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "ranges_df.to_csv('RANGO_DE_PREVALENCIA_POR_AÑO_USANDO_LISTAS_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('RANGO_DE_PREVALENCIA_POR_AÑO_USANDO_LISTAS_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36e003",
   "metadata": {},
   "source": [
    "#### **4.4 CALCULAR LA MEDIANA DE PREVALENCIA USANDO COLAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add369b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la mediana por año\n",
    "medians_queue = deque()\n",
    "\n",
    "# Agrupar por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    values = sorted(list(df[df['TimeDim'] == year]['NumericValue']))\n",
    "    n = len(values)\n",
    "    if n % 2 == 0:  # Si hay un número par de valores\n",
    "        median = (values[n // 2 - 1] + values[n // 2]) / 2\n",
    "    else:  # Si hay un número impar de valores\n",
    "        median = values[n // 2]\n",
    "    medians_queue.append((year, median))\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "medians_df = pd.DataFrame(medians_queue, columns=['Año', 'Mediana'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(medians_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff3044",
   "metadata": {},
   "source": [
    "##### **4.4.1 GUARDAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f447e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "medians_df.to_csv('LA_MEDIANA_DE_PREVALENCIA_USANDO_COLAS_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('LA_MEDIANA_DE_PREVALENCIA_USANDO_COLAS_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f9472",
   "metadata": {},
   "source": [
    "#### **4.5 COMPARAR PAÍSES CON MÁS ESTABILIDAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1912b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista para almacenar rangos por país\n",
    "country_ranges = []\n",
    "\n",
    "# Calcular rango por país\n",
    "for country in df['SpatialDim'].unique():\n",
    "    if df[df['SpatialDim'] == country]['SpatialDimType'].iloc[0] == 'COUNTRY':\n",
    "        values = list(df[df['SpatialDim'] == country]['NumericValue'])\n",
    "        country_range = max(values) - min(values)\n",
    "        country_ranges.append((country, country_range))\n",
    "\n",
    "# Ordenar por rango\n",
    "country_ranges.sort(key=lambda x: x[1])\n",
    "\n",
    "# Convertir a un DataFrame\n",
    "ranges_df = pd.DataFrame(country_ranges, columns=['País', 'Rango'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(ranges_df)  # Mostrar los 60 países más estables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651cf962",
   "metadata": {},
   "source": [
    "#### **4.5.1 DESCARGAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1ee3f",
   "metadata": {},
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "ranges_df.to_csv('COMPARAR_PAÍSES_CON_MÁS_ESTABILIDAD_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('COMPARAR_PAÍSES_CON_MÁS_ESTABILIDAD_gho.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

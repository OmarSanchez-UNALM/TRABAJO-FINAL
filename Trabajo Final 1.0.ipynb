{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97d8bb9",
   "metadata": {},
   "source": [
    "# PRIMERA FUENTE DE DATOS: World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fa858-7856-46d3-8310-6a52568fffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - requests: para obtener datos de Internet.\n",
    "# - pandas: para organizar los datos en tablas.\n",
    "# - json: para trabajar con información en formato JSON.\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API del Banco Mundial donde están los datos de anemia infantil.\n",
    "base_url = \"http://api.worldbank.org/v2/country/ALL/indicator/SH.ANM.CHLD.ZS\"\n",
    "\n",
    "# Indicamos a la API que queremos los datos en formato JSON.\n",
    "params = {\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía donde guardaremos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Enviamos la solicitud a la API.\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Verificamos si la solicitud fue exitosa (código 200 significa éxito).\n",
    "if response.status_code == 200:\n",
    "    # Convertimos la respuesta de la API en un formato que Python pueda entender (JSON).\n",
    "    data = response.json()\n",
    "    \n",
    "    # Revisamos si hay datos útiles en la respuesta.\n",
    "    if len(data) > 1:  # Los datos que necesitamos están en la segunda parte de la respuesta.\n",
    "        all_data = data[1]  # Guardamos esos datos en nuestra lista.\n",
    "    else:\n",
    "        print(\"No se encontraron datos en la respuesta.\")\n",
    "else:\n",
    "    # Si ocurre un error, mostramos el código de error.\n",
    "    print(\"Error al obtener los datos:\", response.status_code)\n",
    "\n",
    "# Ahora, organizamos los datos en una tabla usando pandas.\n",
    "df_worldbank = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV (una hoja de cálculo).\n",
    "output_file = \"world_bank_anemia.csv\"\n",
    "df_worldbank.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo sin incluir índices.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70b340",
   "metadata": {},
   "source": [
    "# SEGUNDA FUENTE: Global Health Observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API para datos de nutrición y anemia infantil.\n",
    "base_url = \"https://ghoapi.azureedge.net/api/NUTRITION_ANAEMIA_CHILDREN_NUM\"\n",
    "\n",
    "# Configuramos los parámetros para obtener los datos en partes (paginación):\n",
    "# - \"$top\": cuántos registros obtener por solicitud.\n",
    "# - \"$skip\": cuántos registros saltar para la siguiente solicitud.\n",
    "params = {\n",
    "    \"$top\": 1000,  # Pedimos 1000 registros por solicitud.\n",
    "    \"$skip\": 0     # Empezamos desde el inicio.\n",
    "}\n",
    "\n",
    "# Lista vacía para guardar todos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para seguir pidiendo datos hasta que no queden más.\n",
    "while True:\n",
    "    # Hacemos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Si la solicitud fue exitosa:\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en un formato JSON y agregamos los datos a nuestra lista.\n",
    "        data = response.json()\n",
    "        all_data.extend(data[\"value\"])  # Extendemos la lista con los nuevos datos.\n",
    "        \n",
    "        # Si la cantidad de datos obtenidos es menor que \"$top\", significa que no hay más datos.\n",
    "        if len(data[\"value\"]) < params[\"$top\"]:\n",
    "            break  # Terminamos el ciclo.\n",
    "        \n",
    "        # Si hay más datos, incrementamos \"$skip\" para pedir la siguiente página.\n",
    "        params[\"$skip\"] += params[\"$top\"]\n",
    "    else:\n",
    "        # Si ocurre un error, mostramos el código de error y terminamos el ciclo.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos en una tabla con pandas.\n",
    "df_anemia = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV.\n",
    "output_file = \"nutrition_anemia_children.csv\"\n",
    "df_anemia.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25d6c",
   "metadata": {},
   "source": [
    "# TERCERA FUENTE: DHS Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ffa11",
   "metadata": {},
   "source": [
    "### ENCUESTA 1: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER TIPO DE ANEMIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de nutrición (anemia en este caso).\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_ANY\"\n",
    "\n",
    "# Parámetros que se enviarán a la API:\n",
    "# - \"perpage\": número máximo de registros por solicitud (aquí pedimos 1000).\n",
    "# - \"page\": indica el número de la página que estamos solicitando (empezamos en la 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Máximo de registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la página 1.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para almacenar todos los datos obtenidos de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para descargar todos los datos disponibles en la API.\n",
    "while True:\n",
    "    # Realizamos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de respuesta 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta de la API a formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos dentro de la clave \"Data\" y los agregamos a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos:\n",
    "        # Si la cantidad de datos obtenidos es menor que el límite \"perpage\",\n",
    "        # significa que no hay más páginas que consultar.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código distinto de 200), mostramos el código de error y terminamos.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Una vez descargados todos los datos, los organizamos en una tabla con Pandas.\n",
    "df_any = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_any_anemia.csv\".\n",
    "output_file = \"df_any_anemia.csv\"\n",
    "df_any.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo se creó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871d90f",
   "metadata": {},
   "source": [
    "### ENCUESTA 2: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA LEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cc55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mld_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "# URL de la API del DHS para obtener datos de anemia infantil leve.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MLD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": cantidad máxima de datos que queremos recibir por solicitud (1000 aquí).\n",
    "# - \"page\": indica el número de página que solicitamos (iniciamos desde la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Empezamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para guardar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para realizar solicitudes a la API hasta que descarguemos todos los datos.\n",
    "while True:\n",
    "    # Realizamos la solicitud a la API con los parámetros configurados.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código 200 indica éxito).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Agregamos los datos obtenidos (clave \"Data\") a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si ya no hay más datos disponibles:\n",
    "        # Si el número de datos recibidos es menor al límite \"perpage\", hemos llegado al final.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, pasamos a la siguiente página incrementando el número de página.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (respuesta distinta de 200), mostramos un mensaje con el código de error.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Cuando terminamos de descargar los datos, los organizamos en una tabla usando pandas.\n",
    "df_mld = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mld_anemia.csv\".\n",
    "output_file = \"df_mld_anemia.csv\"\n",
    "df_mld.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d4460",
   "metadata": {},
   "source": [
    "### ENCUESTA 3: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA MODERADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mod_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de anemia infantil moderada.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MOD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": define el número máximo de registros a recibir por solicitud (en este caso, 1000).\n",
    "# - \"page\": indica el número de página que se solicita (empezamos en la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Lista vacía para almacenar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Ciclo para realizar solicitudes repetidas hasta que se descarguen todos los datos disponibles.\n",
    "while True:\n",
    "    # Realizamos una solicitud GET a la API utilizando la URL base y los parámetros definidos.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de estado 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manipular en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos de la clave \"Data\" y los agregamos a la lista \"all_data\".\n",
    "        # Usamos \"get\" para evitar errores si la clave no está presente.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos disponibles:\n",
    "        # Si el número de registros recibidos es menor que \"perpage\", significa que no hay más páginas.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si todavía hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código diferente de 200), mostramos el código de error y detenemos el proceso.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos descargados en una tabla (DataFrame) usando pandas.\n",
    "df_mod = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mod_anemia.csv\".\n",
    "output_file = \"df_mod_anemia.csv\"\n",
    "df_mod.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea84f9",
   "metadata": {},
   "source": [
    "### ENCUESTA 4: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA GRAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_sev_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS (Nutrición - Anemia infantil moderada)\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_SEV\"\n",
    "\n",
    "# Definir los parámetros para la solicitud (si soporta paginación)\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Número de registros por página (se solicita un máximo de 1000 registros por solicitud)\n",
    "    \"page\": 1         # Página inicial, comenzamos desde la primera página de resultados\n",
    "}\n",
    "\n",
    "# Lista para almacenar todos los datos que se vayan obteniendo\n",
    "all_data = []\n",
    "\n",
    "# Hacer varias solicitudes hasta obtener todos los datos (paginación)\n",
    "while True:\n",
    "    # Realizar la solicitud a la API utilizando los parámetros definidos\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        # Convertir la respuesta en formato JSON para manejar los datos\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraer la lista de datos (\"Data\") de la respuesta JSON y agregarla a all_data\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificar si hemos recibido menos registros de los solicitados, lo que indica que hemos llegado al final\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break\n",
    "        \n",
    "        # Incrementar el número de página para la siguiente solicitud\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # En caso de error, imprimir el código de estado de la respuesta\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Convertir los datos obtenidos (all_data) a un DataFrame de Pandas para facilitar su análisis\n",
    "df_sev = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "output_file = \"df_sev_anemia.csv\"\n",
    "df_sev.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Imprimir mensaje de éxito indicando que el archivo CSV fue creado correctamente\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4eafdc",
   "metadata": {},
   "source": [
    "# CUARTA FUENTE: KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c426899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Ruta al archivo 'kaggle.json' que contiene las credenciales de acceso a la API de Kaggle\n",
    "kaggle_file_path = 'kaggle.json'\n",
    "\n",
    "# Leer el archivo JSON que contiene las credenciales\n",
    "with open(kaggle_file_path, 'r') as file:\n",
    "    kaggle_api = json.load(file)\n",
    "\n",
    "# Extraer el 'username' y la 'key' de las credenciales de Kaggle\n",
    "kaggle_username = kaggle_api['username']  # Obtiene el nombre de usuario de Kaggle\n",
    "kaggle_key = kaggle_api['key']  # Obtiene la clave de la API de Kaggle\n",
    "\n",
    "# Configurar las variables de entorno con las credenciales para acceder a la API de Kaggle\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_username  # Establece la variable de entorno para el nombre de usuario\n",
    "os.environ['KAGGLE_KEY'] = kaggle_key  # Establece la variable de entorno para la clave de la API\n",
    "\n",
    "# Imprimir un mensaje de confirmación indicando que las credenciales han sido configuradas correctamente\n",
    "print(\"Credenciales de Kaggle configuradas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ejecutar el comando para listar datasets relacionados con \"child anemia\" en Kaggle y capturar la salida\n",
    "result = subprocess.run(\n",
    "    [\"kaggle\", \"datasets\", \"list\", \"-s\", \"child anemia\"],  # El comando Kaggle para buscar datasets\n",
    "    capture_output=True,  # Captura tanto la salida estándar como los errores\n",
    "    text=True  # Decirle a subprocess que el resultado debe ser tratado como texto (en lugar de bytes)\n",
    ")\n",
    "\n",
    "# Imprimir la salida del comando ejecutado\n",
    "print(result.stdout)  # Muestra el resultado del comando (en este caso, la lista de datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ba11f",
   "metadata": {},
   "source": [
    "### DATA 1: Factores que afectan el nivel de anemia en los niños (Estudio en Nigeria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset a descargar desde Kaggle\n",
    "dataset_name = \"adeolaadesina/factors-affecting-children-anemia-level\"\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd78a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"children anemia.csv\"  # El nombre del archivo CSV descargado\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_nigeria = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso Nigeria)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac045c44",
   "metadata": {},
   "source": [
    "### DATA 2: Encuesta Nacional de Familia y Salud (Estudio en ¿India?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e08084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset que quieres descargar desde Kaggle\n",
    "dataset_name = \"ravisinghiitbhu/nfhs5\"  # Identificador del dataset\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcfff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"Final.csv\"  # Nombre del archivo CSV descargado desde Kaggle\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_india = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso India)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

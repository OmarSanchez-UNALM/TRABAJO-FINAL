{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97d8bb9",
   "metadata": {},
   "source": [
    "# PRIMERA FUENTE DE DATOS: World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fa858-7856-46d3-8310-6a52568fffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - requests: para obtener datos de Internet.\n",
    "# - pandas: para organizar los datos en tablas.\n",
    "# - json: para trabajar con información en formato JSON.\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API del Banco Mundial donde están los datos de anemia infantil.\n",
    "base_url = \"http://api.worldbank.org/v2/country/ALL/indicator/SH.ANM.CHLD.ZS\"\n",
    "\n",
    "# Indicamos a la API que queremos los datos en formato JSON.\n",
    "params = {\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía donde guardaremos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Enviamos la solicitud a la API.\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Verificamos si la solicitud fue exitosa (código 200 significa éxito).\n",
    "if response.status_code == 200:\n",
    "    # Convertimos la respuesta de la API en un formato que Python pueda entender (JSON).\n",
    "    data = response.json()\n",
    "    \n",
    "    # Revisamos si hay datos útiles en la respuesta.\n",
    "    if len(data) > 1:  # Los datos que necesitamos están en la segunda parte de la respuesta.\n",
    "        all_data = data[1]  # Guardamos esos datos en nuestra lista.\n",
    "    else:\n",
    "        print(\"No se encontraron datos en la respuesta.\")\n",
    "else:\n",
    "    # Si ocurre un error, mostramos el código de error.\n",
    "    print(\"Error al obtener los datos:\", response.status_code)\n",
    "\n",
    "# Ahora, organizamos los datos en una tabla usando pandas.\n",
    "df_worldbank = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV (una hoja de cálculo).\n",
    "output_file = \"world_bank_anemia.csv\"\n",
    "df_worldbank.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo sin incluir índices.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70b340",
   "metadata": {},
   "source": [
    "# SEGUNDA FUENTE: Global Health Observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API para datos de nutrición y anemia infantil.\n",
    "base_url = \"https://ghoapi.azureedge.net/api/NUTRITION_ANAEMIA_CHILDREN_NUM\"\n",
    "\n",
    "# Configuramos los parámetros para obtener los datos en partes (paginación):\n",
    "# - \"$top\": cuántos registros obtener por solicitud.\n",
    "# - \"$skip\": cuántos registros saltar para la siguiente solicitud.\n",
    "params = {\n",
    "    \"$top\": 1000,  # Pedimos 1000 registros por solicitud.\n",
    "    \"$skip\": 0     # Empezamos desde el inicio.\n",
    "}\n",
    "\n",
    "# Lista vacía para guardar todos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para seguir pidiendo datos hasta que no queden más.\n",
    "while True:\n",
    "    # Hacemos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Si la solicitud fue exitosa:\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en un formato JSON y agregamos los datos a nuestra lista.\n",
    "        data = response.json()\n",
    "        all_data.extend(data[\"value\"])  # Extendemos la lista con los nuevos datos.\n",
    "        \n",
    "        # Si la cantidad de datos obtenidos es menor que \"$top\", significa que no hay más datos.\n",
    "        if len(data[\"value\"]) < params[\"$top\"]:\n",
    "            break  # Terminamos el ciclo.\n",
    "        \n",
    "        # Si hay más datos, incrementamos \"$skip\" para pedir la siguiente página.\n",
    "        params[\"$skip\"] += params[\"$top\"]\n",
    "    else:\n",
    "        # Si ocurre un error, mostramos el código de error y terminamos el ciclo.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos en una tabla con pandas.\n",
    "df_anemia = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV.\n",
    "output_file = \"nutrition_anemia_children.csv\"\n",
    "df_anemia.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25d6c",
   "metadata": {},
   "source": [
    "# TERCERA FUENTE: DHS Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ffa11",
   "metadata": {},
   "source": [
    "### ENCUESTA 1: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER TIPO DE ANEMIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de nutrición (anemia en este caso).\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_ANY\"\n",
    "\n",
    "# Parámetros que se enviarán a la API:\n",
    "# - \"perpage\": número máximo de registros por solicitud (aquí pedimos 1000).\n",
    "# - \"page\": indica el número de la página que estamos solicitando (empezamos en la 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Máximo de registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la página 1.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para almacenar todos los datos obtenidos de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para descargar todos los datos disponibles en la API.\n",
    "while True:\n",
    "    # Realizamos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de respuesta 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta de la API a formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos dentro de la clave \"Data\" y los agregamos a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos:\n",
    "        # Si la cantidad de datos obtenidos es menor que el límite \"perpage\",\n",
    "        # significa que no hay más páginas que consultar.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código distinto de 200), mostramos el código de error y terminamos.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Una vez descargados todos los datos, los organizamos en una tabla con Pandas.\n",
    "df_any = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_any_anemia.csv\".\n",
    "output_file = \"df_any_anemia.csv\"\n",
    "df_any.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo se creó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871d90f",
   "metadata": {},
   "source": [
    "### ENCUESTA 2: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA LEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cc55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mld_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "# URL de la API del DHS para obtener datos de anemia infantil leve.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MLD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": cantidad máxima de datos que queremos recibir por solicitud (1000 aquí).\n",
    "# - \"page\": indica el número de página que solicitamos (iniciamos desde la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Empezamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para guardar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para realizar solicitudes a la API hasta que descarguemos todos los datos.\n",
    "while True:\n",
    "    # Realizamos la solicitud a la API con los parámetros configurados.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código 200 indica éxito).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Agregamos los datos obtenidos (clave \"Data\") a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si ya no hay más datos disponibles:\n",
    "        # Si el número de datos recibidos es menor al límite \"perpage\", hemos llegado al final.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, pasamos a la siguiente página incrementando el número de página.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (respuesta distinta de 200), mostramos un mensaje con el código de error.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Cuando terminamos de descargar los datos, los organizamos en una tabla usando pandas.\n",
    "df_mld = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mld_anemia.csv\".\n",
    "output_file = \"df_mld_anemia.csv\"\n",
    "df_mld.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d4460",
   "metadata": {},
   "source": [
    "### ENCUESTA 3: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA MODERADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mod_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de anemia infantil moderada.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MOD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": define el número máximo de registros a recibir por solicitud (en este caso, 1000).\n",
    "# - \"page\": indica el número de página que se solicita (empezamos en la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Lista vacía para almacenar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Ciclo para realizar solicitudes repetidas hasta que se descarguen todos los datos disponibles.\n",
    "while True:\n",
    "    # Realizamos una solicitud GET a la API utilizando la URL base y los parámetros definidos.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de estado 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manipular en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos de la clave \"Data\" y los agregamos a la lista \"all_data\".\n",
    "        # Usamos \"get\" para evitar errores si la clave no está presente.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos disponibles:\n",
    "        # Si el número de registros recibidos es menor que \"perpage\", significa que no hay más páginas.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si todavía hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código diferente de 200), mostramos el código de error y detenemos el proceso.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos descargados en una tabla (DataFrame) usando pandas.\n",
    "df_mod = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mod_anemia.csv\".\n",
    "output_file = \"df_mod_anemia.csv\"\n",
    "df_mod.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea84f9",
   "metadata": {},
   "source": [
    "### ENCUESTA 4: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA GRAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_sev_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS (Nutrición - Anemia infantil moderada)\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_SEV\"\n",
    "\n",
    "# Definir los parámetros para la solicitud (si soporta paginación)\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Número de registros por página (se solicita un máximo de 1000 registros por solicitud)\n",
    "    \"page\": 1         # Página inicial, comenzamos desde la primera página de resultados\n",
    "}\n",
    "\n",
    "# Lista para almacenar todos los datos que se vayan obteniendo\n",
    "all_data = []\n",
    "\n",
    "# Hacer varias solicitudes hasta obtener todos los datos (paginación)\n",
    "while True:\n",
    "    # Realizar la solicitud a la API utilizando los parámetros definidos\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        # Convertir la respuesta en formato JSON para manejar los datos\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraer la lista de datos (\"Data\") de la respuesta JSON y agregarla a all_data\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificar si hemos recibido menos registros de los solicitados, lo que indica que hemos llegado al final\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break\n",
    "        \n",
    "        # Incrementar el número de página para la siguiente solicitud\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # En caso de error, imprimir el código de estado de la respuesta\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Convertir los datos obtenidos (all_data) a un DataFrame de Pandas para facilitar su análisis\n",
    "df_sev = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "output_file = \"df_sev_anemia.csv\"\n",
    "df_sev.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Imprimir mensaje de éxito indicando que el archivo CSV fue creado correctamente\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4eafdc",
   "metadata": {},
   "source": [
    "# CUARTA FUENTE: KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c426899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Ruta al archivo 'kaggle.json' que contiene las credenciales de acceso a la API de Kaggle\n",
    "kaggle_file_path = 'kaggle.json'\n",
    "\n",
    "# Leer el archivo JSON que contiene las credenciales\n",
    "with open(kaggle_file_path, 'r') as file:\n",
    "    kaggle_api = json.load(file)\n",
    "\n",
    "# Extraer el 'username' y la 'key' de las credenciales de Kaggle\n",
    "kaggle_username = kaggle_api['username']  # Obtiene el nombre de usuario de Kaggle\n",
    "kaggle_key = kaggle_api['key']  # Obtiene la clave de la API de Kaggle\n",
    "\n",
    "# Configurar las variables de entorno con las credenciales para acceder a la API de Kaggle\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_username  # Establece la variable de entorno para el nombre de usuario\n",
    "os.environ['KAGGLE_KEY'] = kaggle_key  # Establece la variable de entorno para la clave de la API\n",
    "\n",
    "# Imprimir un mensaje de confirmación indicando que las credenciales han sido configuradas correctamente\n",
    "print(\"Credenciales de Kaggle configuradas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ejecutar el comando para listar datasets relacionados con \"child anemia\" en Kaggle y capturar la salida\n",
    "result = subprocess.run(\n",
    "    [\"kaggle\", \"datasets\", \"list\", \"-s\", \"child anemia\"],  # El comando Kaggle para buscar datasets\n",
    "    capture_output=True,  # Captura tanto la salida estándar como los errores\n",
    "    text=True  # Decirle a subprocess que el resultado debe ser tratado como texto (en lugar de bytes)\n",
    ")\n",
    "\n",
    "# Imprimir la salida del comando ejecutado\n",
    "print(result.stdout)  # Muestra el resultado del comando (en este caso, la lista de datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ba11f",
   "metadata": {},
   "source": [
    "### DATA 1: Factores que afectan el nivel de anemia en los niños (Estudio en Nigeria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset a descargar desde Kaggle\n",
    "dataset_name = \"adeolaadesina/factors-affecting-children-anemia-level\"\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd78a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"children anemia.csv\"  # El nombre del archivo CSV descargado\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_nigeria = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso Nigeria)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac045c44",
   "metadata": {},
   "source": [
    "### DATA 2: Encuesta Nacional de Familia y Salud (Estudio en ¿India?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e08084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset que quieres descargar desde Kaggle\n",
    "dataset_name = \"ravisinghiitbhu/nfhs5\"  # Identificador del dataset\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcfff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"Final.csv\"  # Nombre del archivo CSV descargado desde Kaggle\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_india = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso India)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd86c1",
   "metadata": {},
   "source": [
    "# API: Demographic Health Survey (PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER/LEVE/MODERADO/SEVERO NIVEL DE ANEMIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaaa741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'df_any_anemia.csv'\n",
    "any = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "mild = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "mod = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "sev = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd82ca2",
   "metadata": {},
   "source": [
    "## 1. Limpieza de Datos\n",
    "\n",
    "### 1.1 Eliminación de columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb467ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a eliminar\n",
    "columns_to_drop = ['DataId', 'SurveyId', 'Indicator', 'IsPreferred', 'SDRID', 'Precision', 'RegionId', 'SurveyType',\n",
    "'IndicatorId', 'CharacteristicOrder', 'CharacteristicLabel',  'ByVariableLabel', 'CIHigh', 'IsTotal', 'ByVariableId',\n",
    "                   'IndicatorOrder', 'DHS_CountryCode',  'CILow', 'LevelRank', 'CharacteristicId', 'CharacteristicCategory'\n",
    "                 , 'IndicatorType',\n",
    "                   'DenominatorUnweighted','DenominatorWeighted', \"SurveyYearLabel\", \"Value\"\n",
    "]\n",
    "\n",
    "# Eliminar las columnas no deseadas\n",
    "df_cleaned0 = any.drop(columns=columns_to_drop)\n",
    "df_cleaned1 = mild.drop(columns=columns_to_drop)\n",
    "df_cleaned2 = mod.drop(columns=columns_to_drop)\n",
    "df_cleaned3 = sev.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5653c7",
   "metadata": {},
   "source": [
    "## 1.2 Mejorar nombres de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo dataframe con las columnas especificadas\n",
    "df_combined = pd.DataFrame({\n",
    "    'Year': any['SurveyYear'],  # SurveyYear de 'any'\n",
    "    'Pais': any['CountryName'],  # CountryName de 'any'\n",
    "\n",
    "    'Valor Cualquier': any['Value'],  # Value de 'any' renombrado\n",
    "    '# Encuestas (any, sin ponderar)': any['DenominatorUnweighted'],  # DenominatorUnweighted de 'any'\n",
    "    '# Encuestas (any, ponderadas)': any['DenominatorWeighted'],  # DenominatorWeighted de 'any'\n",
    "\n",
    "    'Valor Leve': mild['Value'],  # Value de 'mild' renombrado\n",
    "    '# Encuestas (mild, sin ponderar)': mild['DenominatorUnweighted'],  # DenominatorUnweighted de 'mild'\n",
    "    '# Encuestas (mild, ponderadas)': mild['DenominatorWeighted'],  # DenominatorWeighted de 'mild'\n",
    "\n",
    "    'Valor Moderado': mod['Value'],  # Value de 'mod' renombrado\n",
    "    '# Encuestas (mod, sin ponderar)': mod['DenominatorUnweighted'],  # DenominatorUnweighted de 'mod'\n",
    "    '# Encuestas (mod, ponderadas)': mod['DenominatorWeighted'],  # DenominatorWeighted de 'mod'\n",
    "\n",
    "    'Valor Severo': sev['Value'],  # Value de 'sev' renombrado\n",
    "    '# Encuestas (sev, sin ponderar)': sev['DenominatorUnweighted'],  # DenominatorUnweighted de 'sev'\n",
    "    '# Encuestas (sev, ponderadas)': sev['DenominatorWeighted']  # DenominatorWeighted de 'sev'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Guardar el dataframe combinado como un nuevo archivo CSV\n",
    "output_file_combined = 'dhs_anemia_final.csv'\n",
    "df_combined.to_csv(output_file_combined, index=False)\n",
    "\n",
    "# Imprimir la ruta del archivo guardado\n",
    "print(f\"Archivo guardado en: {output_file_combined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e869f",
   "metadata": {},
   "source": [
    "# API KAGGLE (FACTORES QUE PODRIAN ESTAR INFLUENCIANDO EL NIVEL DE ANEMIA EN NIÑOS DE 0-59 MESES) - Caso: Nigeria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbf9d5",
   "metadata": {},
   "source": [
    "## Descripción del caso\n",
    "\n",
    "En este estudio, se recopilaron datos transversales de las Encuestas demográficas y de salud de Nigeria (NDHS) de 2018 para responder a preguntas de investigación sobre el efecto de la edad de las madres y otros factores socioeconómicos en el nivel de anemia de los niños de 0 a 59 meses en Nigeria. Las DHS son encuestas transversales de hogares representativas a nivel nacional que generalmente se realizan cada 5 años. Los datos de esta encuesta consideraron los 36 estados de Nigeria, así como el Territorio de la Capital Federal (FCT). La población objetivo de este estudio son los niños de 0 a 59 meses y las madres de 15 a 49 años. En esta encuesta, el ingreso del hogar se midió utilizando el índice de riqueza, la edad actual en grupos de 5 años se produce agrupando la edad actual en años completados, tipo de lugar de residencia donde el encuestado fue entrevistado como urbano o rural, la categorización se creó en función de si el número de punto de muestra o conglomerado se define como urbano o rural, el nivel más alto de educación alcanzado es una variable estandarizada que proporciona el nivel de educación en las siguientes categorías: Sin educación, Educación primaria, secundaria y superior, el número total de nacimientos en los últimos cinco años se define como todos los nacimientos en los meses 0 a 59 anteriores al mes de la entrevista, donde el mes 0 es el mes de la entrevista, la edad del encuestado en el primer nacimiento se calcula utilizando el CMC de la fecha de nacimiento del encuestado.\n",
    "\n",
    "Después de la depuración de los datos, se utilizó el método Chi cuadrado para probar las hipótesis sobre la posible relación que existe entre ciertos factores socioeconómicos y los niveles de anemia en niños de 0 a 59 meses. El nivel de anemia fue la variable predictora y las variables explicativas son la edad de la madre, el nivel de educación, el índice de riqueza, el nacimiento en los últimos cinco años, el uso de mosquiteros, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22df03b",
   "metadata": {},
   "source": [
    "# Diccionario de datos\n",
    "\n",
    "```Python\n",
    "Type of place of residence\n",
    "0: Rural\n",
    "1: Urban\n",
    "\n",
    "\n",
    "Highest educational level\n",
    "0: Higher\n",
    "1: No education\n",
    "2: Primary\n",
    "3: Secondary\n",
    "\n",
    "\n",
    "Wealth index combined\n",
    "0: Middle\n",
    "1: Poorer\n",
    "2: Poorest\n",
    "3: Richer\n",
    "4: Richest\n",
    "\n",
    "\n",
    "Anemia level\n",
    "0: Mild\n",
    "1: Moderate\n",
    "2: Not anemic\n",
    "3: Severe\n",
    "\n",
    "\n",
    "Have mosquito bed net for sleeping (from household questionnaire)\n",
    "0: No\n",
    "1: Yes\n",
    "\n",
    "\n",
    "Smokes cigarettes\n",
    "0: No\n",
    "1: Yes\n",
    "\n",
    "\n",
    "Current marital status\n",
    "0: Divorced\n",
    "1: Living with partner\n",
    "2: Married\n",
    "3: Never in union\n",
    "4: No longer living together/separated\n",
    "5: Widowed\n",
    "\n",
    "\n",
    "Currently residing with husband/partner\n",
    "0: Living with her\n",
    "1: Staying elsewhere\n",
    "\n",
    "\n",
    "When child put to breast\n",
    "0: 102.0\n",
    "1: 103.0\n",
    "2: 104.0\n",
    "... (continuando con valores similares)\n",
    "38: Days: 1\n",
    "39: Hours: 1\n",
    "40: Immediately\n",
    "\n",
    "\n",
    "Had fever in last two weeks\n",
    "0: Don't know\n",
    "1: No\n",
    "2: Yes\n",
    "\n",
    "\n",
    "Taking iron pills, sprinkles or syrup\n",
    "0: Don't know\n",
    "1: No\n",
    "2: Yes\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eca8bd",
   "metadata": {},
   "source": [
    "## 1. Implementacion de funciones para limpiar, ordenar y transformar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'children anemia.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar una vista previa de los datos para analizar la estructura\n",
    "data.head(), data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43091910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para limpiar, ordenar y transformar los datos\n",
    "def limpiar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia los datos eliminando columnas duplicadas, renombrando columnas y gestionando valores faltantes.\n",
    "    \"\"\"\n",
    "    # Eliminar columnas duplicadas o irrelevantes\n",
    "    columnas_a_eliminar = ['Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)',\n",
    "                           'Anemia level.1']\n",
    "    dataframe = dataframe.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "    # Renombrar columnas para mayor claridad\n",
    "    dataframe = dataframe.rename(columns={\n",
    "        'Age in 5-year groups': 'Age_Group',\n",
    "        'Type of place of residence': 'Residence_Type',\n",
    "        'Highest educational level': 'Education_Level',\n",
    "        'Wealth index combined': 'Wealth_Index',\n",
    "        'Births in last five years': 'Births_Last_5_Years',\n",
    "        'Age of respondent at 1st birth': 'Age_First_Birth',\n",
    "        'Anemia level': 'Anemia_Level',\n",
    "        'Have mosquito bed net for sleeping (from household questionnaire)': 'Mosquito_Net',\n",
    "        'Smokes cigarettes': 'Smokes',\n",
    "        'Current marital status': 'Marital_Status',\n",
    "        'Currently residing with husband/partner': 'Residing_With_Partner',\n",
    "        'When child put to breast': 'Breastfeeding_Timing',\n",
    "        'Had fever in last two weeks': 'Fever_Last_2_Weeks',\n",
    "        'Hemoglobin level adjusted for altitude (g/dl - 1 decimal)': 'Hemoglobin_Level',\n",
    "        'Taking iron pills, sprinkles or syrup': 'Iron_Supplements'\n",
    "    })\n",
    "\n",
    "    # Manejo de valores faltantes\n",
    "    dataframe['Anemia_Level'] = dataframe['Anemia_Level'].fillna('Unknown')  # Llenar valores faltantes de anemia con \"Unknown\"\n",
    "    dataframe = dataframe.dropna(subset=['Hemoglobin_Level', 'Education_Level'])  # Eliminar filas con valores críticos faltantes\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def transformar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Transforma los datos categóricos a variables numéricas y estandariza las columnas.\n",
    "    \"\"\"\n",
    "    # Convertir categorías a valores numéricos\n",
    "    categoricas_a_codificar = ['Residence_Type', 'Education_Level', 'Wealth_Index', 'Anemia_Level',\n",
    "                               'Mosquito_Net', 'Smokes', 'Marital_Status', 'Residing_With_Partner',\n",
    "                               'Breastfeeding_Timing', 'Fever_Last_2_Weeks', 'Iron_Supplements']\n",
    "\n",
    "    for columna in categoricas_a_codificar:\n",
    "        dataframe[columna] = dataframe[columna].astype('category').cat.codes\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'children anemia.csv'  # Reemplaza con la ruta del archivo en tu sistema\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Aplicar funciones al dataset\n",
    "datos_limpios = limpiar_datos(data)\n",
    "datos_transformados = transformar_datos(datos_limpios)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame transformado\n",
    "print(datos_transformados.head())\n",
    "\n",
    "# Guardar los datos transformados en un archivo CSV\n",
    "datos_transformados.to_csv('datos_limpios_transformados.csv', index=False)\n",
    "print(\"Datos guardados como 'datos_limpios_transformados.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493c51e",
   "metadata": {},
   "source": [
    "## 2. Calcular métricas como media, mediana, moda, y otras estadísticas relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be42b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_avanzadas(dataframe):\n",
    "    \"\"\"\n",
    "    Calcula métricas descriptivas avanzadas como percentiles, asimetría, curtosis y más.\n",
    "    \"\"\"\n",
    "    # Seleccionar columnas numéricas\n",
    "    columnas_numericas = dataframe.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "    # Crear un diccionario para almacenar las métricas\n",
    "    estadisticas = {}\n",
    "\n",
    "    for columna in columnas_numericas.columns:\n",
    "        estadisticas[columna] = {\n",
    "            'Media': columnas_numericas[columna].mean(),\n",
    "            'Mediana': columnas_numericas[columna].median(),\n",
    "            'Moda': columnas_numericas[columna].mode().iloc[0] if not columnas_numericas[columna].mode().empty else None,\n",
    "            'Desviación Estándar': columnas_numericas[columna].std(),\n",
    "            'Mínimo': columnas_numericas[columna].min(),\n",
    "            'Máximo': columnas_numericas[columna].max(),\n",
    "            'Rango': columnas_numericas[columna].max() - columnas_numericas[columna].min(),\n",
    "            'Percentil 25': columnas_numericas[columna].quantile(0.25),\n",
    "            'Percentil 75': columnas_numericas[columna].quantile(0.75),\n",
    "            'Asimetría': columnas_numericas[columna].skew(),\n",
    "            'Curtosis': columnas_numericas[columna].kurt(),\n",
    "            'Rango Intercuartílico (IQR)': columnas_numericas[columna].quantile(0.75) - columnas_numericas[columna].quantile(0.25),\n",
    "            'Coeficiente de Variación (CV)': columnas_numericas[columna].std() / columnas_numericas[columna].mean(),\n",
    "        }\n",
    "\n",
    "    # Convertir a un DataFrame para mejor visualización\n",
    "    estadisticas_df = pd.DataFrame(estadisticas).transpose()\n",
    "    return estadisticas_df\n",
    "\n",
    "\n",
    "# Calcular métricas avanzadas\n",
    "metricas_avanzadas = calcular_metricas_avanzadas(datos_transformados)\n",
    "\n",
    "# Mostrar las métricas avanzadas\n",
    "print(metricas_avanzadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1795277",
   "metadata": {},
   "source": [
    "## 3. Estructuras de datos (listas, pilas, colas) que faciliten el análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d0498",
   "metadata": {},
   "source": [
    "### 3.1 Lista\n",
    "\n",
    "Las listas son ideales para almacenar datos tabulares o registros específicos que se necesitan procesar en secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer datos relevantes y almacenarlos en una lista\n",
    "lista_anemia = datos_transformados[['Age_Group', 'Anemia_Level', 'Hemoglobin_Level']].values.tolist()\n",
    "\n",
    "# Ejemplo de acceso a los datos\n",
    "print(\"Ejemplo de registros en lista:\")\n",
    "print(lista_anemia[:5])  # Imprime los primeros 5 registros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684d1c3",
   "metadata": {},
   "source": [
    "### 3.2 Pila (Stack)\n",
    "\n",
    "Las pilas siguen el principio LIFO (Last In, First Out) y son útiles si los datos se necesitan procesar en orden inverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c33f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pila:\n",
    "    def __init__(self):\n",
    "        self.stack = []\n",
    "\n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.stack.pop() if not self.is_empty() else None\n",
    "\n",
    "    def peek(self):\n",
    "        return self.stack[-1] if not self.is_empty() else None\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.stack) == 0\n",
    "\n",
    "# Crear una pila con los datos relevantes\n",
    "pila_anemia = Pila()\n",
    "for _, row in datos_transformados.iterrows():\n",
    "    pila_anemia.push({'Age_Group': row['Age_Group'], 'Anemia_Level': row['Anemia_Level']})\n",
    "\n",
    "# Ejemplo de uso de la pila\n",
    "print(\"Dato extraído de la pila:\", pila_anemia.pop())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba0311",
   "metadata": {},
   "source": [
    "### 3.3 Cola (Queue)\n",
    "\n",
    "Las colas siguen el principio FIFO (First In, First Out) y son útiles si los datos se deben procesar en el mismo orden en que se almacenaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d575a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Crear una cola con los datos relevantes\n",
    "cola_anemia = deque()\n",
    "for _, row in datos_transformados.iterrows():\n",
    "    cola_anemia.append({'Age_Group': row['Age_Group'], 'Anemia_Level': row['Anemia_Level']})\n",
    "\n",
    "# Ejemplo de uso de la cola\n",
    "print(\"Dato extraído de la cola:\", cola_anemia.popleft())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6a716e",
   "metadata": {},
   "source": [
    "# PRIMERA FUENTE DE DATOS: World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fa858-7856-46d3-8310-6a52568fffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - requests: para obtener datos de Internet.\n",
    "# - pandas: para organizar los datos en tablas.\n",
    "# - json: para trabajar con información en formato JSON.\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API del Banco Mundial donde están los datos de anemia infantil.\n",
    "base_url = \"http://api.worldbank.org/v2/country/ALL/indicator/SH.ANM.CHLD.ZS\"\n",
    "\n",
    "# Indicamos a la API que queremos los datos en formato JSON.\n",
    "params = {\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía donde guardaremos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Enviamos la solicitud a la API.\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Verificamos si la solicitud fue exitosa (código 200 significa éxito).\n",
    "if response.status_code == 200:\n",
    "    # Convertimos la respuesta de la API en un formato que Python pueda entender (JSON).\n",
    "    data = response.json()\n",
    "    \n",
    "    # Revisamos si hay datos útiles en la respuesta.\n",
    "    if len(data) > 1:  # Los datos que necesitamos están en la segunda parte de la respuesta.\n",
    "        all_data = data[1]  # Guardamos esos datos en nuestra lista.\n",
    "    else:\n",
    "        print(\"No se encontraron datos en la respuesta.\")\n",
    "else:\n",
    "    # Si ocurre un error, mostramos el código de error.\n",
    "    print(\"Error al obtener los datos:\", response.status_code)\n",
    "\n",
    "# Ahora, organizamos los datos en una tabla usando pandas.\n",
    "df_worldbank = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV (una hoja de cálculo).\n",
    "output_file = \"world_bank_anemia.csv\"\n",
    "df_worldbank.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo sin incluir índices.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70b340",
   "metadata": {},
   "source": [
    "# SEGUNDA FUENTE: Global Health Observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL de la API para datos de nutrición y anemia infantil.\n",
    "base_url = \"https://ghoapi.azureedge.net/api/NUTRITION_ANAEMIA_CHILDREN_NUM\"\n",
    "\n",
    "# Configuramos los parámetros para obtener los datos en partes (paginación):\n",
    "# - \"$top\": cuántos registros obtener por solicitud.\n",
    "# - \"$skip\": cuántos registros saltar para la siguiente solicitud.\n",
    "params = {\n",
    "    \"$top\": 1000,  # Pedimos 1000 registros por solicitud.\n",
    "    \"$skip\": 0     # Empezamos desde el inicio.\n",
    "}\n",
    "\n",
    "# Lista vacía para guardar todos los datos.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para seguir pidiendo datos hasta que no queden más.\n",
    "while True:\n",
    "    # Hacemos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Si la solicitud fue exitosa:\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en un formato JSON y agregamos los datos a nuestra lista.\n",
    "        data = response.json()\n",
    "        all_data.extend(data[\"value\"])  # Extendemos la lista con los nuevos datos.\n",
    "        \n",
    "        # Si la cantidad de datos obtenidos es menor que \"$top\", significa que no hay más datos.\n",
    "        if len(data[\"value\"]) < params[\"$top\"]:\n",
    "            break  # Terminamos el ciclo.\n",
    "        \n",
    "        # Si hay más datos, incrementamos \"$skip\" para pedir la siguiente página.\n",
    "        params[\"$skip\"] += params[\"$top\"]\n",
    "    else:\n",
    "        # Si ocurre un error, mostramos el código de error y terminamos el ciclo.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos en una tabla con pandas.\n",
    "df_anemia = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV.\n",
    "output_file = \"nutrition_anemia_children.csv\"\n",
    "df_anemia.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos el archivo.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que se creó el archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25d6c",
   "metadata": {},
   "source": [
    "# TERCERA FUENTE: DHS Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ffa11",
   "metadata": {},
   "source": [
    "### ENCUESTA 1: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER TIPO DE ANEMIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de nutrición (anemia en este caso).\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_ANY\"\n",
    "\n",
    "# Parámetros que se enviarán a la API:\n",
    "# - \"perpage\": número máximo de registros por solicitud (aquí pedimos 1000).\n",
    "# - \"page\": indica el número de la página que estamos solicitando (empezamos en la 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Máximo de registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la página 1.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para almacenar todos los datos obtenidos de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para descargar todos los datos disponibles en la API.\n",
    "while True:\n",
    "    # Realizamos una solicitud a la API con los parámetros actuales.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de respuesta 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta de la API a formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos dentro de la clave \"Data\" y los agregamos a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos:\n",
    "        # Si la cantidad de datos obtenidos es menor que el límite \"perpage\",\n",
    "        # significa que no hay más páginas que consultar.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código distinto de 200), mostramos el código de error y terminamos.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Una vez descargados todos los datos, los organizamos en una tabla con Pandas.\n",
    "df_any = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_any_anemia.csv\".\n",
    "output_file = \"df_any_anemia.csv\"\n",
    "df_any.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo se creó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871d90f",
   "metadata": {},
   "source": [
    "### ENCUESTA 2: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA LEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cc55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mld_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "# URL de la API del DHS para obtener datos de anemia infantil leve.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MLD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": cantidad máxima de datos que queremos recibir por solicitud (1000 aquí).\n",
    "# - \"page\": indica el número de página que solicitamos (iniciamos desde la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Empezamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Creamos una lista vacía para guardar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Usamos un ciclo para realizar solicitudes a la API hasta que descarguemos todos los datos.\n",
    "while True:\n",
    "    # Realizamos la solicitud a la API con los parámetros configurados.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código 200 indica éxito).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manejar en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Agregamos los datos obtenidos (clave \"Data\") a nuestra lista.\n",
    "        # Usamos \"get\" para evitar errores si la clave no existe.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si ya no hay más datos disponibles:\n",
    "        # Si el número de datos recibidos es menor al límite \"perpage\", hemos llegado al final.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque no hay más datos.\n",
    "        \n",
    "        # Si aún hay más datos, pasamos a la siguiente página incrementando el número de página.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (respuesta distinta de 200), mostramos un mensaje con el código de error.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Cuando terminamos de descargar los datos, los organizamos en una tabla usando pandas.\n",
    "df_mld = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mld_anemia.csv\".\n",
    "output_file = \"df_mld_anemia.csv\"\n",
    "df_mld.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d4460",
   "metadata": {},
   "source": [
    "### ENCUESTA 3: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA MODERADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_mod_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS para obtener datos de anemia infantil moderada.\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_MOD\"\n",
    "\n",
    "# Parámetros que enviamos a la API:\n",
    "# - \"perpage\": define el número máximo de registros a recibir por solicitud (en este caso, 1000).\n",
    "# - \"page\": indica el número de página que se solicita (empezamos en la página 1).\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Pedimos hasta 1000 registros por página.\n",
    "    \"page\": 1         # Comenzamos desde la primera página.\n",
    "}\n",
    "\n",
    "# Lista vacía para almacenar todos los datos descargados de la API.\n",
    "all_data = []\n",
    "\n",
    "# Ciclo para realizar solicitudes repetidas hasta que se descarguen todos los datos disponibles.\n",
    "while True:\n",
    "    # Realizamos una solicitud GET a la API utilizando la URL base y los parámetros definidos.\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificamos si la solicitud fue exitosa (código de estado 200).\n",
    "    if response.status_code == 200:\n",
    "        # Convertimos la respuesta en formato JSON (fácil de manipular en Python).\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraemos los datos de la clave \"Data\" y los agregamos a la lista \"all_data\".\n",
    "        # Usamos \"get\" para evitar errores si la clave no está presente.\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificamos si hemos llegado al final de los datos disponibles:\n",
    "        # Si el número de registros recibidos es menor que \"perpage\", significa que no hay más páginas.\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break  # Salimos del ciclo porque ya no hay más datos.\n",
    "        \n",
    "        # Si todavía hay más datos, incrementamos el número de página para la siguiente solicitud.\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # Si ocurre un error (código diferente de 200), mostramos el código de error y detenemos el proceso.\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Organizamos los datos descargados en una tabla (DataFrame) usando pandas.\n",
    "df_mod = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardamos la tabla en un archivo CSV llamado \"df_mod_anemia.csv\".\n",
    "output_file = \"df_mod_anemia.csv\"\n",
    "df_mod.to_csv(output_file, index=False, encoding=\"utf-8\")  # Guardamos sin incluir índices y en formato UTF-8.\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")  # Confirmamos que el archivo fue creado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea84f9",
   "metadata": {},
   "source": [
    "### ENCUESTA 4: PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON ANEMIA GRAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV creado exitosamente: df_sev_anemia.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# URL base de la API de DHS (Nutrición - Anemia infantil moderada)\n",
    "base_url = \"https://api.dhsprogram.com/rest/dhs/data/CN_ANMC_C_SEV\"\n",
    "\n",
    "# Definir los parámetros para la solicitud (si soporta paginación)\n",
    "params = {\n",
    "    \"perpage\": 1000,  # Número de registros por página (se solicita un máximo de 1000 registros por solicitud)\n",
    "    \"page\": 1         # Página inicial, comenzamos desde la primera página de resultados\n",
    "}\n",
    "\n",
    "# Lista para almacenar todos los datos que se vayan obteniendo\n",
    "all_data = []\n",
    "\n",
    "# Hacer varias solicitudes hasta obtener todos los datos (paginación)\n",
    "while True:\n",
    "    # Realizar la solicitud a la API utilizando los parámetros definidos\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        # Convertir la respuesta en formato JSON para manejar los datos\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extraer la lista de datos (\"Data\") de la respuesta JSON y agregarla a all_data\n",
    "        all_data.extend(data.get(\"Data\", []))\n",
    "        \n",
    "        # Verificar si hemos recibido menos registros de los solicitados, lo que indica que hemos llegado al final\n",
    "        if len(data.get(\"Data\", [])) < params[\"perpage\"]:\n",
    "            break\n",
    "        \n",
    "        # Incrementar el número de página para la siguiente solicitud\n",
    "        params[\"page\"] += 1\n",
    "    else:\n",
    "        # En caso de error, imprimir el código de estado de la respuesta\n",
    "        print(\"Error al obtener los datos:\", response.status_code)\n",
    "        break\n",
    "\n",
    "# Convertir los datos obtenidos (all_data) a un DataFrame de Pandas para facilitar su análisis\n",
    "df_sev = pd.json_normalize(all_data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "output_file = \"df_sev_anemia.csv\"\n",
    "df_sev.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Imprimir mensaje de éxito indicando que el archivo CSV fue creado correctamente\n",
    "print(f\"Archivo CSV creado exitosamente: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4eafdc",
   "metadata": {},
   "source": [
    "# CUARTA FUENTE: KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c426899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Ruta al archivo 'kaggle.json' que contiene las credenciales de acceso a la API de Kaggle\n",
    "kaggle_file_path = 'kaggle.json'\n",
    "\n",
    "# Leer el archivo JSON que contiene las credenciales\n",
    "with open(kaggle_file_path, 'r') as file:\n",
    "    kaggle_api = json.load(file)\n",
    "\n",
    "# Extraer el 'username' y la 'key' de las credenciales de Kaggle\n",
    "kaggle_username = kaggle_api['username']  # Obtiene el nombre de usuario de Kaggle\n",
    "kaggle_key = kaggle_api['key']  # Obtiene la clave de la API de Kaggle\n",
    "\n",
    "# Configurar las variables de entorno con las credenciales para acceder a la API de Kaggle\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_username  # Establece la variable de entorno para el nombre de usuario\n",
    "os.environ['KAGGLE_KEY'] = kaggle_key  # Establece la variable de entorno para la clave de la API\n",
    "\n",
    "# Imprimir un mensaje de confirmación indicando que las credenciales han sido configuradas correctamente\n",
    "print(\"Credenciales de Kaggle configuradas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ejecutar el comando para listar datasets relacionados con \"child anemia\" en Kaggle y capturar la salida\n",
    "result = subprocess.run(\n",
    "    [\"kaggle\", \"datasets\", \"list\", \"-s\", \"child anemia\"],  # El comando Kaggle para buscar datasets\n",
    "    capture_output=True,  # Captura tanto la salida estándar como los errores\n",
    "    text=True  # Decirle a subprocess que el resultado debe ser tratado como texto (en lugar de bytes)\n",
    ")\n",
    "\n",
    "# Imprimir la salida del comando ejecutado\n",
    "print(result.stdout)  # Muestra el resultado del comando (en este caso, la lista de datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ba11f",
   "metadata": {},
   "source": [
    "### DATA 1: Factores que afectan el nivel de anemia en los niños (Estudio en Nigeria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset a descargar desde Kaggle\n",
    "dataset_name = \"adeolaadesina/factors-affecting-children-anemia-level\"\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd78a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"children anemia.csv\"  # El nombre del archivo CSV descargado\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_nigeria = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso Nigeria)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac045c44",
   "metadata": {},
   "source": [
    "### DATA 2: Encuesta Nacional de Familia y Salud (Estudio en ¿India?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e08084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Nombre del dataset que quieres descargar desde Kaggle\n",
    "dataset_name = \"ravisinghiitbhu/nfhs5\"  # Identificador del dataset\n",
    "\n",
    "# Ejecutar el comando para descargar y descomprimir el dataset\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_name, \"--unzip\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcfff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Verifica el nombre del archivo descargado y ajústalo aquí\n",
    "csv_file = \"Final.csv\"  # Nombre del archivo CSV descargado desde Kaggle\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame de Pandas\n",
    "df_india = pd.read_csv(csv_file)\n",
    "\n",
    "# Confirmar que los datos se han leído correctamente\n",
    "print(\"Datos extraídos exitosamente de Kaggle (Caso India)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa73104",
   "metadata": {},
   "source": [
    "# **Módulo Análisis de Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c3fd4",
   "metadata": {},
   "source": [
    "## API: World Bank Prevalencia de anemia infantil (% de anemia infantil entre los 6-59 meses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586ad13",
   "metadata": {},
   "source": [
    "## 1. Limpieza de Datos\n",
    "### 1.1 Primera revisión del archivo para observar sus columnas y contenido de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'world_bank_anemia.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar una vista previa de los datos para analizar la estructura\n",
    "data.head(), data.info()\n",
    "\n",
    "# Obtener el nombre de las columnas\n",
    "columnas = data.columns.tolist()\n",
    "\n",
    "print(\"Nombres de las columnas:\", columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f100edc",
   "metadata": {},
   "source": [
    "### 1.2 Eliminamos las columnas innecesarias y filas sin valores de anemia, también redondeamos valores de anemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a68f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV original\n",
    "archivo_original = \"world_bank_anemia.csv\"  # Nombre de tu archivo\n",
    "df = pd.read_csv(archivo_original)\n",
    "\n",
    "# Especificar las columnas a eliminar\n",
    "columnas_a_eliminar = [\"unit\", \"obs_status\", \"decimal\", \"indicator.id\",\"countryiso3code\",\"country.id\", \"indicator.value\"]  # Cambia según lo que quieras eliminar\n",
    "\n",
    "# Redondear los valores de la columna \"value\" a 1 decimal\n",
    "df['value'] = df['value'].round(1)\n",
    "\n",
    "# Eliminar las columnas especificadas\n",
    "df_filtrado = df.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Eliminar filas donde la columna 'value' esté vacía\n",
    "world_bank_anemia_limpio = df_filtrado.dropna(subset=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d17731",
   "metadata": {},
   "source": [
    "## 2. Filtrar\n",
    "### 2.1 Filtrar CSV: Separación por países"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6237873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV original\n",
    "archivo_csv = \"world_bank_anemia_limpio.csv\"  # Reemplaza con la ruta a tu archivo\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Filtrar las filas desde \"Afghanistan\" hasta \"Zimbabwe\" en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "filtro_paises = world_bank_anemia_limpio[ultima_columna].str.strip().isin([\"Afghanistan\", \"Zimbabwe\"])  # Filtrar inicio y fin\n",
    "\n",
    "# Obtener los índices del rango\n",
    "inicio = world_bank_anemia_limpio[filtro_paises].index.min()  # Índice de \"Afghanistan\"\n",
    "fin = world_bank_anemia_limpio[filtro_paises].index.max()  # Índice de \"Zimbabwe\"\n",
    "\n",
    "# Seleccionar los datos dentro de este rango\n",
    "df_paises = world_bank_anemia_limpio.iloc[inicio:fin + 1]  # Incluye ambas filas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5241485",
   "metadata": {},
   "source": [
    "### 2.1.1 Mejoramos el nombre de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los nombres de las columnas\n",
    "df_paises = df_paises.rename(columns={\n",
    "    'date': 'year',\n",
    "    'value': 'prevalencia (%)',\n",
    "    'country.value': 'pais'\n",
    "})\n",
    "\n",
    "# Guardar el nuevo archivo CSV con los nombres de columnas cambiados\n",
    "archivo_csv_nuevo = \"world_bank_anemia_paises_listo.csv\"\n",
    "df.to_csv(archivo_csv_nuevo, index=False)\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32273f6f",
   "metadata": {},
   "source": [
    "### 2.2 Agrupar por continentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "file_path = 'world_bank_anemia_paises_listo.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Diccionario para mapear países a continentes\n",
    "country_to_continent = {\n",
    "    \"Afghanistan\": \"Asia\",\n",
    "    \"Albania\": \"Europe\",\n",
    "    \"Algeria\": \"Africa\",\n",
    "    \"Andorra\": \"Europe\",\n",
    "    \"Angola\": \"Africa\",\n",
    "    \"Antigua and Barbuda\": \"North America\",\n",
    "    \"Argentina\": \"South America\",\n",
    "    \"Armenia\": \"Asia\",\n",
    "    \"Australia\": \"Oceania\",\n",
    "    \"Austria\": \"Europe\",\n",
    "    \"Azerbaijan\": \"Asia\",\n",
    "    \"Bahamas\": \"North America\",\n",
    "    \"Bahamas, The\": \"North America\",\n",
    "    \"Bahrain\": \"Asia\",\n",
    "    \"Bangladesh\": \"Asia\",\n",
    "    \"Barbados\": \"North America\",\n",
    "    \"Belarus\": \"Europe\",\n",
    "    \"Belgium\": \"Europe\",\n",
    "    \"Belize\": \"North America\",\n",
    "    \"Benin\": \"Africa\",\n",
    "    \"Bhutan\": \"Asia\",\n",
    "    \"Bolivia\": \"South America\",\n",
    "    \"Bosnia and Herzegovina\": \"Europe\",\n",
    "    \"Botswana\": \"Africa\",\n",
    "    \"Brazil\": \"South America\",\n",
    "    \"Brunei Darussalam\": \"Asia\",\n",
    "    \"Bulgaria\": \"Europe\",\n",
    "    \"Burkina Faso\": \"Africa\",\n",
    "    \"Burundi\": \"Africa\",\n",
    "    \"Cabo Verde\": \"Africa\",\n",
    "    \"Cambodia\": \"Asia\",\n",
    "    \"Cameroon\": \"Africa\",\n",
    "    \"Canada\": \"North America\",\n",
    "    \"Central African Republic\": \"Africa\",\n",
    "    \"Chad\": \"Africa\",\n",
    "    \"Chile\": \"South America\",\n",
    "    \"China\": \"Asia\",\n",
    "    \"Colombia\": \"South America\",\n",
    "    \"Comoros\": \"Africa\",\n",
    "    \"Congo, Dem. Rep.\": \"Africa\",\n",
    "    \"Congo, Rep.\": \"Africa\",\n",
    "    \"Costa Rica\": \"North America\",\n",
    "    \"Cote d'Ivoire\": \"Africa\",\n",
    "    \"Croatia\": \"Europe\",\n",
    "    \"Cuba\": \"North America\",\n",
    "    \"Cyprus\": \"Asia\",\n",
    "    \"Czech Republic\": \"Europe\",\n",
    "    \"Czechia\": \"Europe\",\n",
    "    \"Denmark\": \"Europe\",\n",
    "    \"Djibouti\": \"Africa\",\n",
    "    \"Dominica\": \"North America\",\n",
    "    \"Dominican Republic\": \"North America\",\n",
    "    \"Ecuador\": \"South America\",\n",
    "    \"Egypt\": \"Africa\",\n",
    "    \"Egypt, Arab Rep.\": \"Africa\",\n",
    "    \"El Salvador\": \"North America\",\n",
    "    \"Equatorial Guinea\": \"Africa\",\n",
    "    \"Eritrea\": \"Africa\",\n",
    "    \"Estonia\": \"Europe\",\n",
    "    \"Eswatini\": \"Africa\",\n",
    "    \"Ethiopia\": \"Africa\",\n",
    "    \"Fiji\": \"Oceania\",\n",
    "    \"Finland\": \"Europe\",\n",
    "    \"France\": \"Europe\",\n",
    "    \"Gabon\": \"Africa\",\n",
    "    \"Gambia\": \"Africa\",\n",
    "    \"Gambia, The\": \"Africa\",\n",
    "    \"Georgia\": \"Asia\",\n",
    "    \"Germany\": \"Europe\",\n",
    "    \"Ghana\": \"Africa\",\n",
    "    \"Greece\": \"Europe\",\n",
    "    \"Grenada\": \"North America\",\n",
    "    \"Guatemala\": \"North America\",\n",
    "    \"Guinea\": \"Africa\",\n",
    "    \"Guinea-Bissau\": \"Africa\",\n",
    "    \"Guyana\": \"South America\",\n",
    "    \"Haiti\": \"North America\",\n",
    "    \"Honduras\": \"North America\",\n",
    "    \"Hungary\": \"Europe\",\n",
    "    \"Iceland\": \"Europe\",\n",
    "    \"India\": \"Asia\",\n",
    "    \"Indonesia\": \"Asia\",\n",
    "    \"Iran\": \"Asia\",\n",
    "    \"Iran, Islamic Rep.\": \"Asia\",\n",
    "    \"Iraq\": \"Asia\",\n",
    "    \"Ireland\": \"Europe\",\n",
    "    \"Israel\": \"Asia\",\n",
    "    \"Italy\": \"Europe\",\n",
    "    \"Jamaica\": \"North America\",\n",
    "    \"Japan\": \"Asia\",\n",
    "    \"Jordan\": \"Asia\",\n",
    "    \"Kazakhstan\": \"Asia\",\n",
    "    \"Kenya\": \"Africa\",\n",
    "    \"Kiribati\": \"Oceania\",\n",
    "    \"Korea, Dem. People's Rep.\": \"Asia\",\n",
    "    \"Korea, Dem. Rep.\": \"Asia\",\n",
    "    \"Korea, Rep.\": \"Asia\",\n",
    "    \"Kuwait\": \"Asia\",\n",
    "    \"Kyrgyz Republic\": \"Asia\",\n",
    "    \"Kyrgyzstan\": \"Asia\",\n",
    "    \"Lao PDR\": \"Asia\",\n",
    "    \"Latvia\": \"Europe\",\n",
    "    \"Lebanon\": \"Asia\",\n",
    "    \"Lesotho\": \"Africa\",\n",
    "    \"Liberia\": \"Africa\",\n",
    "    \"Libya\": \"Africa\",\n",
    "    \"Liechtenstein\": \"Europe\",\n",
    "    \"Lithuania\": \"Europe\",\n",
    "    \"Luxembourg\": \"Europe\",\n",
    "    \"Madagascar\": \"Africa\",\n",
    "    \"Malawi\": \"Africa\",\n",
    "    \"Malaysia\": \"Asia\",\n",
    "    \"Maldives\": \"Asia\",\n",
    "    \"Mali\": \"Africa\",\n",
    "    \"Malta\": \"Europe\",\n",
    "    \"Marshall Islands\": \"Oceania\",\n",
    "    \"Mauritania\": \"Africa\",\n",
    "    \"Mauritius\": \"Africa\",\n",
    "    \"Mexico\": \"North America\",\n",
    "    \"Micronesia, Fed. Sts.\": \"Oceania\",\n",
    "    \"Moldova\": \"Europe\",\n",
    "    \"Monaco\": \"Europe\",\n",
    "    \"Mongolia\": \"Asia\",\n",
    "    \"Montenegro\": \"Europe\",\n",
    "    \"Morocco\": \"Africa\",\n",
    "    \"Mozambique\": \"Africa\",\n",
    "    \"Myanmar\": \"Asia\",\n",
    "    \"Namibia\": \"Africa\",\n",
    "    \"Nauru\": \"Oceania\",\n",
    "    \"Nepal\": \"Asia\",\n",
    "    \"Netherlands\": \"Europe\",\n",
    "    \"New Zealand\": \"Oceania\",\n",
    "    \"Nicaragua\": \"North America\",\n",
    "    \"Niger\": \"Africa\",\n",
    "    \"Nigeria\": \"Africa\",\n",
    "    \"North Macedonia\": \"Europe\",\n",
    "    \"Norway\": \"Europe\",\n",
    "    \"Oman\": \"Asia\",\n",
    "    \"Pakistan\": \"Asia\",\n",
    "    \"Palau\": \"Oceania\",\n",
    "    \"Panama\": \"North America\",\n",
    "    \"Papua New Guinea\": \"Oceania\",\n",
    "    \"Paraguay\": \"South America\",\n",
    "    \"Peru\": \"South America\",\n",
    "    \"Philippines\": \"Asia\",\n",
    "    \"Poland\": \"Europe\",\n",
    "    \"Portugal\": \"Europe\",\n",
    "    \"Qatar\": \"Asia\",\n",
    "    \"Romania\": \"Europe\",\n",
    "    \"Russian Federation\": \"Europe\",\n",
    "    \"Rwanda\": \"Africa\",\n",
    "    \"Samoa\": \"Oceania\",\n",
    "    \"San Marino\": \"Europe\",\n",
    "    \"Sao Tome and Principe\": \"Africa\",\n",
    "    \"Saudi Arabia\": \"Asia\",\n",
    "    \"Senegal\": \"Africa\",\n",
    "    \"Serbia\": \"Europe\",\n",
    "    \"Seychelles\": \"Africa\",\n",
    "    \"Sierra Leone\": \"Africa\",\n",
    "    \"Singapore\": \"Asia\",\n",
    "    \"Slovak Republic\": \"Europe\",\n",
    "    \"Slovenia\": \"Europe\",\n",
    "    \"Solomon Islands\": \"Oceania\",\n",
    "    \"Somalia\": \"Africa\",\n",
    "    \"South Africa\": \"Africa\",\n",
    "    \"South Sudan\": \"Africa\",\n",
    "    \"Spain\": \"Europe\",\n",
    "    \"Sri Lanka\": \"Asia\",\n",
    "    \"St. Kitts and Nevis\": \"North America\",\n",
    "    \"St. Lucia\": \"North America\",\n",
    "    \"St. Vincent and the Grenadines\": \"North America\",\n",
    "    \"Sudan\": \"Africa\",\n",
    "    \"Suriname\": \"South America\",\n",
    "    \"Sweden\": \"Europe\",\n",
    "    \"Switzerland\": \"Europe\",\n",
    "    \"Syrian Arab Republic\": \"Asia\",\n",
    "    \"Tajikistan\": \"Asia\",\n",
    "    \"Tanzania\": \"Africa\",\n",
    "    \"Thailand\": \"Asia\",\n",
    "    \"Timor-Leste\": \"Asia\",\n",
    "    \"Togo\": \"Africa\",\n",
    "    \"Tonga\": \"Oceania\",\n",
    "    \"Trinidad and Tobago\": \"North America\",\n",
    "    \"Tunisia\": \"Africa\",\n",
    "    \"Turkey\": \"Asia\",\n",
    "    \"Turkmenistan\": \"Asia\",\n",
    "    \"Tuvalu\": \"Oceania\",\n",
    "    \"Uganda\": \"Africa\",\n",
    "    \"Ukraine\": \"Europe\",\n",
    "    \"United Arab Emirates\": \"Asia\",\n",
    "    \"United Kingdom\": \"Europe\",\n",
    "    \"United States\": \"North America\",\n",
    "    \"Uruguay\": \"South America\",\n",
    "    \"Uzbekistan\": \"Asia\",\n",
    "    \"Vanuatu\": \"Oceania\",\n",
    "    \"Venezuela\": \"South America\",\n",
    "    \"Venezuela, RB\": \"South America\",\n",
    "    \"Vietnam\": \"Asia\",\n",
    "    \"Viet Nam\": \"Asia\",\n",
    "    \"West Bank and Gaza\": \"Asia\",\n",
    "    \"Yemen\": \"Asia\",\n",
    "    \"Yemen, Rep.\": \"Asia\",\n",
    "    \"Zambia\": \"Africa\",\n",
    "    \"Zimbabwe\": \"Africa\"\n",
    "}\n",
    "\n",
    "# Crear la nueva columna \"Continente\"\n",
    "data['Continente'] = data['country.value'].map(country_to_continent)\n",
    "\n",
    "# Ordenar los países por continente y luego por nombre\n",
    "sorted_data = data.sort_values(by=['Continente', 'country.value'])\n",
    "\n",
    "# Guardar el archivo CSV resultante\n",
    "output_path = 'world_bank_continentes.csv'\n",
    "sorted_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo generado: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e30ff8",
   "metadata": {},
   "source": [
    "### 2.3 Filtrar CSV: Separación por ingresos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a filtrar en la última columna\n",
    "valores_deseados = [\n",
    "    \"High income\",\n",
    "    \"Low & middle income\",\n",
    "    \"Low income\",\n",
    "    \"Middle income\",\n",
    "    \"Upper middle income\"\n",
    "]\n",
    "\n",
    "# Filtrar las filas que contienen estos valores en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "world_bank_anemia_filtrado = world_bank_anemia_limpio[world_bank_anemia_limpio[ultima_columna].str.strip().isin(valores_deseados)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2c2d6",
   "metadata": {},
   "source": [
    "### 2.3.1 Mejoramos el nombre de las columnas y valor de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los nombres de las columnas\n",
    "world_bank_anemia_filtrado = world_bank_anemia_filtrado.rename(columns={\n",
    "    'date': 'year',\n",
    "    'value': 'prevalencia (%)',\n",
    "    'country.value': 'nivel de ingresos'\n",
    "})\n",
    "\n",
    "# Modificar los valores de la columna \"nivel de ingresos\"\n",
    "world_bank_anemia_filtrado['nivel de ingresos'] = world_bank_anemia_filtrado['nivel de ingresos'].replace({\n",
    "    'High income': 'Ingresos altos',\n",
    "    'Low & middle income': 'Ingresos bajos y medios',\n",
    "    'Low income': 'Bajos ingresos',\n",
    "    'Middle income': 'Ingreso medio',\n",
    "    'Upper middle income': 'Ingreso medio alto',\n",
    "    'Lower middle income': 'Ingreso medio bajo'\n",
    "})\n",
    "\n",
    "# Guardar el nuevo archivo CSV con los nombres de columnas cambiados\n",
    "archivo_csv_nuevo = \"world_bank_anemia_ingresos_listo.csv\"\n",
    "world_bank_anemia_filtrado.to_csv(archivo_csv_nuevo, index=False)\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfe85f",
   "metadata": {},
   "source": [
    "### 2.4 Filtrar CSV: A nivel mundial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758607a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a filtrar en la última columna\n",
    "valores_deseados = [\n",
    "    \"World\"\n",
    "]\n",
    "\n",
    "# Filtrar las filas que contienen estos valores en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "df_filtrado = world_bank_anemia_limpio[world_bank_anemia_limpio[ultima_columna].str.strip().isin(valores_deseados)]\n",
    "\n",
    "# Guardar en un nuevo archivo CSV\n",
    "nuevo_csv = \"world_bank_anemia_mundial.csv\"\n",
    "df_filtrado.to_csv(nuevo_csv, index=False)\n",
    "\n",
    "print(f\"Datos filtrados guardados en: {nuevo_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acf850",
   "metadata": {},
   "source": [
    "### 2.4.1 Mejoramos el nombre de las columnas y valor de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09573696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "archivo_csv = \"world_bank_anemia_mundial.csv\"  # Asegúrate de que el archivo esté en la misma carpeta o proporciona la ruta completa\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Cambiar los nombres de las columnas\n",
    "df = df.rename(columns={\n",
    "    'date': 'year',\n",
    "    'value': 'prevalencia (%)',\n",
    "    'country.value': 'nivel geográfico'\n",
    "})\n",
    "\n",
    "# Modificar los valores de la columna \"nivel de ingresos\"\n",
    "df['nivel geográfico'] = df['nivel geográfico'].replace({\n",
    "    'World': 'Mundial'\n",
    "})\n",
    "\n",
    "# Guardar el nuevo archivo CSV con los nombres de columnas cambiados\n",
    "archivo_csv_nuevo = \"world_bank_anemia_mundial_listo.csv\"\n",
    "df.to_csv(archivo_csv_nuevo, index=False)\n",
    "\n",
    "print(f\"Archivo con las columnas renombradas guardado como {archivo_csv_nuevo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10867ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores a filtrar en la última columna\n",
    "valores_deseados = [\n",
    "    \"World\"\n",
    "]\n",
    "\n",
    "# Filtrar las filas que contienen estos valores en la última columna\n",
    "ultima_columna = world_bank_anemia_limpio.columns[-1]  # Nombre de la última columna\n",
    "df_filtrado = world_bank_anemia_limpio[world_bank_anemia_limpio[ultima_columna].str.strip().isin(valores_deseados)]\n",
    "\n",
    "# Guardar en un nuevo archivo CSV\n",
    "nuevo_csv = \"world_bank_anemia_mundial.csv\"\n",
    "df_filtrado.to_csv(nuevo_csv, index=False)\n",
    "\n",
    "print(f\"Datos filtrados guardados en: {nuevo_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd86c1",
   "metadata": {},
   "source": [
    "# API: Demographic Health Survey (PORCENTAJE DE NIÑOS MENORES A 5 AÑOS CLASIFICADOS CON CUALQUIER/LEVE/MODERADO/SEVERO NIVEL DE ANEMIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaaa741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'df_any_anemia.csv'\n",
    "any = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "mild = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "mod = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'df_mld_anemia.csv'\n",
    "sev = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd82ca2",
   "metadata": {},
   "source": [
    "## 1. Limpieza de Datos\n",
    "\n",
    "### 1.1 Eliminación de columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb467ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a eliminar\n",
    "columns_to_drop = ['DataId', 'SurveyId', 'Indicator', 'IsPreferred', 'SDRID', 'Precision', 'RegionId', 'SurveyType',\n",
    "'IndicatorId', 'CharacteristicOrder', 'CharacteristicLabel',  'ByVariableLabel', 'CIHigh', 'IsTotal', 'ByVariableId',\n",
    "                   'IndicatorOrder', 'DHS_CountryCode',  'CILow', 'LevelRank', 'CharacteristicId', 'CharacteristicCategory'\n",
    "                 , 'IndicatorType',\n",
    "                   'DenominatorUnweighted','DenominatorWeighted', \"SurveyYearLabel\", \"Value\"\n",
    "]\n",
    "\n",
    "# Eliminar las columnas no deseadas\n",
    "df_cleaned0 = any.drop(columns=columns_to_drop)\n",
    "df_cleaned1 = mild.drop(columns=columns_to_drop)\n",
    "df_cleaned2 = mod.drop(columns=columns_to_drop)\n",
    "df_cleaned3 = sev.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5653c7",
   "metadata": {},
   "source": [
    "## 1.2 Mejorar nombres de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo dataframe con las columnas especificadas\n",
    "df_combined = pd.DataFrame({\n",
    "    'Year': any['SurveyYear'],  # SurveyYear de 'any'\n",
    "    'Pais': any['CountryName'],  # CountryName de 'any'\n",
    "\n",
    "    'Valor Cualquier': any['Value'],  # Value de 'any' renombrado\n",
    "    '# Encuestas (any, sin ponderar)': any['DenominatorUnweighted'],  # DenominatorUnweighted de 'any'\n",
    "    '# Encuestas (any, ponderadas)': any['DenominatorWeighted'],  # DenominatorWeighted de 'any'\n",
    "\n",
    "    'Valor Leve': mild['Value'],  # Value de 'mild' renombrado\n",
    "    '# Encuestas (mild, sin ponderar)': mild['DenominatorUnweighted'],  # DenominatorUnweighted de 'mild'\n",
    "    '# Encuestas (mild, ponderadas)': mild['DenominatorWeighted'],  # DenominatorWeighted de 'mild'\n",
    "\n",
    "    'Valor Moderado': mod['Value'],  # Value de 'mod' renombrado\n",
    "    '# Encuestas (mod, sin ponderar)': mod['DenominatorUnweighted'],  # DenominatorUnweighted de 'mod'\n",
    "    '# Encuestas (mod, ponderadas)': mod['DenominatorWeighted'],  # DenominatorWeighted de 'mod'\n",
    "\n",
    "    'Valor Severo': sev['Value'],  # Value de 'sev' renombrado\n",
    "    '# Encuestas (sev, sin ponderar)': sev['DenominatorUnweighted'],  # DenominatorUnweighted de 'sev'\n",
    "    '# Encuestas (sev, ponderadas)': sev['DenominatorWeighted']  # DenominatorWeighted de 'sev'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Guardar el dataframe combinado como un nuevo archivo CSV\n",
    "output_file_combined = 'dhs_anemia_final.csv'\n",
    "df_combined.to_csv(output_file_combined, index=False)\n",
    "\n",
    "# Imprimir la ruta del archivo guardado\n",
    "print(f\"Archivo guardado en: {output_file_combined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e869f",
   "metadata": {},
   "source": [
    "# API KAGGLE (FACTORES QUE PODRIAN ESTAR INFLUENCIANDO EL NIVEL DE ANEMIA EN NIÑOS DE 0-59 MESES) - Caso: Nigeria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbf9d5",
   "metadata": {},
   "source": [
    "## Descripción del caso\n",
    "\n",
    "En este estudio, se recopilaron datos transversales de las Encuestas demográficas y de salud de Nigeria (NDHS) de 2018 para responder a preguntas de investigación sobre el efecto de la edad de las madres y otros factores socioeconómicos en el nivel de anemia de los niños de 0 a 59 meses en Nigeria. Las DHS son encuestas transversales de hogares representativas a nivel nacional que generalmente se realizan cada 5 años. Los datos de esta encuesta consideraron los 36 estados de Nigeria, así como el Territorio de la Capital Federal (FCT). La población objetivo de este estudio son los niños de 0 a 59 meses y las madres de 15 a 49 años. En esta encuesta, el ingreso del hogar se midió utilizando el índice de riqueza, la edad actual en grupos de 5 años se produce agrupando la edad actual en años completados, tipo de lugar de residencia donde el encuestado fue entrevistado como urbano o rural, la categorización se creó en función de si el número de punto de muestra o conglomerado se define como urbano o rural, el nivel más alto de educación alcanzado es una variable estandarizada que proporciona el nivel de educación en las siguientes categorías: Sin educación, Educación primaria, secundaria y superior, el número total de nacimientos en los últimos cinco años se define como todos los nacimientos en los meses 0 a 59 anteriores al mes de la entrevista, donde el mes 0 es el mes de la entrevista, la edad del encuestado en el primer nacimiento se calcula utilizando el CMC de la fecha de nacimiento del encuestado.\n",
    "\n",
    "Después de la depuración de los datos, se utilizó el método Chi cuadrado para probar las hipótesis sobre la posible relación que existe entre ciertos factores socioeconómicos y los niveles de anemia en niños de 0 a 59 meses. El nivel de anemia fue la variable predictora y las variables explicativas son la edad de la madre, el nivel de educación, el índice de riqueza, el nacimiento en los últimos cinco años, el uso de mosquiteros, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22df03b",
   "metadata": {},
   "source": [
    "# Diccionario de datos\n",
    "\n",
    "```Python\n",
    "Type of place of residence\n",
    "0: Rural\n",
    "1: Urban\n",
    "\n",
    "\n",
    "Highest educational level\n",
    "0: Higher\n",
    "1: No education\n",
    "2: Primary\n",
    "3: Secondary\n",
    "\n",
    "\n",
    "Wealth index combined\n",
    "0: Middle\n",
    "1: Poorer\n",
    "2: Poorest\n",
    "3: Richer\n",
    "4: Richest\n",
    "\n",
    "\n",
    "Anemia level\n",
    "0: Mild\n",
    "1: Moderate\n",
    "2: Not anemic\n",
    "3: Severe\n",
    "\n",
    "\n",
    "Have mosquito bed net for sleeping (from household questionnaire)\n",
    "0: No\n",
    "1: Yes\n",
    "\n",
    "\n",
    "Smokes cigarettes\n",
    "0: No\n",
    "1: Yes\n",
    "\n",
    "\n",
    "Current marital status\n",
    "0: Divorced\n",
    "1: Living with partner\n",
    "2: Married\n",
    "3: Never in union\n",
    "4: No longer living together/separated\n",
    "5: Widowed\n",
    "\n",
    "\n",
    "Currently residing with husband/partner\n",
    "0: Living with her\n",
    "1: Staying elsewhere\n",
    "\n",
    "\n",
    "When child put to breast\n",
    "0: 102.0\n",
    "1: 103.0\n",
    "2: 104.0\n",
    "... (continuando con valores similares)\n",
    "38: Days: 1\n",
    "39: Hours: 1\n",
    "40: Immediately\n",
    "\n",
    "\n",
    "Had fever in last two weeks\n",
    "0: Don't know\n",
    "1: No\n",
    "2: Yes\n",
    "\n",
    "\n",
    "Taking iron pills, sprinkles or syrup\n",
    "0: Don't know\n",
    "1: No\n",
    "2: Yes\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eca8bd",
   "metadata": {},
   "source": [
    "## 1. Implementacion de funciones para limpiar, ordenar y transformar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo proporcionado por el usuario\n",
    "file_path = 'children anemia.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar una vista previa de los datos para analizar la estructura\n",
    "data.head(), data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43091910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para limpiar, ordenar y transformar los datos\n",
    "def limpiar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Limpia los datos eliminando columnas duplicadas, renombrando columnas y gestionando valores faltantes.\n",
    "    \"\"\"\n",
    "    # Eliminar columnas duplicadas o irrelevantes\n",
    "    columnas_a_eliminar = ['Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)',\n",
    "                           'Anemia level.1']\n",
    "    dataframe = dataframe.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "    # Renombrar columnas para mayor claridad\n",
    "    dataframe = dataframe.rename(columns={\n",
    "        'Age in 5-year groups': 'Age_Group',\n",
    "        'Type of place of residence': 'Residence_Type',\n",
    "        'Highest educational level': 'Education_Level',\n",
    "        'Wealth index combined': 'Wealth_Index',\n",
    "        'Births in last five years': 'Births_Last_5_Years',\n",
    "        'Age of respondent at 1st birth': 'Age_First_Birth',\n",
    "        'Anemia level': 'Anemia_Level',\n",
    "        'Have mosquito bed net for sleeping (from household questionnaire)': 'Mosquito_Net',\n",
    "        'Smokes cigarettes': 'Smokes',\n",
    "        'Current marital status': 'Marital_Status',\n",
    "        'Currently residing with husband/partner': 'Residing_With_Partner',\n",
    "        'When child put to breast': 'Breastfeeding_Timing',\n",
    "        'Had fever in last two weeks': 'Fever_Last_2_Weeks',\n",
    "        'Hemoglobin level adjusted for altitude (g/dl - 1 decimal)': 'Hemoglobin_Level',\n",
    "        'Taking iron pills, sprinkles or syrup': 'Iron_Supplements'\n",
    "    })\n",
    "\n",
    "    # Manejo de valores faltantes\n",
    "    dataframe['Anemia_Level'] = dataframe['Anemia_Level'].fillna('Unknown')  # Llenar valores faltantes de anemia con \"Unknown\"\n",
    "    dataframe = dataframe.dropna(subset=['Hemoglobin_Level', 'Education_Level'])  # Eliminar filas con valores críticos faltantes\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def transformar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Transforma los datos categóricos a variables numéricas y estandariza las columnas.\n",
    "    \"\"\"\n",
    "    # Convertir categorías a valores numéricos\n",
    "    categoricas_a_codificar = ['Residence_Type', 'Education_Level', 'Wealth_Index', 'Anemia_Level',\n",
    "                               'Mosquito_Net', 'Smokes', 'Marital_Status', 'Residing_With_Partner',\n",
    "                               'Breastfeeding_Timing', 'Fever_Last_2_Weeks', 'Iron_Supplements']\n",
    "\n",
    "    for columna in categoricas_a_codificar:\n",
    "        dataframe[columna] = dataframe[columna].astype('category').cat.codes\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'children anemia.csv'  # Reemplaza con la ruta del archivo en tu sistema\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Aplicar funciones al dataset\n",
    "datos_limpios = limpiar_datos(data)\n",
    "datos_transformados = transformar_datos(datos_limpios)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame transformado\n",
    "print(datos_transformados.head())\n",
    "\n",
    "# Guardar los datos transformados en un archivo CSV\n",
    "datos_transformados.to_csv('datos_limpios_transformados.csv', index=False)\n",
    "print(\"Datos guardados como 'datos_limpios_transformados.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493c51e",
   "metadata": {},
   "source": [
    "## 2. Calcular métricas como media, mediana, moda, y otras estadísticas relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be42b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_avanzadas(dataframe):\n",
    "    \"\"\"\n",
    "    Calcula métricas descriptivas avanzadas como percentiles, asimetría, curtosis y más.\n",
    "    \"\"\"\n",
    "    # Seleccionar columnas numéricas\n",
    "    columnas_numericas = dataframe.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "    # Crear un diccionario para almacenar las métricas\n",
    "    estadisticas = {}\n",
    "\n",
    "    for columna in columnas_numericas.columns:\n",
    "        estadisticas[columna] = {\n",
    "            'Media': columnas_numericas[columna].mean(),\n",
    "            'Mediana': columnas_numericas[columna].median(),\n",
    "            'Moda': columnas_numericas[columna].mode().iloc[0] if not columnas_numericas[columna].mode().empty else None,\n",
    "            'Desviación Estándar': columnas_numericas[columna].std(),\n",
    "            'Mínimo': columnas_numericas[columna].min(),\n",
    "            'Máximo': columnas_numericas[columna].max(),\n",
    "            'Rango': columnas_numericas[columna].max() - columnas_numericas[columna].min(),\n",
    "            'Percentil 25': columnas_numericas[columna].quantile(0.25),\n",
    "            'Percentil 75': columnas_numericas[columna].quantile(0.75),\n",
    "            'Asimetría': columnas_numericas[columna].skew(),\n",
    "            'Curtosis': columnas_numericas[columna].kurt(),\n",
    "            'Rango Intercuartílico (IQR)': columnas_numericas[columna].quantile(0.75) - columnas_numericas[columna].quantile(0.25),\n",
    "            'Coeficiente de Variación (CV)': columnas_numericas[columna].std() / columnas_numericas[columna].mean(),\n",
    "        }\n",
    "\n",
    "    # Convertir a un DataFrame para mejor visualización\n",
    "    estadisticas_df = pd.DataFrame(estadisticas).transpose()\n",
    "    return estadisticas_df\n",
    "\n",
    "\n",
    "# Calcular métricas avanzadas\n",
    "metricas_avanzadas = calcular_metricas_avanzadas(datos_transformados)\n",
    "\n",
    "# Mostrar las métricas avanzadas\n",
    "print(metricas_avanzadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1795277",
   "metadata": {},
   "source": [
    "## 3. Estructuras de datos (listas, pilas, colas) que faciliten el análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d0498",
   "metadata": {},
   "source": [
    "### 3.1 Lista\n",
    "\n",
    "Las listas son ideales para almacenar datos tabulares o registros específicos que se necesitan procesar en secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer datos relevantes y almacenarlos en una lista\n",
    "lista_anemia = datos_transformados[['Age_Group', 'Anemia_Level', 'Hemoglobin_Level']].values.tolist()\n",
    "\n",
    "# Ejemplo de acceso a los datos\n",
    "print(\"Ejemplo de registros en lista:\")\n",
    "print(lista_anemia[:5])  # Imprime los primeros 5 registros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684d1c3",
   "metadata": {},
   "source": [
    "### 3.2 Pila (Stack)\n",
    "\n",
    "Las pilas siguen el principio LIFO (Last In, First Out) y son útiles si los datos se necesitan procesar en orden inverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c33f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pila:\n",
    "    def __init__(self):\n",
    "        self.stack = []\n",
    "\n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.stack.pop() if not self.is_empty() else None\n",
    "\n",
    "    def peek(self):\n",
    "        return self.stack[-1] if not self.is_empty() else None\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.stack) == 0\n",
    "\n",
    "# Crear una pila con los datos relevantes\n",
    "pila_anemia = Pila()\n",
    "for _, row in datos_transformados.iterrows():\n",
    "    pila_anemia.push({'Age_Group': row['Age_Group'], 'Anemia_Level': row['Anemia_Level']})\n",
    "\n",
    "# Ejemplo de uso de la pila\n",
    "print(\"Dato extraído de la pila:\", pila_anemia.pop())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba0311",
   "metadata": {},
   "source": [
    "### 3.3 Cola (Queue)\n",
    "\n",
    "Las colas siguen el principio FIFO (First In, First Out) y son útiles si los datos se deben procesar en el mismo orden en que se almacenaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d575a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Crear una cola con los datos relevantes\n",
    "cola_anemia = deque()\n",
    "for _, row in datos_transformados.iterrows():\n",
    "    cola_anemia.append({'Age_Group': row['Age_Group'], 'Anemia_Level': row['Anemia_Level']})\n",
    "\n",
    "# Ejemplo de uso de la cola\n",
    "print(\"Dato extraído de la cola:\", cola_anemia.popleft())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24f61b",
   "metadata": {},
   "source": [
    "## API: Global Health Observatory - Prevalencia de anemia infantil (% de anemia infantil entre los 6-59 meses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38397a5",
   "metadata": {},
   "source": [
    "## 1. Analisis de datos inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la API para la prevalencia de anemia (sustituir con el código correcto)\n",
    "indicator_code = \"NUTRITION_ANAEMIA_CHILDREN_PREV\"  # Cambia a la API para prevalencia de anemia\n",
    "url = f\"https://ghoapi.azureedge.net/api/{indicator_code}\"\n",
    "\n",
    "# Realizar la solicitud\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificar que la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Extraer los datos en formato JSON\n",
    "\n",
    "    # Convertir los datos a un DataFrame\n",
    "    df = pd.json_normalize(data['value'])\n",
    "    # Mostrar las primeras filas\n",
    "    print(df.head(48))\n",
    "\n",
    "else:\n",
    "    print(f\"Error al acceder a la API: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f3d2e",
   "metadata": {},
   "source": [
    "## **2. Limpieza de datos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6d448",
   "metadata": {},
   "source": [
    "### **2.1 Eliminación de filas y columnas sin datos**\n",
    "\n",
    "*   Elemento de la lista\n",
    "*   Elemento de la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Eliminar columnas con valores nulos\n",
    "df_cleaned = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columnas después de la limpieza:\")\n",
    "print(df_cleaned.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3586ee3",
   "metadata": {},
   "source": [
    "### **2.2 Imputación de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd25d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas específicas\n",
    "# Asegúrate de que los nombres de las columnas coincidan exactamente con los del DataFrame\n",
    "columnas_deseadas = ['SpatialDimType', 'SpatialDim', 'Dim1Type', 'TimeDim','NumericValue', 'Low', 'High']\n",
    "# Elimina espacios extra en ' Dim1Type' y 'TimeDim '\n",
    "\n",
    "# Verificar si las columnas existen antes de seleccionarlas\n",
    "columnas_existentes = df_cleaned.columns\n",
    "columnas_deseadas = [col for col in columnas_deseadas if col in columnas_existentes]\n",
    "\n",
    "df_seleccion = df_cleaned[columnas_deseadas]\n",
    "\n",
    "print(df_seleccion.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e24952",
   "metadata": {},
   "source": [
    "## 3. Organización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Asegurando que la columna tiene valores correctos\n",
    "# Aquí supongo que df es tu DataFrame\n",
    "df['SpatialDim'] = df['SpatialDim'].astype(str)\n",
    "\n",
    "# Filtrar los valores no numéricos y encontrar la moda\n",
    "moda_no_numerica = df[~df['SpatialDim'].str.isnumeric()]['SpatialDim'].mode()[0]\n",
    "\n",
    "# Reemplazar los valores numéricos por la moda\n",
    "df['SpatialDim'] = df['SpatialDim'].apply(lambda x: moda_no_numerica if x.isnumeric() else x)\n",
    "\n",
    "# Mostrar los primeros registros para verificar\n",
    "print(df_seleccion.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ddea5",
   "metadata": {},
   "source": [
    "### **3.1 Obtener años únicos por país en un DataFrame ordenado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27214e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los años únicos por cada valor de SpatialDim\n",
    "years_by_spatialdim = df[df['SpatialDimType'] == 'COUNTRY'].groupby('SpatialDim')['TimeDim'].unique()\n",
    "\n",
    "# Convertir a un DataFrame para una mejor presentación\n",
    "result = years_by_spatialdim.apply(sorted).reset_index(name='Years')\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa255d04",
   "metadata": {},
   "source": [
    "#### **3.2 COMPARAR AÑOS CON MAYOR Y MENOR PROMEDIO USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar promedios anuales\n",
    "year_averages = []\n",
    "\n",
    "# Calcular promedio por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    values = list(df[df['TimeDim'] == year]['NumericValue'])\n",
    "    avg = sum(values) / len(values)\n",
    "    year_averages.append((year, avg))\n",
    "\n",
    "# Ordenar por promedio\n",
    "year_averages.sort(key=lambda x: x[1])\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Año con menor promedio: {year_averages[0][0]} - Promedio: {year_averages[0][1]:.2f}\")\n",
    "print(f\"Año con mayor promedio: {year_averages[-1][0]} - Promedio: {year_averages[-1][1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b619d",
   "metadata": {},
   "source": [
    "#### **4.1 PREVALENCIA DE ANEMIA POR CADA AÑO EN LOS DIFERENTES PAISES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe06dd",
   "metadata": {},
   "source": [
    "# Filtrar registros donde SpatialDimType sea \"COUNTRY\"\n",
    "df_filtered = df[df['SpatialDimType'] == 'COUNTRY']\n",
    "\n",
    "# Calcular el promedio de prevalencia de anemia por país y año\n",
    "average_anemia = df_filtered.groupby(['SpatialDim', 'TimeDim'])['NumericValue'].mean().reset_index()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "average_anemia.columns = ['Country', 'Year', 'AveragePrevalence']\n",
    "\n",
    "# Mostrar los primeros registros del resultado\n",
    "print(average_anemia.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18537e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.1.1 Descargar el archivo en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import pandas as pd\n",
    "\n",
    "# ... (Your existing code to generate average_anemia DataFrame) ...\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "average_anemia.to_csv('PREVALENCIA_DE_ANEMIA_POR_CADA_AÑO_EN_LOS_DIFERENTES_PAISES.csv', index=False)\n",
    "\n",
    "# Download the CSV file\n",
    "files.download('PREVALENCIA_DE_ANEMIA_POR_CADA_AÑO_EN_LOS_DIFERENTES_PAISES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ceb18",
   "metadata": {},
   "source": [
    "#### **4.2 PROMEDIO DE PREVALENCIA POR PAÍS USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88983598",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Lista para almacenar los promedios\n",
    "country_averages = []\n",
    "\n",
    "# Agrupar por país y calcular el promedio manualmente\n",
    "for country in df['SpatialDim'].unique():\n",
    "    if df[df['SpatialDim'] == country]['SpatialDimType'].iloc[0] == 'COUNTRY':\n",
    "        prevalences = list(df[df['SpatialDim'] == country]['NumericValue'])\n",
    "        avg_prevalence = sum(prevalences) / len(prevalences)\n",
    "        country_averages.append((country, avg_prevalence))\n",
    "\n",
    "# Mostrar los resultados\n",
    "for country, avg in country_averages:\n",
    "    print(f\"{country}: {avg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e31b5",
   "metadata": {},
   "source": [
    "### 4.2.1 Descargar el archivo en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame a partir de los resultados\n",
    "results_df = pd.DataFrame(country_averages, columns=['Country', 'AveragePrevalence'])\n",
    "\n",
    "# Guardar el DataFrame como archivo CSV\n",
    "results_df.to_csv('PROMEDIO_DE_PREVALENCIA_POR_PAÍS_USANDO_LISTAS_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('PROMEDIO_DE_PREVALENCIA_POR_PAÍS_USANDO_LISTAS_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ad67c",
   "metadata": {},
   "source": [
    "#### **4.3 RANGO DE PREVALENCIA POR AÑO USANDO LISTAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear una pila para almacenar rangos por año\n",
    "ranges_stack = []\n",
    "\n",
    "# Agrupar por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    values = list(df[df['TimeDim'] == year]['NumericValue'])\n",
    "    max_val = max(values)\n",
    "    min_val = min(values)\n",
    "    year_range = max_val - min_val\n",
    "    ranges_stack.append((year, min_val, max_val, year_range))\n",
    "\n",
    "# Crear un DataFrame con las columnas correspondientes\n",
    "ranges_df = pd.DataFrame(ranges_stack, columns=['Año', 'Min', 'Max', 'Rango'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(ranges_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1d4f5",
   "metadata": {},
   "source": [
    "###### **4.3.1 DESCARGAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ea9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "ranges_df.to_csv('RANGO_DE_PREVALENCIA_POR_AÑO_USANDO_LISTAS_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('RANGO_DE_PREVALENCIA_POR_AÑO_USANDO_LISTAS_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36e003",
   "metadata": {},
   "source": [
    "#### **4.4 CALCULAR LA MEDIANA DE PREVALENCIA USANDO COLAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add369b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la mediana por año\n",
    "medians_queue = deque()\n",
    "\n",
    "# Agrupar por año\n",
    "for year in df['TimeDim'].unique():\n",
    "    values = sorted(list(df[df['TimeDim'] == year]['NumericValue']))\n",
    "    n = len(values)\n",
    "    if n % 2 == 0:  # Si hay un número par de valores\n",
    "        median = (values[n // 2 - 1] + values[n // 2]) / 2\n",
    "    else:  # Si hay un número impar de valores\n",
    "        median = values[n // 2]\n",
    "    medians_queue.append((year, median))\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "medians_df = pd.DataFrame(medians_queue, columns=['Año', 'Mediana'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(medians_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff3044",
   "metadata": {},
   "source": [
    "##### **4.4.1 GUARDAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f447e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "medians_df.to_csv('LA_MEDIANA_DE_PREVALENCIA_USANDO_COLAS_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('LA_MEDIANA_DE_PREVALENCIA_USANDO_COLAS_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f9472",
   "metadata": {},
   "source": [
    "#### **4.5 COMPARAR PAÍSES CON MÁS ESTABILIDAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1912b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista para almacenar rangos por país\n",
    "country_ranges = []\n",
    "\n",
    "# Calcular rango por país\n",
    "for country in df['SpatialDim'].unique():\n",
    "    if df[df['SpatialDim'] == country]['SpatialDimType'].iloc[0] == 'COUNTRY':\n",
    "        values = list(df[df['SpatialDim'] == country]['NumericValue'])\n",
    "        country_range = max(values) - min(values)\n",
    "        country_ranges.append((country, country_range))\n",
    "\n",
    "# Ordenar por rango\n",
    "country_ranges.sort(key=lambda x: x[1])\n",
    "\n",
    "# Convertir a un DataFrame\n",
    "ranges_df = pd.DataFrame(country_ranges, columns=['País', 'Rango'])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(ranges_df)  # Mostrar los 60 países más estables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651cf962",
   "metadata": {},
   "source": [
    "#### **4.5.1 DESCARGAR EN FORMATO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como archivo CSV\n",
    "ranges_df.to_csv('COMPARAR_PAÍSES_CON_MÁS_ESTABILIDAD_gho.csv', index=False)\n",
    "\n",
    "# Descargar el archivo a tu ordenador\n",
    "from google.colab import files\n",
    "files.download('COMPARAR_PAÍSES_CON_MÁS_ESTABILIDAD_gho.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8521f3",
   "metadata": {},
   "source": [
    "## 5. Visualización de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594410b3",
   "metadata": {},
   "source": [
    "### 5.1 Paquetes requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddadfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import plotly.express as px #Para hacer graficos interactivos, no funcionaba en mapamundi\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib.patches import Wedge\n",
    "from pandas.plotting import table\n",
    "from plotly.subplots import make_subplots #Para poder poner subgraficos categorizados\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "#Para el mapamundi\n",
    "#!pip install folium\n",
    "#import folium\n",
    "\n",
    "#!pip install geopandas\n",
    "#!pip install geopy\n",
    "\n",
    "#No se podía poner el filtro dinámico, gpt comentó instalar --> #jupyter nbextension enable --py widgetsnbextension\n",
    "#generaba un error porque la versión de Jupyter no lo soportaba.\n",
    "#Por lo que se actualizo con este código --> pip install --upgrade jupyter jupyterlab ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5e3e5",
   "metadata": {},
   "source": [
    "### 5.2 Anemia infantil a través del tiempo (2000-2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803328ed",
   "metadata": {},
   "source": [
    "#### 5.2.1 Anemia infantil a nivel mundial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuente: World Bank\n",
    "\n",
    "# Cargar datos\n",
    "data_historico = pd.read_csv(r\"world_bank_anemia_mundial_listo.csv\")\n",
    "\n",
    "# Crear el gráfico\n",
    "fig = px.line(\n",
    "    data_historico,\n",
    "    x=\"year\",\n",
    "    y=\"prevalencia (%)\",\n",
    "    markers=True,\n",
    "    title=\"Prevalencia de anemia (en %), 2000-2019\",\n",
    "    labels={\"year\": \"Año\", \"prevalencia (%)\": \"Prevalencia (%)\"}\n",
    ")\n",
    "\n",
    "# Personalizar diseño\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"Prevalencia: %{y:.1f}%\",\n",
    "    line=dict(color=\"blue\"),\n",
    "    marker=dict(size=8)\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(title=\"Prevalencia (%)\", range=[10, 50]),\n",
    "    xaxis=dict(\n",
    "        tickangle=-90,  # Rotar las etiquetas de los años\n",
    "        tickmode='array',  # Mostrar todos los años\n",
    "        tickvals=data_historico[\"year\"],  # Asegura que todos los años se muestren\n",
    "        title=\"\"  # Eliminar el título del eje X\n",
    "    ),\n",
    "    title=dict(font=dict(size=18)),\n",
    "    template=\"simple_white\"\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a17f4",
   "metadata": {},
   "source": [
    "#### 5.2.2 Prevalencia de anemia infantil según nivel de ingreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuente: World Bank\n",
    "\n",
    "# Cargar datos\n",
    "data_nivelingresos = pd.read_csv(r\"world_bank_anemia_ingresos_listo.csv\")\n",
    "\n",
    "# Asegurarse de que los datos de 'year' sean numéricos\n",
    "data_nivelingresos['year'] = pd.to_numeric(data_nivelingresos['year'], errors='coerce')\n",
    "data_nivelingresos = data_nivelingresos.dropna(subset=['year', 'prevalencia (%)'])  # Eliminar filas con datos faltantes\n",
    "data_nivelingresos['year'] = data_nivelingresos['year'].astype(int)\n",
    "\n",
    "# Crear el gráfico interactivo con Plotly\n",
    "fig = px.line(data_nivelingresos, x='year', y='prevalencia (%)', color='nivel de ingresos',\n",
    "              markers=True, title='Prevalencia histórica de anemia por nivel de ingresos',\n",
    "              labels={'prevalencia (%)': 'Prevalencia (%)', 'year': 'Año'})\n",
    "\n",
    "# Eliminar la leyenda\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# Añadir el nombre del nivel de ingresos cerca del último punto disponible y alineado verticalmente\n",
    "y_offset = 0.1  # Ajuste de distancia entre los nombres de los niveles\n",
    "for i, level in enumerate(data_nivelingresos['nivel de ingresos'].unique()):\n",
    "    level_data = data_nivelingresos[data_nivelingresos['nivel de ingresos'] == level]\n",
    "    last_row = level_data[level_data['year'] == level_data['year'].max()]\n",
    "    if not last_row.empty:\n",
    "        last_year = last_row['year'].values[0]\n",
    "        last_value = last_row['prevalencia (%)'].values[0]\n",
    "        \n",
    "        # Añadir la anotación en la posición deseada\n",
    "        fig.add_annotation(\n",
    "            x=last_year + 0.4,  # Posición horizontal cerca del último punto\n",
    "            y=last_value + (y_offset * i),  # Posición vertical con ajuste para separar los nombres\n",
    "            text=level,  # Texto con el nombre del nivel de ingresos\n",
    "            showarrow=False,  # Sin flecha\n",
    "            font=dict(size=10),  # Tamaño de la fuente\n",
    "            xanchor='left',  # Alineación del texto a la izquierda\n",
    "            align='left',  # Alineación del texto a la izquierda\n",
    "        )\n",
    "\n",
    "# Mejorar el diseño del gráfico\n",
    "fig.update_traces(mode='lines+markers', hovertemplate='Prevalencia: %{y}')  # Solo mostrar prevalencia en el tooltip\n",
    "fig.update_layout(\n",
    "    xaxis_title='Año',\n",
    "    yaxis_title='Prevalencia (%)',\n",
    "    xaxis=dict(\n",
    "        title=None,  # Quitar el título del eje X\n",
    "        tickmode='array', \n",
    "        tickvals=sorted(\n",
    "            data_nivelingresos['year'].unique()),\n",
    "        showline=True,\n",
    "        linecolor='black',\n",
    "        ticks='outside',  # Mostrar marcas de graduación principales hacia el exterior\n",
    "        tickwidth=1,  # Grosor de las marcas de graduación\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "            showline=True,  # Mostrar la línea del eje Y\n",
    "            linewidth=1,  # Definir el grosor de la línea\n",
    "            linecolor='black'  # Definir el color de la línea\n",
    "    ),\n",
    "    xaxis_tickangle=-90,  # Girar el eje de los años en sentido opuesto\n",
    "    plot_bgcolor='white',\n",
    "    font=dict(size=12),\n",
    "    title_x=0.5,  # Centrar el título\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b35b9",
   "metadata": {},
   "source": [
    "#### 5.3.3 Prevalencia de anemia infantil por país (Multiselección) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27580ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuente: World Bank\n",
    "\n",
    "# Cargar los datos\n",
    "data_historico_pais_est = pd.read_csv(r\"world_bank_anemia_paises_listo.csv\")\n",
    "data_historico_pais_est['year'] = pd.to_numeric(data_historico_pais_est['year'], errors='coerce')\n",
    "data_historico_pais_est['year'] = data_historico_pais_est['year'].astype(int)\n",
    "\n",
    "# Obtener la lista de países únicos\n",
    "countries = sorted(data_historico_pais_est['pais'].unique())\n",
    "\n",
    "# Asignar un color único a cada país\n",
    "def assign_colors(countries):\n",
    "    colors = {}\n",
    "    for country in countries:\n",
    "        # Asignamos un color aleatorio a cada país\n",
    "        colors[country] = f'rgba({random.randint(0,255)},{random.randint(0,255)},{random.randint(0,255)}, 0.8)'\n",
    "    return colors\n",
    "\n",
    "colors = assign_colors(countries)\n",
    "\n",
    "# Función para completar los años faltantes y hacer líneas continuas\n",
    "def completar_anios(data, country):\n",
    "    # Filtrar datos del país\n",
    "    country_data = data[data['pais'] == country].copy()\n",
    "\n",
    "    # Generar el rango completo de años\n",
    "    all_years = pd.DataFrame({'year': range(country_data['year'].min(), country_data['year'].max() + 1)})\n",
    "\n",
    "    # Unir con los datos originales y llenar los valores faltantes mediante interpolación\n",
    "    completed_data = pd.merge(all_years, country_data, on='year', how='left')\n",
    "    completed_data['prevalencia (%)'] = completed_data['prevalencia (%)'].interpolate()\n",
    "\n",
    "    # Añadir el nombre del país\n",
    "    completed_data['pais'] = country\n",
    "    return completed_data\n",
    "\n",
    "# Función para graficar prevalencias históricas basadas en los países seleccionados\n",
    "def plot_selected_countries_plotly(countries_selected):\n",
    "    if not countries_selected:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Por favor selecciona al menos un país.\")\n",
    "        return\n",
    "\n",
    "    # Crear una figura\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for country in countries_selected:\n",
    "        # Completar los años faltantes\n",
    "        country_data = completar_anios(data_historico_pais_est, country)\n",
    "\n",
    "        # Dividir los datos en tres segmentos\n",
    "        before_2020 = country_data[country_data['year'] < 2020]\n",
    "        between_2020_2030 = country_data[(country_data['year'] >= 2020) & (country_data['year'] <= 2030)]\n",
    "        after_2030 = country_data[country_data['year'] > 2030]\n",
    "\n",
    "        # Obtener el color para el país\n",
    "        country_color = colors[country]\n",
    "\n",
    "        # Añadir el segmento antes de 2020 (línea continua)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=before_2020['year'],\n",
    "                y=before_2020['prevalencia (%)'],\n",
    "                mode='lines+markers',\n",
    "                name=country,\n",
    "                hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",  # Personalizar el tooltip sin el símbolo '%'\n",
    "                line=dict(color=country_color)  # Usamos el color del país\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Añadir el segmento entre 2020 y 2030 (línea punteada)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=between_2020_2030['year'],\n",
    "                y=between_2020_2030['prevalencia (%)'],\n",
    "                mode='lines+markers',\n",
    "                name=country,\n",
    "                hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",  # Personalizar el tooltip sin el símbolo '%'\n",
    "                line=dict(dash='dot', color=country_color)  # Usamos el mismo color del país para la línea punteada\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Añadir el segmento después de 2030 (línea continua)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=after_2030['year'],\n",
    "                y=after_2030['prevalencia (%)'],\n",
    "                mode='lines+markers',\n",
    "                name=country,\n",
    "                hovertemplate=\"Prevalencia: %{y:.2f}<extra></extra>\",  # Personalizar el tooltip sin el símbolo '%'\n",
    "                line=dict(color=country_color)  # Usamos el color del país\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Colocar el nombre del país ligeramente desplazado a la derecha de 2030\n",
    "        year_2030_data = country_data[country_data['year'] == 2019]\n",
    "        if not year_2030_data.empty:\n",
    "            # Obtenemos el valor de prevalencia para 2030\n",
    "            prev_2030 = year_2030_data['prevalencia (%)'].values[0]\n",
    "            fig.add_annotation(\n",
    "                x=2019 + 1.2,  # Desplazamos un poco a la derecha de 2030\n",
    "                y=prev_2030,\n",
    "                text=country,\n",
    "                showarrow=False,\n",
    "                font=dict(size=10, color='black'),\n",
    "                xanchor='left',  # Alineación del texto a la izquierda\n",
    "                align='left'  # Alineación del texto a la izquierda\n",
    "            )\n",
    "\n",
    "    # Ajustar el diseño del gráfico\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Prevalencia histórica de anemia',\n",
    "            'x': 0.5,  # Centrar el título\n",
    "            'xanchor': 'center',  # Asegurar que el anclaje sea en el centro\n",
    "        },\n",
    "        xaxis=dict(\n",
    "            title=None,  # Quitar el título del eje X\n",
    "            tickangle=-90,\n",
    "            showline=True,\n",
    "            linecolor='black',\n",
    "            ticks='outside',  # Mostrar marcas de graduación principales hacia el exterior\n",
    "            tickwidth=1,  # Grosor de las marcas de graduación\n",
    "            tickvals=list(\n",
    "                range(\n",
    "                    data_historico_pais_est['year'].min(), \n",
    "                    data_historico_pais_est['year'].max() + 1\n",
    "                )\n",
    "            )  # Asegurar que todos los años estén en el eje X\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showline=True,  # Mostrar la línea del eje Y\n",
    "            linewidth=1,  # Definir el grosor de la línea\n",
    "            linecolor='black'  # Definir el color de la línea\n",
    "        ),\n",
    "        showlegend=False,  # Quitar la leyenda\n",
    "        yaxis_title='Prevalencia (%)',\n",
    "        legend_title='Países',\n",
    "        template='plotly_white',\n",
    "        width=850  # Ampliar el ancho del gráfico,\n",
    "    )\n",
    "\n",
    "    # Mostrar el gráfico en el área de salida\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        fig.show()\n",
    "\n",
    "# Función para manejar la actualización dinámica del gráfico\n",
    "def update_plot(change=None):\n",
    "    # Obtener los países seleccionados\n",
    "    selected_countries = [cb.description for cb in checkboxes if cb.value]\n",
    "\n",
    "    # Actualizar el gráfico\n",
    "    plot_selected_countries_plotly(selected_countries)\n",
    "\n",
    "# Crear checkboxes para cada país\n",
    "checkboxes = [widgets.Checkbox(value=False, description=country) for country in countries]\n",
    "\n",
    "# Agregar un evento a cada checkbox\n",
    "for cb in checkboxes:\n",
    "    cb.observe(update_plot, names='value')\n",
    "\n",
    "# Crear un contenedor para los checkboxes con barra de desplazamiento\n",
    "checkbox_box = widgets.VBox(checkboxes, layout=widgets.Layout(overflow='auto', height='300px', width='200px'))\n",
    "\n",
    "# Crear un área de salida para el gráfico\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Mostrar los checkboxes y el área de salida\n",
    "display(widgets.HBox([checkbox_box, output_area]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7c238",
   "metadata": {},
   "source": [
    "#### 5.3.4 Clasificación de la importancia de la anemia infantil en la salud pública, por país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d728874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuente: World Bank\n",
    "\n",
    "# Función para graficar la prevalencia de anemia de un país específico\n",
    "\n",
    "data_ind_anemia = pd.read_csv(r\"dhs_anemia_final.csv\")\n",
    "data_ind_anemia.drop(data_ind_anemia.columns[[3, 4, 5, 6, 7, 8, 9, 10]], axis=1, inplace=True)\n",
    "data_ind_anemia.rename(\n",
    "    columns={\n",
    "    'Valor Cualquier': 'Valor\\nReal',\n",
    "    'Valor Severo' : 'Valor\\nsevero',\n",
    "    '# Encuestas (sev, sin ponderar)': '# Encuestas\\n(sin ponderar)',\n",
    "    '# Encuestas (sev, ponderadas)': '# Encuestas\\n(ponderadas)'\n",
    "    }, \n",
    "    inplace=True) \n",
    "\n",
    "# Función para crear un velocímetro estilizado\n",
    "def plot_stylized_gauge(ax, value, country, min_val=0, max_val=100):\n",
    "    levels = [\"Baja\", \"Moderada\", \"Alta\"]\n",
    "    colors = [\"#32CD32\", \"#FFD700\", \"#FF4D4D\"]  # Verde -> Amarillo -> Rojo\n",
    "    thresholds = [0, 20, 40, 100]\n",
    "\n",
    "    start_angle = 180  # Inicio del semicírculo en 180° (sentido antihorario)\n",
    "    end_angle = 0 # Fin del semicírculo\n",
    "\n",
    "    for i, (level, color) in enumerate(zip(levels, colors)):\n",
    "\n",
    "        # Calcular los ángulos para cada nivel en función de los umbrales\n",
    "        start = start_angle - (start_angle - end_angle) * (thresholds[i + 1] - min_val) / (max_val - min_val)\n",
    "        end = start_angle - (start_angle - end_angle) * (thresholds[i] - min_val) / (max_val - min_val)\n",
    "        \n",
    "        # Dibujar sección usando Wedge\n",
    "        wedge = Wedge(center=(0, 0), r=1, theta1=start, theta2=end, facecolor=color, edgecolor=\"white\")\n",
    "        ax.add_patch(wedge)\n",
    "\n",
    "        # Posicionar texto\n",
    "        mid_angle = (start + end) / 2\n",
    "        x_text = np.cos(np.radians(mid_angle)) * 0.7\n",
    "        y_text = np.sin(np.radians(mid_angle)) * 0.7\n",
    "        ax.text(x_text, y_text, level, ha=\"center\", va=\"center\", fontsize=14, color=\"white\")\n",
    "\n",
    "    # Dibujar la aguja (en sentido antihorario)\n",
    "    value_angle = start_angle - (start_angle - end_angle) * (value - min_val) / (max_val - min_val)\n",
    "    x_needle = np.cos(np.radians(value_angle)) * 0.9\n",
    "    y_needle = np.sin(np.radians(value_angle)) * 0.9\n",
    "    ax.plot([0, x_needle], [0, y_needle], color=\"black\", linewidth=2)\n",
    "\n",
    "    # Agregar valor al centro\n",
    "    ax.text(0, -0.2, f\"{value}\", ha=\"center\", va=\"center\", fontsize=18, weight=\"bold\")\n",
    "    ax.text(0, -0.35, country, ha=\"center\", va=\"center\", fontsize=12, style=\"italic\")\n",
    "\n",
    "    # Ajustar límites y ocultar ejes\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-0.0025, 1.2)  # Mostrar solo el semicírculo superior\n",
    "    ax.set_aspect('equal')  # Relación de aspecto 1:1 para un semicírculo perfecto\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Función para graficar la tabla de prevalencia \n",
    "def plot_paises(paises):\n",
    "    # Filtrar los datos para el país seleccionado\n",
    "    data_paises = data_ind_anemia[data_ind_anemia['Pais'] == paises]\n",
    "    \n",
    "    # Obtener el valor \"severo\" del año más reciente\n",
    "    latest_year = data_paises['Year'].max()\n",
    "    severe_value = data_paises[data_paises['Year'] == latest_year]['Valor\\nReal'].values[0] \n",
    "\n",
    "    # Crear figura con dos subgráficos (uno para la tabla y otro para el velocímetro)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))  # Tamaño de la figura\n",
    "\n",
    "    # Mostrar la tabla en el primer subgráfico\n",
    "    ax1.axis('off')  # Apagar los ejes para la tabla\n",
    "    \n",
    "    # Crear la tabla usando ax.table\n",
    "    table_data = data_paises.values\n",
    "    table_columns = data_paises.columns\n",
    "    table = ax1.table(cellText=table_data, colLabels=table_columns, loc='center', cellLoc='center')\n",
    "\n",
    "    # Personalizar el estilo de la tabla\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "\n",
    "    # Ajustar las celdas\n",
    "    for (i, j), cell in table.get_celld().items():\n",
    "        cell.set_edgecolor('black')\n",
    "        cell.set_linewidth(1.2)\n",
    "        if i == 0:  # Encabezados\n",
    "            cell.set_height(0.25)\n",
    "            cell.set_facecolor('#4CAF50')\n",
    "            cell.set_text_props(ha='center', va='center', color='white', weight='bold', fontsize=10)\n",
    "        else:  # Filas de datos\n",
    "            cell.set_facecolor('#f9f9f9')\n",
    "            cell.set_text_props(color='black', fontsize=10)\n",
    "        if j == 0:  # Primera columna\n",
    "            cell.set_facecolor('#d3d3d3')\n",
    "            cell.set_text_props(color='black', weight='bold')\n",
    "            \n",
    "    # Ajustar el ancho de las columnas basado en el texto\n",
    "    col_widths = [max(len(str(cell)) for cell in data_paises[col].tolist() + [col]) for col in data_paises.columns]\n",
    "    total_width = sum(col_widths)\n",
    "    for i, width in enumerate(col_widths):\n",
    "        table.auto_set_column_width(i)  # Ajustar automáticamente\n",
    "        table.get_celld()[(0, i)].set_width(width / total_width * 2)  # Normalizar al tamaño del gráfico\n",
    "\n",
    "    # Mostrar el velocímetro en el segundo subgráfico\n",
    "    value = data_paises['Valor\\nReal'].values[0]  # Suponiendo que 'Valor Cualquier' es el valor que usas\n",
    "    plot_stylized_gauge(ax2, severe_value, paises)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Crear el selector interactivo\n",
    "lista_paises = data_ind_anemia['Pais'].unique()\n",
    "interact(plot_paises, paises=lista_paises)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
